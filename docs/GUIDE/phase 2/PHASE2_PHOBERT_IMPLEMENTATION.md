# ğŸš€ Triá»ƒn Khai Reranking vá»›i PhoBERT - Plan Má»™t Buá»•i Chiá»u

**Dá»± Ã¡n**: RAG-bidding  
**Thá»i gian**: 3-4 giá» (má»™t buá»•i chiá»u)  
**Má»¥c tiÃªu**: Triá»ƒn khai PhoBERT reranking cho vÄƒn báº£n phÃ¡p luáº­t Viá»‡t Nam  
**NgÃ y**: 23 thÃ¡ng 10, 2025

---

## ğŸ¯ Má»¥c TiÃªu Buá»•i Chiá»u

### **Káº¿t quáº£ cáº§n Ä‘áº¡t Ä‘Æ°á»£c:**
- âœ… PhoBERT reranker hoáº¡t Ä‘á»™ng trong cháº¿ Ä‘á»™ quality
- âœ… Test cases pass
- âœ… API endpoint hoáº¡t Ä‘á»™ng vá»›i reranking
- âœ… Benchmark latency < 150ms cho 10 docs
- âœ… Cáº£i thiá»‡n MRR Ã­t nháº¥t 10-15%

### **KhÃ´ng cáº§n lÃ m hÃ´m nay:**
- âŒ Fine-tune PhoBERT trÃªn dá»¯ liá»‡u phÃ¡p luáº­t (Phase 3)
- âŒ LLM reranking (Phase 2B)
- âŒ Legal scoring (Phase 2C)
- âŒ Production deployment

---

## â° Timeline Chi Tiáº¿t

### **13:00 - 13:45 (45 phÃºt): Setup & Base Infrastructure**
- [x] ~~CÃ i dependencies~~ (Ä‘Ã£ xong: sentence-transformers 5.1.2)
- [ ] Táº¡o folder structure
- [ ] Implement `BaseReranker` abstract class
- [ ] Test PhoBERT model download vÃ  khá»Ÿi táº¡o

### **13:45 - 14:30 (45 phÃºt): PhoBERT Reranker Implementation**
- [ ] Implement `PhoBERTReranker` class
- [ ] Test vá»›i sample query-document pairs
- [ ] Benchmark latency
- [ ] Handle edge cases (empty docs, long text)

### **14:30 - 15:00 (30 phÃºt): Giáº£i Lao & Review Code**
- [ ] Coffee break â˜•
- [ ] Review code Ä‘Ã£ viáº¿t
- [ ] Fix bugs/issues náº¿u cÃ³

### **15:00 - 15:45 (45 phÃºt): Integration vá»›i Retrievers**
- [ ] Update `EnhancedRetriever` Ä‘á»ƒ há»— trá»£ reranking
- [ ] Update factory pattern trong `__init__.py`
- [ ] Test integration end-to-end

### **15:45 - 16:30 (45 phÃºt): Testing & Validation**
- [ ] Viáº¿t unit tests
- [ ] Viáº¿t integration test
- [ ] Cháº¡y test vá»›i real legal queries
- [ ] So sÃ¡nh káº¿t quáº£ cÃ³/khÃ´ng reranking

### **16:30 - 17:00 (30 phÃºt): Wrap Up**
- [ ] Update config
- [ ] Test API endpoint
- [ ] Document changes
- [ ] Commit code

---

## ğŸ“‹ Chi Tiáº¿t Tá»«ng BÆ°á»›c

## **BÆ¯á»šC 1: Setup & Base Infrastructure (13:00 - 13:45)**

### **1.1. Táº¡o Folder Structure (5 phÃºt)**

```bash
cd /home/sakana/Code/RAG-bidding

# Táº¡o thÆ° má»¥c ranking
mkdir -p src/retrieval/ranking

# Táº¡o cÃ¡c files
touch src/retrieval/ranking/__init__.py
touch src/retrieval/ranking/base_reranker.py
touch src/retrieval/ranking/phobert_reranker.py

# Táº¡o test folder
mkdir -p tests/unit/test_retrieval
touch tests/unit/test_retrieval/test_reranking.py
```

### **1.2. Implement BaseReranker (15 phÃºt)**

```python
# src/retrieval/ranking/base_reranker.py

from abc import ABC, abstractmethod
from typing import List, Tuple
from langchain_core.documents import Document


class BaseReranker(ABC):
    """
    Abstract base class cho táº¥t cáº£ rerankers
    
    Reranker nháº­n query vÃ  list documents, tráº£ vá»
    documents Ä‘Æ°á»£c xáº¿p háº¡ng láº¡i theo Ä‘á»™ liÃªn quan.
    """
    
    @abstractmethod
    def rerank(
        self, 
        query: str, 
        documents: List[Document],
        top_k: int = 5
    ) -> List[Tuple[Document, float]]:
        """
        Xáº¿p háº¡ng láº¡i documents theo Ä‘á»™ liÃªn quan vá»›i query
        
        Args:
            query: CÃ¢u há»i cá»§a user
            documents: List documents tá»« retriever
            top_k: Sá»‘ documents tráº£ vá» (máº·c Ä‘á»‹nh 5)
            
        Returns:
            List of (document, score) tuples, sorted by score descending
            
        Example:
            >>> reranker = PhoBERTReranker()
            >>> docs = [doc1, doc2, doc3]
            >>> results = reranker.rerank("Äiá»u 14 Luáº­t Äáº¥u tháº§u", docs, top_k=2)
            >>> [(doc1, 0.95), (doc3, 0.82)]
        """
        pass
    
    def rerank_batch(
        self,
        queries: List[str],
        documents_list: List[List[Document]],
        top_k: int = 5
    ) -> List[List[Tuple[Document, float]]]:
        """
        Batch reranking cho nhiá»u queries
        
        Máº·c Ä‘á»‹nh gá»i rerank() cho tá»«ng query.
        Subclass cÃ³ thá»ƒ override Ä‘á»ƒ optimize batch processing.
        """
        return [
            self.rerank(query, docs, top_k)
            for query, docs in zip(queries, documents_list)
        ]
```

### **1.3. Test PhoBERT Download (25 phÃºt)**

```python
# Táº¡o file test nhanh: test_phobert_setup.py

"""
Test script Ä‘á»ƒ verify PhoBERT setup
Cháº¡y: python test_phobert_setup.py
"""

import time
from sentence_transformers import CrossEncoder

print("ğŸ” Testing PhoBERT setup...")
print("-" * 60)

# Test 1: Load model
print("\n1ï¸âƒ£ Loading PhoBERT model...")
start = time.time()

try:
    # Thá»­ vá»›i vinai/phobert-base-v2 (nhá» hÆ¡n, nhanh hÆ¡n)
    model = CrossEncoder(
        'vinai/phobert-base-v2',
        device='cpu',
        max_length=256  # PhoBERT max sequence length
    )
    load_time = time.time() - start
    print(f"   âœ… Model loaded successfully in {load_time:.2f}s")
    print(f"   ğŸ“¦ Model: vinai/phobert-base-v2")
except Exception as e:
    print(f"   âŒ Error loading model: {e}")
    exit(1)

# Test 2: Sample inference
print("\n2ï¸âƒ£ Testing inference with legal text...")
start = time.time()

query = "Quy Ä‘á»‹nh vá» báº£o Ä‘áº£m dá»± tháº§u"
docs = [
    "Äiá»u 14. Báº£o Ä‘áº£m dá»± tháº§u lÃ  Ä‘iá»u kiá»‡n báº¯t buá»™c Ä‘á»‘i vá»›i nhÃ  tháº§u khi dá»± tháº§u.",
    "Äiá»u 68. Báº£o Ä‘áº£m thá»±c hiá»‡n há»£p Ä‘á»“ng Ä‘Æ°á»£c thá»±c hiá»‡n sau khi kÃ½ há»£p Ä‘á»“ng.",
    "Äiá»u 10. Æ¯u Ä‘Ã£i nhÃ  tháº§u trong nÆ°á»›c Ä‘Æ°á»£c quy Ä‘á»‹nh chi tiáº¿t táº¡i Nghá»‹ Ä‘á»‹nh."
]

pairs = [[query, doc] for doc in docs]
scores = model.predict(pairs)
inference_time = time.time() - start

print(f"   âœ… Inference completed in {inference_time:.2f}s")
print(f"   ğŸ“Š Scores:")
for i, (doc, score) in enumerate(zip(docs, scores)):
    print(f"      [{i+1}] Score: {score:.4f} - {doc[:60]}...")

# Test 3: Verify ranking
print("\n3ï¸âƒ£ Verifying ranking quality...")
best_idx = scores.argmax()
if best_idx == 0:  # Äiá»u 14 nÃªn cÃ³ score cao nháº¥t
    print(f"   âœ… Correct! Äiá»u 14 ranked #1 (score: {scores[0]:.4f})")
else:
    print(f"   âš ï¸  Warning: Äiá»u 14 not ranked #1 (best: doc {best_idx+1})")

# Test 4: Latency benchmark
print("\n4ï¸âƒ£ Benchmarking latency for 10 docs...")
docs_10 = docs * 4  # Táº¡o 12 docs (gáº§n vá»›i 10)
pairs_10 = [[query, doc] for doc in docs_10[:10]]

start = time.time()
scores_10 = model.predict(pairs_10)
latency = (time.time() - start) * 1000  # Convert to ms

print(f"   â±ï¸  Latency: {latency:.2f}ms for 10 docs")
if latency < 150:
    print(f"   âœ… Good! Under 150ms target")
else:
    print(f"   âš ï¸  Warning: Slower than 150ms target")

print("\n" + "=" * 60)
print("âœ… PhoBERT setup test COMPLETE!")
print("=" * 60)
```

**Cháº¡y test:**
```bash
cd /home/sakana/Code/RAG-bidding
python test_phobert_setup.py
```

**Káº¿t quáº£ ká»³ vá»ng:**
- Model load: 5-10s (láº§n Ä‘áº§u download ~500MB)
- Inference: <1s cho 3 docs
- Äiá»u 14 cÃ³ score cao nháº¥t
- Latency <150ms cho 10 docs

---

## **BÆ¯á»šC 2: PhoBERT Reranker Implementation (13:45 - 14:30)**

### **2.1. Implement PhoBERTReranker (30 phÃºt)**

```python
# src/retrieval/ranking/phobert_reranker.py

from sentence_transformers import CrossEncoder
from typing import List, Tuple, Optional
from langchain_core.documents import Document
import logging
import time

from .base_reranker import BaseReranker

logger = logging.getLogger(__name__)


class PhoBERTReranker(BaseReranker):
    """
    PhoBERT-based reranking cho vÄƒn báº£n phÃ¡p luáº­t Viá»‡t Nam
    
    Model: vinai/phobert-base-v2
    - 135M parameters
    - Trained on 20GB Vietnamese text
    - Max sequence length: 256 tokens (RoBERTa tokenizer)
    
    Performance:
    - Latency: ~100-150ms for 10 docs on CPU
    - Accuracy: Tá»‘t cho tiáº¿ng Viá»‡t, Ä‘áº·c biá»‡t vÄƒn báº£n chÃ­nh thá»‘ng
    
    Note:
    - Sá»­ dá»¥ng AutoTokenizer tá»± Ä‘á»™ng (khÃ´ng xung Ä‘á»™t vá»›i tiktoken)
    - Device: cpu (cÃ³ thá»ƒ chuyá»ƒn sang cuda náº¿u cÃ³ GPU)
    """
    
    # Model options (cÃ³ thá»ƒ thá»­ fine-tuned models sau)
    PHOBERT_BASE = "vinai/phobert-base-v2"      # 135M params, fast
    PHOBERT_LARGE = "vinai/phobert-large"       # 370M params, slower
    
    def __init__(
        self, 
        model_name: str = PHOBERT_BASE,
        device: str = "cpu",
        max_length: int = 256,
        batch_size: int = 16,
        cache_dir: Optional[str] = None
    ):
        """
        Args:
            model_name: PhoBERT model name (default: vinai/phobert-base-v2)
            device: "cpu" or "cuda"
            max_length: Max tokens (PhoBERT max = 256)
            batch_size: Batch size for inference
            cache_dir: Model cache directory (default: ~/.cache/huggingface)
        """
        logger.info(f"ğŸ”§ Initializing PhoBERT reranker: {model_name}")
        
        self.model_name = model_name
        self.device = device
        self.max_length = max_length
        self.batch_size = batch_size
        
        # Load CrossEncoder (tá»± Ä‘á»™ng load AutoTokenizer bÃªn trong)
        try:
            self.model = CrossEncoder(
                model_name,
                device=device,
                max_length=max_length,
                default_activation_function=None  # DÃ¹ng raw scores
            )
            logger.info(f"âœ… PhoBERT loaded on {device}")
            logger.info(f"ğŸ“¦ Max sequence length: {max_length} tokens")
        except Exception as e:
            logger.error(f"âŒ Failed to load PhoBERT: {e}")
            raise
    
    def rerank(
        self, 
        query: str, 
        documents: List[Document],
        top_k: int = 5
    ) -> List[Tuple[Document, float]]:
        """
        Rerank documents using PhoBERT cross-encoder
        
        Args:
            query: User query (tiáº¿ng Viá»‡t)
            documents: Retrieved documents
            top_k: Number of top documents to return
            
        Returns:
            List of (document, score) sorted by score descending
        """
        if not documents:
            logger.warning("âš ï¸  Empty documents list")
            return []
        
        start_time = time.time()
        
        # Truncate náº¿u cÃ³ quÃ¡ nhiá»u docs (trÃ¡nh OOM)
        if len(documents) > 50:
            logger.warning(f"âš ï¸  Too many docs ({len(documents)}), truncating to 50")
            documents = documents[:50]
        
        # Chuáº©n bá»‹ query-document pairs
        pairs = []
        for doc in documents:
            # Truncate content náº¿u quÃ¡ dÃ i (PhoBERT max 256 tokens)
            # Æ¯á»›c tÃ­nh: 1 token â‰ˆ 4 chars cho tiáº¿ng Viá»‡t
            content = doc.page_content[:800]  # ~200 tokens content
            pairs.append([query, content])
        
        # Predict relevance scores
        try:
            scores = self.model.predict(
                pairs,
                batch_size=self.batch_size,
                show_progress_bar=False
            )
        except Exception as e:
            logger.error(f"âŒ Prediction error: {e}")
            # Fallback: return original order with dummy scores
            return [(doc, 1.0 - i * 0.1) for i, doc in enumerate(documents[:top_k])]
        
        # Zip documents with scores vÃ  sort
        doc_scores = list(zip(documents, scores))
        doc_scores.sort(key=lambda x: x[1], reverse=True)
        
        # Log performance
        latency = (time.time() - start_time) * 1000
        top_score = doc_scores[0][1] if doc_scores else 0
        
        logger.info(
            f"ğŸ“Š Reranked {len(documents)} docs in {latency:.1f}ms | "
            f"Top score: {top_score:.4f} | Returning top {top_k}"
        )
        
        # Debug: Log top 3 scores
        if logger.isEnabledFor(logging.DEBUG):
            for i, (doc, score) in enumerate(doc_scores[:3]):
                preview = doc.page_content[:80].replace('\n', ' ')
                logger.debug(f"  [{i+1}] {score:.4f} - {preview}...")
        
        return doc_scores[:top_k]
    
    def rerank_batch(
        self,
        queries: List[str],
        documents_list: List[List[Document]],
        top_k: int = 5
    ) -> List[List[Tuple[Document, float]]]:
        """
        Batch reranking (tá»‘i Æ°u hÃ³a sau náº¿u cáº§n)
        
        Hiá»‡n táº¡i: Gá»i rerank() cho tá»«ng query
        TODO: Implement true batch processing
        """
        logger.info(f"ğŸ”„ Batch reranking {len(queries)} queries...")
        
        results = []
        for query, docs in zip(queries, documents_list):
            result = self.rerank(query, docs, top_k)
            results.append(result)
        
        return results
```

### **2.2. Update __init__.py (5 phÃºt)**

```python
# src/retrieval/ranking/__init__.py

from .base_reranker import BaseReranker
from .phobert_reranker import PhoBERTReranker

__all__ = [
    "BaseReranker",
    "PhoBERTReranker",
]
```

### **2.3. Test PhoBERTReranker (10 phÃºt)**

```python
# Táº¡o file: test_phobert_reranker.py

"""
Quick test PhoBERTReranker implementation
"""

from langchain_core.documents import Document
from src.retrieval.ranking import PhoBERTReranker

print("ğŸ§ª Testing PhoBERTReranker...")
print("-" * 60)

# Initialize reranker
reranker = PhoBERTReranker(device="cpu")

# Sample query vá» báº£o Ä‘áº£m dá»± tháº§u
query = "Quy Ä‘á»‹nh vá» thá»i gian hiá»‡u lá»±c báº£o Ä‘áº£m dá»± tháº§u trong Luáº­t Äáº¥u tháº§u 2023"

# Sample documents (giáº£ láº­p tá»« vector search)
docs = [
    Document(
        page_content="Äiá»u 14. Báº£o Ä‘áº£m dá»± tháº§u\n1. Thá»i gian hiá»‡u lá»±c báº£o Ä‘áº£m dá»± tháº§u Ä‘Æ°á»£c quy Ä‘á»‹nh trong há»“ sÆ¡ má»i tháº§u, tá»‘i thiá»ƒu lÃ  30 ngÃ y ká»ƒ tá»« ngÃ y háº¿t háº¡n ná»™p há»“ sÆ¡ dá»± tháº§u.",
        metadata={"source": "Luáº­t Äáº¥u tháº§u 2023", "article": "Äiá»u 14"}
    ),
    Document(
        page_content="Äiá»u 68. Báº£o Ä‘áº£m thá»±c hiá»‡n há»£p Ä‘á»“ng\nThá»i háº¡n báº£o Ä‘áº£m thá»±c hiá»‡n há»£p Ä‘á»“ng Ä‘Æ°á»£c quy Ä‘á»‹nh trong há»£p Ä‘á»“ng, thÆ°á»ng tá»« ngÃ y kÃ½ há»£p Ä‘á»“ng Ä‘áº¿n khi hoÃ n thÃ nh nghÄ©a vá»¥.",
        metadata={"source": "Luáº­t Äáº¥u tháº§u 2023", "article": "Äiá»u 68"}
    ),
    Document(
        page_content="Äiá»u 10. Æ¯u Ä‘Ã£i nhÃ  tháº§u trong nÆ°á»›c\nNhÃ  tháº§u trong nÆ°á»›c Ä‘Æ°á»£c hÆ°á»Ÿng Æ°u Ä‘Ã£i vá» giÃ¡ trong Ä‘Ã¡nh giÃ¡, Æ°u tiÃªn xem xÃ©t trong trÆ°á»ng há»£p Ä‘iá»ƒm ká»¹ thuáº­t báº±ng nhau.",
        metadata={"source": "Luáº­t Äáº¥u tháº§u 2023", "article": "Äiá»u 10"}
    ),
    Document(
        page_content="Äiá»u 25. Thá»i Ä‘iá»ƒm cÃ³ hiá»‡u lá»±c cá»§a há»£p Ä‘á»“ng\nHá»£p Ä‘á»“ng cÃ³ hiá»‡u lá»±c ká»ƒ tá»« ngÃ y Ä‘Æ°á»£c kÃ½ káº¿t hoáº·c theo thá»a thuáº­n cá»§a cÃ¡c bÃªn trong há»£p Ä‘á»“ng.",
        metadata={"source": "Luáº­t Äáº¥u tháº§u 2023", "article": "Äiá»u 25"}
    ),
]

print(f"\nğŸ“ Query: {query}")
print(f"ğŸ“š Documents to rerank: {len(docs)}")

# Rerank
results = reranker.rerank(query, docs, top_k=3)

print(f"\nğŸ† Top 3 Results:")
print("-" * 60)
for i, (doc, score) in enumerate(results):
    article = doc.metadata.get("article", "Unknown")
    preview = doc.page_content[:100].replace('\n', ' ')
    print(f"\n[{i+1}] Score: {score:.4f}")
    print(f"    Article: {article}")
    print(f"    Preview: {preview}...")

# Verify
print("\n" + "=" * 60)
if "Äiá»u 14" in results[0][0].metadata.get("article", ""):
    print("âœ… TEST PASSED: Äiá»u 14 ranked #1 (correct!)")
else:
    print("âš ï¸  TEST WARNING: Äiá»u 14 not ranked #1")
print("=" * 60)
```

**Cháº¡y:**
```bash
python test_phobert_reranker.py
```

---

## **BÆ¯á»šC 3: Giáº£i Lao (14:30 - 15:00)**

â˜• **Coffee break & code review**

**Checklist trÆ°á»›c khi tiáº¿p tá»¥c:**
- [ ] PhoBERT model Ä‘Ã£ download thÃ nh cÃ´ng
- [ ] Reranker tráº£ vá» káº¿t quáº£ Ä‘Ãºng format
- [ ] Äiá»u 14 Ä‘Æ°á»£c rank cao hÆ¡n cÃ¡c Ä‘iá»u khÃ¡c
- [ ] Latency < 150ms
- [ ] Code clean, cÃ³ logging

---

## **BÆ¯á»šC 4: Integration vá»›i Retrievers (15:00 - 15:45)**

### **4.1. Update EnhancedRetriever (25 phÃºt)**

```python
# src/retrieval/retrievers/enhanced_retriever.py
# TÃ¬m class EnhancedRetriever vÃ  thÃªm reranking support

# ThÃªm import á»Ÿ Ä‘áº§u file
from typing import Optional
from ..ranking import BaseReranker

# Update class EnhancedRetriever
class EnhancedRetriever(BaseRetriever):
    """Enhanced retriever with query enhancement + optional reranking"""
    
    base_retriever: BaseVectorRetriever
    enhancement_strategies: Optional[List[EnhancementStrategy]] = None
    reranker: Optional[BaseReranker] = None  # â­ NEW
    k: int = 5
    rerank_top_k: int = 10  # â­ NEW: Retrieve more, rerank down to k
    enable_deduplication: bool = True
    
    def _get_relevant_documents(
        self, 
        query: str,
        run_manager: CallbackManagerForRetrieverRun = None
    ) -> List[Document]:
        """
        Retrieve vÃ  rerank documents
        
        Workflow:
        1. Enhance query (náº¿u cÃ³ strategies)
        2. Retrieve nhiá»u docs (rerank_top_k náº¿u cÃ³ reranker)
        3. Deduplicate
        4. Rerank (náº¿u cÃ³ reranker) â­ NEW
        5. Return top k
        """
        # Step 1: Enhance query
        if self.enhancement_strategies:
            queries = self._enhance_query(query)
        else:
            queries = [query]
        
        # Step 2: Retrieve (láº¥y nhiá»u hÆ¡n náº¿u sáº½ rerank)
        retrieval_k = self.rerank_top_k if self.reranker else self.k
        
        all_docs = []
        for q in queries:
            docs = self.base_retriever.invoke(q, k=retrieval_k)
            all_docs.extend(docs)
        
        # Step 3: Deduplicate
        if self.enable_deduplication:
            all_docs = self._deduplicate_docs(all_docs)
        
        # Step 4: Rerank â­ NEW
        if self.reranker:
            logger.info(f"ğŸ”„ Reranking {len(all_docs)} docs with {self.reranker.__class__.__name__}")
            doc_scores = self.reranker.rerank(query, all_docs, top_k=self.k)
            reranked_docs = [doc for doc, score in doc_scores]
            
            # Log improvement
            if logger.isEnabledFor(logging.DEBUG):
                logger.debug(f"  Original top doc: {all_docs[0].page_content[:60]}...")
                logger.debug(f"  Reranked top doc: {reranked_docs[0].page_content[:60]}...")
            
            return reranked_docs
        
        # No reranking: return first k docs
        return all_docs[:self.k]
```

### **4.2. Update Factory Pattern (20 phÃºt)**

```python
# src/retrieval/retrievers/__init__.py

from typing import Optional
from ...ranking import PhoBERTReranker, BaseReranker

def create_retriever(
    mode: str = "balanced",
    vector_store=None,
    enable_reranking: bool = True,  # â­ NEW parameter
    reranker: Optional[BaseReranker] = None  # â­ NEW: custom reranker
) -> BaseRetriever:
    """
    Factory function to create retriever based on mode
    
    Args:
        mode: "fast", "balanced", "quality", "adaptive"
        vector_store: PGVector store instance
        enable_reranking: Enable PhoBERT reranking (default: True)
        reranker: Custom reranker (default: PhoBERTReranker)
    
    Returns:
        Configured retriever instance
    """
    from .base_retriever import BaseVectorRetriever
    from .enhanced_retriever import EnhancedRetriever
    from .fusion_retriever import FusionRetriever
    from .adaptive_retriever import AdaptiveKRetriever
    from ..query_processing.strategies import EnhancementStrategy
    
    # Create base retriever
    base_retriever = BaseVectorRetriever(vector_store=vector_store)
    
    # Initialize reranker náº¿u enabled vÃ  mode há»— trá»£
    reranker_instance = None
    if enable_reranking and mode in ["balanced", "quality", "adaptive"]:
        if reranker:
            reranker_instance = reranker
        else:
            logger.info("ğŸ”§ Initializing PhoBERT reranker...")
            reranker_instance = PhoBERTReranker(device="cpu")
    
    # Fast mode: No enhancement, no reranking
    if mode == "fast":
        return base_retriever
    
    # Balanced mode: Light enhancement + reranking
    elif mode == "balanced":
        return EnhancedRetriever(
            base_retriever=base_retriever,
            enhancement_strategies=[
                EnhancementStrategy.MULTI_QUERY,
                EnhancementStrategy.STEP_BACK
            ],
            reranker=reranker_instance,  # â­ NEW
            rerank_top_k=8,
            k=4,
            enable_deduplication=True
        )
    
    # Quality mode: Full enhancement + reranking
    elif mode == "quality":
        return FusionRetriever(
            base_retriever=base_retriever,
            enhancement_strategies=[
                EnhancementStrategy.MULTI_QUERY,
                EnhancementStrategy.HYDE,
                EnhancementStrategy.STEP_BACK,
                EnhancementStrategy.DECOMPOSITION
            ],
            reranker=reranker_instance,  # â­ NEW
            rerank_top_k=10,
            k=5,
            enable_deduplication=True,
            fusion_weights=[0.4, 0.3, 0.2, 0.1]  # Weighted fusion
        )
    
    # Adaptive mode: Dynamic + reranking
    elif mode == "adaptive":
        return AdaptiveKRetriever(
            base_retriever=base_retriever,
            reranker=reranker_instance,  # â­ NEW
            min_k=3,
            max_k=10,
            enable_query_enhancement=True
        )
    
    else:
        raise ValueError(f"Unknown mode: {mode}")
```

---

## **BÆ¯á»šC 5: Testing & Validation (15:45 - 16:30)**

### **5.1. Unit Tests (20 phÃºt)**

```python
# tests/unit/test_retrieval/test_reranking.py

import pytest
from langchain_core.documents import Document
from src.retrieval.ranking import PhoBERTReranker


class TestPhoBERTReranker:
    """Test suite cho PhoBERT reranker"""
    
    @pytest.fixture
    def reranker(self):
        """Fixture: Khá»Ÿi táº¡o reranker"""
        return PhoBERTReranker(device="cpu")
    
    @pytest.fixture
    def sample_docs(self):
        """Fixture: Sample legal documents"""
        return [
            Document(
                page_content="Äiá»u 14. Báº£o Ä‘áº£m dá»± tháº§u lÃ  yÃªu cáº§u báº¯t buá»™c.",
                metadata={"article": "Äiá»u 14"}
            ),
            Document(
                page_content="Äiá»u 68. Báº£o Ä‘áº£m thá»±c hiá»‡n há»£p Ä‘á»“ng Ã¡p dá»¥ng sau kÃ½ káº¿t.",
                metadata={"article": "Äiá»u 68"}
            ),
            Document(
                page_content="Äiá»u 10. Æ¯u Ä‘Ã£i nhÃ  tháº§u trong nÆ°á»›c.",
                metadata={"article": "Äiá»u 10"}
            ),
        ]
    
    def test_rerank_basic(self, reranker, sample_docs):
        """Test basic reranking functionality"""
        query = "Quy Ä‘á»‹nh vá» báº£o Ä‘áº£m dá»± tháº§u"
        
        results = reranker.rerank(query, sample_docs, top_k=2)
        
        # Check format
        assert len(results) == 2
        assert all(isinstance(r, tuple) for r in results)
        assert all(len(r) == 2 for r in results)
        
        # Check scores descending
        scores = [score for _, score in results]
        assert scores[0] >= scores[1]
    
    def test_rerank_relevance(self, reranker, sample_docs):
        """Test ranking relevance"""
        query = "Thá»i gian hiá»‡u lá»±c báº£o Ä‘áº£m dá»± tháº§u"
        
        results = reranker.rerank(query, sample_docs, top_k=3)
        
        # Äiá»u 14 vá» báº£o Ä‘áº£m dá»± tháº§u nÃªn ranked cao nháº¥t
        top_doc = results[0][0]
        assert "Äiá»u 14" in top_doc.metadata.get("article", "")
    
    def test_rerank_empty_docs(self, reranker):
        """Test vá»›i empty documents"""
        results = reranker.rerank("test query", [], top_k=5)
        assert results == []
    
    def test_rerank_single_doc(self, reranker, sample_docs):
        """Test vá»›i single document"""
        results = reranker.rerank("test", sample_docs[:1], top_k=5)
        assert len(results) == 1
    
    def test_rerank_top_k_limit(self, reranker, sample_docs):
        """Test top_k limit"""
        results = reranker.rerank("test", sample_docs, top_k=2)
        assert len(results) <= 2


# Cháº¡y tests
if __name__ == "__main__":
    pytest.main([__file__, "-v"])
```

### **5.2. Integration Test (15 phÃºt)**

```python
# tests/integration/test_reranking_pipeline.py

import pytest
from src.retrieval.retrievers import create_retriever
from src.embedding.store import vector_store


@pytest.mark.integration
class TestRerankingPipeline:
    """Test end-to-end pipeline vá»›i reranking"""
    
    def test_quality_mode_with_reranking(self):
        """Test quality mode cÃ³ reranking"""
        # Create retriever vá»›i reranking
        retriever = create_retriever(
            mode="quality",
            vector_store=vector_store,
            enable_reranking=True
        )
        
        # Query thá»±c táº¿
        query = "Thá»i háº¡n hiá»‡u lá»±c cá»§a báº£o Ä‘áº£m dá»± tháº§u lÃ  bao lÃ¢u?"
        
        # Invoke
        docs = retriever.invoke(query)
        
        # Verify
        assert len(docs) == 5
        assert all(hasattr(doc, 'page_content') for doc in docs)
        assert all(hasattr(doc, 'metadata') for doc in docs)
        
        # Check relevance (Äiá»u 14 nÃªn trong top 2)
        top_2_content = " ".join([d.page_content for d in docs[:2]])
        assert "Äiá»u 14" in top_2_content or "báº£o Ä‘áº£m dá»± tháº§u" in top_2_content
    
    def test_comparison_with_without_reranking(self):
        """So sÃ¡nh cÃ³/khÃ´ng reranking"""
        query = "Quy Ä‘á»‹nh vá» thá»i gian hiá»‡u lá»±c báº£o Ä‘áº£m dá»± tháº§u"
        
        # Without reranking
        retriever_no_rerank = create_retriever(
            mode="quality",
            vector_store=vector_store,
            enable_reranking=False
        )
        docs_no_rerank = retriever_no_rerank.invoke(query)
        
        # With reranking
        retriever_rerank = create_retriever(
            mode="quality",
            vector_store=vector_store,
            enable_reranking=True
        )
        docs_rerank = retriever_rerank.invoke(query)
        
        # Compare
        print("\nğŸ“Š Comparison:")
        print(f"Without reranking top doc: {docs_no_rerank[0].page_content[:80]}...")
        print(f"With reranking top doc: {docs_rerank[0].page_content[:80]}...")
        
        # Assert cÃ³ sá»± khÃ¡c biá»‡t (hoáº·c improvement)
        assert len(docs_no_rerank) == len(docs_rerank)
```

### **5.3. Manual Testing vá»›i Real Queries (10 phÃºt)**

```python
# Táº¡o file: test_real_queries.py

"""
Manual test vá»›i real legal queries
"""

from src.retrieval.retrievers import create_retriever
from src.embedding.store import vector_store

print("ğŸ§ª Testing vá»›i Real Legal Queries")
print("=" * 70)

# Initialize retriever
retriever = create_retriever(
    mode="quality",
    vector_store=vector_store,
    enable_reranking=True
)

# Real queries tá»« use cases
queries = [
    "Thá»i gian hiá»‡u lá»±c báº£o Ä‘áº£m dá»± tháº§u tá»‘i thiá»ƒu lÃ  bao nhiÃªu ngÃ y?",
    "Äiá»u kiá»‡n Ä‘á»ƒ Ä‘Æ°á»£c Æ°u Ä‘Ã£i nhÃ  tháº§u trong nÆ°á»›c?",
    "So sÃ¡nh báº£o Ä‘áº£m dá»± tháº§u vÃ  báº£o Ä‘áº£m thá»±c hiá»‡n há»£p Ä‘á»“ng",
    "Há»“ sÆ¡ dá»± tháº§u cáº§n cÃ³ nhá»¯ng gÃ¬?",
]

for i, query in enumerate(queries, 1):
    print(f"\n{'â”€' * 70}")
    print(f"Query {i}: {query}")
    print(f"{'â”€' * 70}")
    
    docs = retriever.invoke(query)
    
    print(f"\nğŸ† Top 3 Results:")
    for j, doc in enumerate(docs[:3], 1):
        article = doc.metadata.get("article", "N/A")
        source = doc.metadata.get("source", "N/A")
        preview = doc.page_content[:120].replace('\n', ' ')
        
        print(f"\n  [{j}] {article} ({source})")
        print(f"      {preview}...")

print("\n" + "=" * 70)
print("âœ… Manual testing complete!")
```

---

## **BÆ¯á»šC 6: Wrap Up (16:30 - 17:00)**

### **6.1. Update Config (10 phÃºt)**

```python
# config/models.py

# ThÃªm reranking config
@dataclass
class Settings:
    # ... existing settings ...
    
    # Reranking (Phase 2)
    enable_reranking: bool = _env_bool("ENABLE_RERANKING", True)  # â­ Set TRUE
    reranker_model: str = os.getenv("RERANKER_MODEL", "vinai/phobert-base-v2")
    reranker_device: str = os.getenv("RERANKER_DEVICE", "cpu")
    rerank_top_k: int = int(os.getenv("RERANK_TOP_K", "10"))
```

Update `.env`:
```bash
# Reranking
ENABLE_RERANKING=true
RERANKER_MODEL=vinai/phobert-base-v2
RERANKER_DEVICE=cpu
RERANK_TOP_K=10
```

### **6.2. Test API Endpoint (10 phÃºt)**

```bash
# Test vá»›i curl
curl -X POST http://localhost:8000/api/query \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Thá»i háº¡n hiá»‡u lá»±c báº£o Ä‘áº£m dá»± tháº§u lÃ  bao lÃ¢u?",
    "mode": "quality"
  }'
```

**Ká»³ vá»ng:**
- Response cÃ³ `documents` vá»›i 5 docs
- Top doc liÃªn quan Ä‘áº¿n Äiá»u 14
- Response time < 2s

### **6.3. Commit Code (10 phÃºt)**

```bash
cd /home/sakana/Code/RAG-bidding

# Check status
git status

# Add files
git add src/retrieval/ranking/
git add tests/unit/test_retrieval/test_reranking.py
git add tests/integration/test_reranking_pipeline.py
git add config/models.py
git add docs/GUIDE/phase\ 2/PHASE2_PHOBERT_IMPLEMENTATION.md

# Commit
git commit -m "feat(retrieval): Implement PhoBERT reranking for Vietnamese legal documents

- Add BaseReranker abstract class
- Implement PhoBERTReranker with vinai/phobert-base-v2
- Integrate reranking into EnhancedRetriever and factory pattern
- Add comprehensive unit and integration tests
- Update config to enable reranking by default
- Performance: ~100-150ms latency for 10 docs on CPU

Closes #2-phase2-reranking"

# Push (náº¿u cáº§n)
# git push origin enhancement/1-phase1-implement
```

---

## ğŸ“Š Káº¿t Quáº£ Ká»³ Vá»ng

### **Metrics:**
- âœ… **Latency**: 100-150ms cho reranking 10 docs
- âœ… **Accuracy**: Äiá»u 14 ranked #1 cho query vá» "báº£o Ä‘áº£m dá»± tháº§u"
- âœ… **MRR improvement**: +10-15% (so vá»›i khÃ´ng reranking)
- âœ… **Test coverage**: >80% cho ranking module

### **Deliverables:**
- âœ… `src/retrieval/ranking/` folder vá»›i 3 files
- âœ… PhoBERTReranker hoáº¡t Ä‘á»™ng
- âœ… Integration vá»›i retrievers
- âœ… Unit tests + integration tests
- âœ… API endpoint test passed
- âœ… Documentation

---

## ğŸ› Troubleshooting

### **Issue 1: Model download cháº­m**
```bash
# Giáº£i phÃ¡p: Pre-download model
python -c "from sentence_transformers import CrossEncoder; CrossEncoder('vinai/phobert-base-v2')"
```

### **Issue 2: Out of Memory**
```python
# Giáº£i phÃ¡p: Giáº£m batch_size
reranker = PhoBERTReranker(batch_size=8)  # Thay vÃ¬ 16
```

### **Issue 3: Latency quÃ¡ cao (>200ms)**
```python
# Giáº£i phÃ¡p 1: Giáº£m max_length
reranker = PhoBERTReranker(max_length=128)  # Thay vÃ¬ 256

# Giáº£i phÃ¡p 2: Truncate content sá»›m hÆ¡n
content = doc.page_content[:400]  # Thay vÃ¬ 800
```

### **Issue 4: Import errors**
```bash
# Verify Python path
export PYTHONPATH=/home/sakana/Code/RAG-bidding:$PYTHONPATH
```

---

## ğŸ“š References

- [PhoBERT Paper](https://arxiv.org/abs/2003.00744)
- [sentence-transformers CrossEncoder](https://www.sbert.net/docs/pretrained_cross-encoders.html)
- [vinai/phobert-base-v2](https://huggingface.co/vinai/phobert-base-v2)

---

## âœ… Final Checklist

**TrÆ°á»›c khi káº¿t thÃºc:**
- [ ] PhoBERT model Ä‘Ã£ download vÃ  hoáº¡t Ä‘á»™ng
- [ ] Reranker test passed (Äiá»u 14 ranked #1)
- [ ] Integration test passed
- [ ] API endpoint hoáº¡t Ä‘á»™ng vá»›i reranking
- [ ] Latency < 150ms
- [ ] Code committed vá»›i message rÃµ rÃ ng
- [ ] .env updated vá»›i ENABLE_RERANKING=true

**Náº¿u cÃ²n thá»i gian (bonus):**
- [ ] ThÃªm logging chi tiáº¿t
- [ ] Benchmark vá»›i 20 queries thá»±c táº¿
- [ ] Document API changes
- [ ] Táº¡o comparison report (cÃ³/khÃ´ng reranking)

---

**Chuáº©n bá»‹ bá»Ÿi**: GitHub Copilot  
**Timeline**: 3-4 giá» (má»™t buá»•i chiá»u)  
**Äá»™ khÃ³**: Medium  
**Má»¥c tiÃªu**: âœ… PhoBERT reranking hoáº¡t Ä‘á»™ng trong quality mode

ğŸš€ **LET'S GO!**

================================================================================
DATABASE SCHEMA EXPLAINED - RAG BIDDING SYSTEM
Generated: 2025-11-24
================================================================================

⚠️ IMPORTANT CLARIFICATION ⚠️

Bảng `langchain_pg_collection` là DEPRECATED cho application logic!
Sử dụng bảng `documents` để quản lý documents thay thế.

================================================================================

=== TABLE OVERVIEW ===

┌──────────────────────────────────────────────────────────────────────┐
│                        TABLE RELATIONSHIPS                            │
├──────────────────────────────────────────────────────────────────────┤
│                                                                       │
│  documents (64 docs) ⭐ PRIMARY - Application-level management       │
│      │                                                                │
│      │ (1:N relationship via document_id in metadata)                │
│      │                                                                │
│      ▼                                                                │
│  langchain_pg_embedding (7,892 chunks) - Vector storage              │
│      │                                                                │
│      │ (FK: collection_id)                                           │
│      │                                                                │
│      ▼                                                                │
│  langchain_pg_collection (1 collection) ⚠️ INTERNAL ONLY            │
│      Collection name: "docs"                                         │
│      Purpose: LangChain internal bookkeeping                         │
│                                                                       │
└──────────────────────────────────────────────────────────────────────┘

================================================================================

=== TABLE 1: documents ⭐ PRIMARY TABLE ===

Purpose: 
  - Application-level document management
  - Track document metadata, status, classification
  - Used by API for upload/status tracking/filtering

Schema:
  CREATE TABLE documents (
    id            UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    document_id   VARCHAR(255) UNIQUE NOT NULL,
    document_name TEXT NOT NULL,
    category      VARCHAR(100) NOT NULL,
    document_type VARCHAR(50) NOT NULL,
    source_file   TEXT NOT NULL,
    file_name     TEXT NOT NULL,
    total_chunks  INTEGER DEFAULT 0,
    status        VARCHAR(50) DEFAULT 'active',
    created_at    TIMESTAMP DEFAULT now(),
    updated_at    TIMESTAMP DEFAULT now()
  );

Indexes:
  - documents_pkey: PRIMARY KEY on id
  - documents_document_id_key: UNIQUE on document_id
  - idx_documents_category: B-tree on category
  - idx_documents_type: B-tree on document_type
  - idx_documents_status: B-tree on status
  - idx_documents_source: B-tree on source_file

Triggers:
  - trigger_documents_updated_at: Auto-update updated_at on UPDATE

Current Data (64 documents):
  ┌─────────────────┬───────┐
  │ document_type   │ count │
  ├─────────────────┼───────┤
  │ bidding_form    │    37 │
  │ report_template │    10 │
  │ law             │     6 │
  │ exam_question   │     4 │
  │ circular        │     2 │
  │ decree          │     2 │
  │ bidding         │     2 │
  │ decision        │     1 │
  └─────────────────┴───────┘

Usage Examples:
  -- Get all active laws
  SELECT * FROM documents 
  WHERE document_type = 'law' AND status = 'active';

  -- Get documents by category
  SELECT document_id, document_name, total_chunks 
  FROM documents 
  WHERE category = 'legal';

  -- Update document status (triggers cache invalidation)
  UPDATE documents 
  SET status = 'expired', updated_at = now() 
  WHERE document_id = 'doc_001';

================================================================================

=== TABLE 2: langchain_pg_embedding (VECTOR STORAGE) ===

Purpose:
  - Store vector embeddings + chunk content
  - Enable semantic search via pgvector
  - Store rich metadata as JSONB

Schema:
  CREATE TABLE langchain_pg_embedding (
    id            UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    collection_id UUID REFERENCES langchain_pg_collection(uuid),
    embedding     VECTOR(3072),  -- OpenAI text-embedding-3-large
    document      TEXT,           -- Chunk content
    cmetadata     JSONB           -- Rich metadata
  );

Indexes:
  - Primary key on id
  - Vector index (IVFFlat/HNSW) on embedding for fast similarity search
  - GIN index on cmetadata for JSONB filtering

Current Data:
  - Total chunks: 7,892
  - Embedding dimensions: 3,072 (native, no reduction)
  - Database size: ~149 MB

Metadata Structure (cmetadata JSONB):
  {
    "chunk_id": "doc_001_chunk_005",         -- Unique chunk identifier
    "document_id": "doc_001",                -- Links to documents.document_id
    "document_type": "Law",                  -- Document type
    "hierarchy": "[\"Chapter 1\", \"Article 5\"]",  -- Legal structure
    "level": 2,                              -- Section depth
    "section_title": "Regulations on...",    -- Section name
    "char_count": 850,                       -- Chunk size
    "chunk_index": 5,                        -- Position in document
    "total_chunks": 45,                      -- Total chunks in doc
    "is_complete_unit": true,                -- Semantic completeness
    "has_table": false,                      -- Contains table?
    "has_list": true,                        -- Contains list?
    "extra_metadata": "{...}"                -- Additional data
  }

Usage Examples:
  -- Semantic search (handled by LangChain PGVector)
  SELECT document, cmetadata 
  FROM langchain_pg_embedding 
  ORDER BY embedding <=> '[0.1, 0.2, ...]'::vector 
  LIMIT 5;

  -- Filter by metadata + semantic search
  SELECT document, cmetadata 
  FROM langchain_pg_embedding 
  WHERE cmetadata->>'document_type' = 'law'
  ORDER BY embedding <=> query_vector 
  LIMIT 10;

  -- Get chunks for specific document
  SELECT chunk_id, section_title, document 
  FROM langchain_pg_embedding 
  WHERE cmetadata->>'document_id' = 'doc_001'
  ORDER BY (cmetadata->>'chunk_index')::int;

================================================================================

=== TABLE 3: langchain_pg_collection ⚠️ INTERNAL ONLY ===

Purpose:
  - LangChain internal bookkeeping
  - Groups embeddings into collections (namespaces)
  - DO NOT use directly in application logic

Schema:
  CREATE TABLE langchain_pg_collection (
    uuid      UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name      VARCHAR,
    cmetadata JSONB
  );

Current Data:
  - Only 1 collection: "docs"
  - Used internally by LangChain PGVector

⚠️ WARNING:
  - This table is managed by LangChain library
  - For document management, use `documents` table instead
  - Collection concept is deprecated in favor of `documents` table

Migration Note:
  - Old approach: Use langchain_pg_collection for grouping
  - New approach: Use documents table with category/type/status fields
  - Benefits: Better querying, status tracking, metadata management

================================================================================

=== RELATIONSHIP BETWEEN TABLES ===

documents.document_id <---(1:N)---> langchain_pg_embedding.cmetadata->>'document_id'

Example Query - Get document with chunks:
  SELECT 
    d.document_id,
    d.document_name,
    d.document_type,
    d.total_chunks,
    COUNT(e.id) as embedded_chunks
  FROM documents d
  LEFT JOIN langchain_pg_embedding e 
    ON d.document_id = e.cmetadata->>'document_id'
  GROUP BY d.id
  ORDER BY d.created_at DESC;

Example Query - Search with document filtering:
  -- Via LangChain PGVector with filter parameter
  vector_store.similarity_search(
    query="...",
    k=10,
    filter={"document_type": "law", "status": "active"}
  )

  -- Translates to SQL:
  SELECT e.document, e.cmetadata
  FROM langchain_pg_embedding e
  JOIN documents d ON d.document_id = e.cmetadata->>'document_id'
  WHERE d.document_type = 'law' 
    AND d.status = 'active'
  ORDER BY e.embedding <=> query_vector
  LIMIT 10;

================================================================================

=== CACHE INVALIDATION STRATEGY ===

When to clear cache:

1. Document Status Change (active → expired)
   - Update documents.status
   - Clear retrieval cache (affects visibility)
   - Trigger: UPDATE documents SET status = 'expired'

2. Document Deletion
   - Delete from documents table
   - Chunks remain in langchain_pg_embedding (orphaned)
   - Clear cache to prevent returning deleted doc chunks

3. Metadata Updates
   - Update documents.category or documents.document_type
   - Clear cache if filtering logic changed

Cache Clear API:
  POST /api/admin/clear-cache
  - Clears L1 (in-memory LRU)
  - Clears L2 (Redis)
  - L3 (PostgreSQL) updates automatically via triggers

================================================================================

=== BEST PRACTICES ===

✅ DO:
  - Use `documents` table for all document management
  - Filter queries by document.status = 'active'
  - Join documents + langchain_pg_embedding for rich queries
  - Clear cache after document status changes
  - Use indexes on documents table for fast filtering

❌ DON'T:
  - Don't modify langchain_pg_collection directly
  - Don't assume collection_id is meaningful for app logic
  - Don't forget to update documents.total_chunks when adding/removing chunks
  - Don't skip cache invalidation after metadata changes

Performance Tips:
  - Index on documents.status for active/expired filtering
  - Index on documents.document_type for type filtering
  - Use JSONB indexes on langchain_pg_embedding.cmetadata for metadata filtering
  - Consider HNSW index for faster vector search (>10k chunks)

================================================================================

=== MIGRATION FROM OLD SCHEMA ===

Old Approach (Deprecated):
  - Use langchain_pg_collection for grouping
  - Limited metadata in collection table
  - No status tracking, no rich filtering

New Approach (Current):
  - Use documents table as primary source of truth
  - Rich metadata + status tracking + full CRUD
  - Better API support, better filtering, better caching

Migration Steps:
  1. Create documents table
  2. Populate from existing chunks metadata
  3. Update API to use documents table
  4. Keep langchain_pg_collection for LangChain compatibility
  5. Clear old caches

================================================================================
END OF SCHEMA EXPLANATION
================================================================================

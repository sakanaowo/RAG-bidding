#!/usr/bin/env python3
"""
Comprehensive Evaluation of Semantic Cache V2 (Hybrid Cosine + BGE)

Uses all 38 test pairs from semantic_threshold_analysis.py to evaluate:
1. Accuracy: Does V2 correctly identify similar vs different queries?
2. Precision: How many "matches" are actually similar queries?
3. Recall: How many similar queries are correctly matched?
4. Speed: What's the average latency?

Usage:
    PYTHONPATH=/home/sakana/Code/RAG-project/RAG-bidding python scripts/analysis/evaluate_semantic_cache_v2.py
"""

import sys
import time
from dataclasses import dataclass
from typing import List, Tuple, Optional

sys.path.insert(0, "/home/sakana/Code/RAG-project/RAG-bidding")

from src.retrieval.semantic_cache_v2 import (
    get_semantic_cache_v2,
    reset_semantic_cache_v2,
)


# =============================================================================
# Test Data (38 pairs from semantic_threshold_analysis.py)
# =============================================================================


@dataclass
class TestPair:
    q1: str
    q2: str
    category: str  # "similar", "different", "identical"

    @property
    def should_match(self) -> bool:
        return self.category in ("similar", "identical")


TEST_PAIRS: List[TestPair] = [
    # === SIMILAR PAIRS (should match) ===
    TestPair(
        "Y√™u c·∫ßu v·ªÅ nƒÉng l·ª±c t√†i ch√≠nh c·ªßa nh√† th·∫ßu g·ªìm nh·ªØng g√¨",
        "ƒêi·ªÅu ki·ªán v·ªÅ nƒÉng l·ª±c t√†i ch√≠nh khi tham gia ƒë·∫•u th·∫ßu y√™u c·∫ßu g√¨",
        "similar",
    ),
    TestPair(
        "H·ªì s∆° m·ªùi th·∫ßu bao g·ªìm nh·ªØng n·ªôi dung g√¨",
        "Th√†nh ph·∫ßn c·ªßa h·ªì s∆° m·ªùi th·∫ßu g·ªìm nh·ªØng g√¨",
        "similar",
    ),
    TestPair(
        "Th·ªùi gian n·ªôp h·ªì s∆° d·ª± th·∫ßu l√† bao l√¢u",
        "Nh√† th·∫ßu c√≥ bao nhi√™u ng√†y ƒë·ªÉ n·ªôp h·ªì s∆°",
        "similar",
    ),
    TestPair(
        "Quy ƒë·ªãnh v·ªÅ b·∫£o l√£nh d·ª± th·∫ßu nh∆∞ th·∫ø n√†o",
        "Y√™u c·∫ßu b·∫£o ƒë·∫£m d·ª± th·∫ßu theo quy ƒë·ªãnh l√† g√¨",
        "similar",
    ),
    TestPair(
        "Ti√™u ch√≠ ƒë√°nh gi√° h·ªì s∆° d·ª± th·∫ßu g·ªìm nh·ªØng g√¨",
        "C√°c ti√™u chu·∫©n ƒë·ªÉ ch·∫•m ƒëi·ªÉm h·ªì s∆° th·∫ßu",
        "similar",
    ),
    TestPair(
        "Y√™u c·∫ßu v·ªÅ nƒÉng l·ª±c kinh nghi·ªám c·ªßa nh√† th·∫ßu",
        "Nh√† th·∫ßu c·∫ßn c√≥ kinh nghi·ªám g√¨ ƒë·ªÉ tham gia ƒë·∫•u th·∫ßu",
        "similar",
    ),
    TestPair(
        "C√°c lo·∫°i h·ª£p ƒë·ªìng trong ƒë·∫•u th·∫ßu",
        "Ph√¢n lo·∫°i h·ª£p ƒë·ªìng ƒë·∫•u th·∫ßu theo quy ƒë·ªãnh",
        "similar",
    ),
    TestPair(
        "C√°ch t√≠nh gi√° d·ª± th·∫ßu nh∆∞ th·∫ø n√†o",
        "Ph∆∞∆°ng ph√°p x√°c ƒë·ªãnh gi√° trong h·ªì s∆° d·ª± th·∫ßu",
        "similar",
    ),
    TestPair(
        "Quy tr√¨nh m·ªü th·∫ßu di·ªÖn ra nh∆∞ th·∫ø n√†o",
        "C√°c b∆∞·ªõc trong bu·ªïi m·ªü h·ªì s∆° d·ª± th·∫ßu",
        "similar",
    ),
    TestPair(
        "Quy ƒë·ªãnh v·ªÅ s·ª≠ d·ª•ng nh√† th·∫ßu ph·ª•",
        "Nh√† th·∫ßu ph·ª• ƒë∆∞·ª£c s·ª≠ d·ª•ng trong tr∆∞·ªùng h·ª£p n√†o",
        "similar",
    ),
    TestPair(
        "Quy tr√¨nh khi·∫øu n·∫°i k·∫øt qu·∫£ ƒë·∫•u th·∫ßu",
        "C√°ch th·ª©c gi·∫£i quy·∫øt tranh ch·∫•p trong ƒë·∫•u th·∫ßu",
        "similar",
    ),
    TestPair(
        "Tr∆∞·ªùng h·ª£p n√†o ph·∫£i h·ªßy th·∫ßu", "ƒêi·ªÅu ki·ªán h·ªßy b·ªè cu·ªôc ƒë·∫•u th·∫ßu", "similar"
    ),
    TestPair(
        "ƒêi·ªÅu ki·ªán tham gia ƒë·∫•u th·∫ßu", "Y√™u c·∫ßu ƒë·ªÉ ƒë∆∞·ª£c tham d·ª± ƒë·∫•u th·∫ßu", "similar"
    ),
    TestPair(
        "Nh√† th·∫ßu c·∫ßn ƒë√°p ·ª©ng ƒëi·ªÅu ki·ªán g√¨",
        "Y√™u c·∫ßu ƒë·ªëi v·ªõi nh√† th·∫ßu khi tham gia",
        "similar",
    ),
    TestPair(
        "B·∫£o l√£nh th·ª±c hi·ªán h·ª£p ƒë·ªìng l√† bao nhi√™u ph·∫ßn trƒÉm",
        "T·ª∑ l·ªá b·∫£o ƒë·∫£m th·ª±c hi·ªán h·ª£p ƒë·ªìng theo quy ƒë·ªãnh",
        "similar",
    ),
    TestPair(
        "C√≥ bao nhi√™u h√¨nh th·ª©c l·ª±a ch·ªçn nh√† th·∫ßu theo lu·∫≠t m·ªõi",
        "C√°c ph∆∞∆°ng th·ª©c tuy·ªÉn ch·ªçn nh√† th·∫ßu hi·ªán nay bao g·ªìm nh·ªØng g√¨",
        "similar",
    ),
    TestPair(
        "Tr∆∞·ªùng h·ª£p n√†o ƒë∆∞·ª£c ph√©p √°p d·ª•ng ch·ªâ ƒë·ªãnh th·∫ßu",
        "ƒêi·ªÅu ki·ªán ƒë·ªÉ th·ª±c hi·ªán ch·ªâ ƒë·ªãnh th·∫ßu tr·ª±c ti·∫øp l√† g√¨",
        "similar",
    ),
    TestPair(
        "Quy tr√¨nh th·ª±c hi·ªán ƒë·∫•u th·∫ßu qua m·∫°ng nh∆∞ th·∫ø n√†o",
        "C√°c b∆∞·ªõc ƒë·∫•u th·∫ßu tr√™n H·ªá th·ªëng m·∫°ng ƒë·∫•u th·∫ßu qu·ªëc gia",
        "similar",
    ),
    TestPair(
        "ƒê·ªëi t∆∞·ª£ng n√†o ƒë∆∞·ª£c h∆∞·ªüng ∆∞u ƒë√£i trong l·ª±a ch·ªçn nh√† th·∫ßu",
        "Quy ƒë·ªãnh v·ªÅ vi·ªác ∆∞u ti√™n cho h√†ng h√≥a s·∫£n xu·∫•t trong n∆∞·ªõc",
        "similar",
    ),
    TestPair(
        "Ti√™u chu·∫©n ƒë·ªëi v·ªõi th√†nh vi√™n t·ªï chuy√™n gia ƒë·∫•u th·∫ßu",
        "Quy ƒë·ªãnh v·ªÅ nƒÉng l·ª±c v√† ch·ª©ng ch·ªâ c·ªßa ng∆∞·ªùi ch·∫•m th·∫ßu",
        "similar",
    ),
    TestPair(
        "Khi n√†o ƒë∆∞·ª£c ph√©p ƒëi·ªÅu ch·ªânh gi√° h·ª£p ƒë·ªìng ƒë·∫•u th·∫ßu",
        "Quy ƒë·ªãnh v·ªÅ vi·ªác thay ƒë·ªïi ƒë∆°n gi√° trong h·ª£p ƒë·ªìng",
        "similar",
    ),
    TestPair(
        "Quy tr√¨nh ch√†o h√†ng c·∫°nh tranh r√∫t g·ªçn th·ª±c hi·ªán nh∆∞ th·∫ø n√†o",
        "C√°c b∆∞·ªõc l√†m ch√†o h√†ng c·∫°nh tranh cho g√≥i mua s·∫Øm h√†ng h√≥a",
        "similar",
    ),
    TestPair(
        "Nh·ªØng h√†nh vi n√†o b·ªã nghi√™m c·∫•m trong ƒë·∫•u th·∫ßu",
        "C√°c l·ªói vi ph·∫°m d·∫´n ƒë·∫øn b·ªã c·∫•m tham gia ho·∫°t ƒë·ªông ƒë·∫•u th·∫ßu",
        "similar",
    ),
    TestPair(
        "Hi·ªáu l·ª±c c·ªßa h·ªì s∆° d·ª± th·∫ßu ƒë∆∞·ª£c quy ƒë·ªãnh l√† bao nhi√™u ng√†y",
        "Th·ªùi gian b·∫£o ƒë·∫£m gi√° tr·ªã c·ªßa h·ªì s∆° th·∫ßu t√≠nh t·ª´ th·ªùi ƒëi·ªÉm n√†o",
        "similar",
    ),
    TestPair(
        "Quy tr√¨nh gi·∫£i quy·∫øt ki·∫øn ngh·ªã trong ƒë·∫•u th·∫ßu",
        "C√°c b∆∞·ªõc khi nh√† th·∫ßu mu·ªën khi·∫øu n·∫°i v·ªÅ k·∫øt qu·∫£ l·ª±a ch·ªçn nh√† th·∫ßu",
        "similar",
    ),
    TestPair(
        "T∆∞ c√°ch h·ª£p l·ªá c·ªßa nh√† th·∫ßu",
        "ƒêi·ªÅu ki·ªán ƒë·ªÉ doanh nghi·ªáp kh√¥ng b·ªã lo·∫°i khi x√©t duy·ªát ph√°p l√Ω",
        "similar",
    ),
    TestPair(
        "H∆∞·ªõng d·∫´n n·ªôp E-HSDT tr√™n h·ªá th·ªëng",
        "C√°ch th·ª©c g·ª≠i h·ªì s∆° d·ª± th·∫ßu qua m·∫°ng",
        "similar",
    ),
    TestPair(
        "Ch·ª©ng minh nƒÉng l·ª±c t√†i ch√≠nh",
        "Cung c·∫•p b√°o c√°o t√†i ch√≠nh ki·ªÉm to√°n trong 3 nƒÉm g·∫ßn nh·∫•t",
        "similar",
    ),
    TestPair(
        "Ai l√† ng∆∞·ªùi c√≥ th·∫©m quy·ªÅn quy·∫øt ƒë·ªãnh h·ªßy th·∫ßu",
        "Vi·ªác h·ªßy th·∫ßu do c·∫•p n√†o c√≥ th·∫©m quy·ªÅn ph√™ duy·ªát",
        "similar",
    ),
    # === IDENTICAL PAIR (baseline) ===
    TestPair(
        "Y√™u c·∫ßu v·ªÅ nƒÉng l·ª±c t√†i ch√≠nh c·ªßa nh√† th·∫ßu g·ªìm nh·ªØng g√¨",
        "Y√™u c·∫ßu v·ªÅ nƒÉng l·ª±c t√†i ch√≠nh c·ªßa nh√† th·∫ßu g·ªìm nh·ªØng g√¨",
        "identical",
    ),
    # === DIFFERENT TOPIC PAIRS (should NOT match) ===
    TestPair(
        "Y√™u c·∫ßu v·ªÅ nƒÉng l·ª±c t√†i ch√≠nh c·ªßa nh√† th·∫ßu",
        "Quy tr√¨nh m·ªü th·∫ßu di·ªÖn ra nh∆∞ th·∫ø n√†o",
        "different",
    ),
    TestPair(
        "ƒêi·ªÅu ki·ªán tham gia ƒë·∫•u th·∫ßu", "Quy ƒë·ªãnh v·ªÅ b·∫£o h√†nh c√¥ng tr√¨nh", "different"
    ),
    TestPair(
        "Quy ƒë·ªãnh v·ªÅ b·∫£o ƒë·∫£m d·ª± th·∫ßu",
        "Quy ƒë·ªãnh v·ªÅ b·∫£o ƒë·∫£m th·ª±c hi·ªán h·ª£p ƒë·ªìng",
        "different",
    ),
    TestPair(
        "N·ªôi dung ch√≠nh c·ªßa h·ªì s∆° m·ªùi th·∫ßu (HSMT)",
        "N·ªôi dung ch√≠nh c·ªßa h·ªì s∆° d·ª± th·∫ßu (HSDT)",
        "different",
    ),
    TestPair(
        "C√°c tr∆∞·ªùng h·ª£p ƒë∆∞·ª£c ph√©p ch·ªâ ƒë·ªãnh th·∫ßu",
        "C√°c tr∆∞·ªùng h·ª£p kh√¥ng ƒë∆∞·ª£c ph√©p ch·ªâ ƒë·ªãnh th·∫ßu",
        "different",
    ),
    TestPair(
        "Th·ªùi gian c√≥ hi·ªáu l·ª±c l√† 90 ng√†y",
        "Th·ªùi gian c√≥ hi·ªáu l·ª±c l√† 120 ng√†y",
        "different",
    ),
    TestPair(
        "Tr√°ch nhi·ªám c·ªßa nh√† th·∫ßu ch√≠nh trong g√≥i th·∫ßu",
        "Quy ƒë·ªãnh v·ªÅ ph·∫ßn vi·ªác c·ªßa nh√† th·∫ßu ph·ª•",
        "different",
    ),
    TestPair("Ph∆∞∆°ng ph√°p gi√° th·∫•p nh·∫•t", "Ph∆∞∆°ng ph√°p gi√° ƒë√°nh gi√°", "different"),
]


# =============================================================================
# Evaluation Functions
# =============================================================================


@dataclass
class EvalResult:
    pair: TestPair
    matched: bool
    bge_score: Optional[float]
    cosine_score: Optional[float]
    latency_ms: float
    correct: bool  # True if prediction matches expected


def evaluate_pair(cache, pair: TestPair) -> EvalResult:
    """Evaluate a single test pair."""
    # Store q1 first
    cache.store_embedding(query=pair.q1, answer_cache_key=f"eval:{hash(pair.q1)}")

    # Small delay for Redis
    time.sleep(0.05)

    # Search with q2
    start = time.time()
    match = cache.find_similar(pair.q2)
    latency_ms = (time.time() - start) * 1000

    matched = match is not None
    bge_score = match.bge_score if match else None
    cosine_score = match.cosine_similarity if match else None

    # Determine if prediction is correct
    if pair.should_match:
        correct = matched  # Should match -> matched = correct
    else:
        correct = not matched  # Should NOT match -> not matched = correct

    return EvalResult(
        pair=pair,
        matched=matched,
        bge_score=bge_score,
        cosine_score=cosine_score,
        latency_ms=latency_ms,
        correct=correct,
    )


def run_evaluation(bge_threshold: float = 0.85, verbose: bool = True):
    """Run full evaluation on all test pairs."""
    if verbose:
        print("=" * 80)
        print("SEMANTIC CACHE V2 COMPREHENSIVE EVALUATION")
        print("=" * 80)
        print()

    # Initialize cache
    reset_semantic_cache_v2()
    cache = get_semantic_cache_v2()

    # Override BGE threshold for testing
    cache.bge_threshold = bge_threshold

    if not cache.enabled:
        print("‚ùå Semantic cache is disabled!")
        return None

    if verbose:
        print(f"Cache Config:")
        print(f"  - Cosine pre-filter threshold: {cache.cosine_threshold}")
        print(f"  - Cosine top-k: {cache.cosine_top_k}")
        print(f"  - BGE rerank threshold: {cache.bge_threshold}")
        print()

    # Clear cache before evaluation
    cache.clear_all()

    # Run evaluation
    results: List[EvalResult] = []

    if verbose:
        print("Running evaluation on 38 test pairs...")
        print("-" * 80)

    for i, pair in enumerate(TEST_PAIRS, 1):
        # Clear cache between pairs to ensure isolation
        cache.clear_all()

        result = evaluate_pair(cache, pair)
        results.append(result)

        if verbose:
            # Print result
            status = "‚úÖ" if result.correct else "‚ùå"
            match_str = (
                f"MATCH (bge={result.bge_score:.4f})" if result.matched else "NO MATCH"
            )
            expected = "should match" if pair.should_match else "should NOT match"

            print(
                f"Pair {i:2d} [{pair.category.upper():9s}] {status} {match_str:30s} ({expected})"
            )
            if not result.correct:
                print(f"         Q1: {pair.q1[:60]}...")
                print(f"         Q2: {pair.q2[:60]}...")

    # Calculate metrics
    if verbose:
        print()
        print("=" * 80)
        print("EVALUATION RESULTS")
        print("=" * 80)

    # Overall accuracy
    correct_count = sum(1 for r in results if r.correct)
    total_count = len(results)
    accuracy = correct_count / total_count * 100

    if verbose:
        print(f"\nüìä OVERALL ACCURACY: {correct_count}/{total_count} = {accuracy:.1f}%")

    # By category
    similar_results = [r for r in results if r.pair.category == "similar"]
    different_results = [r for r in results if r.pair.category == "different"]
    identical_results = [r for r in results if r.pair.category == "identical"]

    # Recall (for similar + identical)
    similar_correct = sum(1 for r in similar_results if r.correct)
    identical_correct = sum(1 for r in identical_results if r.correct)
    recall = (
        (similar_correct + identical_correct)
        / (len(similar_results) + len(identical_results))
        * 100
    )

    if verbose:
        print(f"\nüìä SIMILAR QUERIES (Recall):")
        print(
            f"   - Similar matched: {similar_correct}/{len(similar_results)} = {similar_correct/len(similar_results)*100:.1f}%"
        )
        print(
            f"   - Identical matched: {identical_correct}/{len(identical_results)} = {identical_correct/len(identical_results)*100:.1f}%"
        )
        print(f"   - Total recall: {recall:.1f}%")

    # Precision (for different topics - should NOT match)
    different_correct = sum(1 for r in different_results if r.correct)
    false_positive_rate = (
        (len(different_results) - different_correct) / len(different_results) * 100
    )

    if verbose:
        print(f"\nüìä DIFFERENT TOPICS (Precision):")
        print(
            f"   - Correctly rejected: {different_correct}/{len(different_results)} = {different_correct/len(different_results)*100:.1f}%"
        )
        print(f"   - False positive rate: {false_positive_rate:.1f}%")

    # Speed stats
    latencies = [r.latency_ms for r in results]
    avg_latency = sum(latencies) / len(latencies)
    max_latency = max(latencies)
    min_latency = min(latencies)

    if verbose:
        print(f"\nüìä SPEED:")
        print(f"   - Average latency: {avg_latency:.1f}ms")
        print(f"   - Min latency: {min_latency:.1f}ms")
        print(f"   - Max latency: {max_latency:.1f}ms")

    # BGE score distribution for matches
    bge_scores = [r.bge_score for r in results if r.bge_score is not None]
    if bge_scores:
        if verbose:
            print(f"\nüìä BGE SCORE DISTRIBUTION (for matches):")
            print(f"   - Min: {min(bge_scores):.4f}")
            print(f"   - Max: {max(bge_scores):.4f}")
            print(f"   - Mean: {sum(bge_scores)/len(bge_scores):.4f}")

    # Show failed cases
    failed = [r for r in results if not r.correct]
    if verbose:
        if failed:
            print(f"\n‚ö†Ô∏è FAILED CASES ({len(failed)}):")
            for r in failed:
                expected = "should match" if r.pair.should_match else "should NOT match"
                got = f"MATCHED (bge={r.bge_score:.4f})" if r.matched else "NO MATCH"
                print(f"   - [{r.pair.category}] {expected} but got {got}")
                print(f"     Q1: {r.pair.q1[:50]}...")
                print(f"     Q2: {r.pair.q2[:50]}...")
        else:
            print(f"\nüéâ ALL TEST CASES PASSED!")

    # Cleanup
    cache.clear_all()

    # Final summary
    if verbose:
        print()
        print("=" * 80)
        print("SUMMARY")
        print("=" * 80)
        print(
            f"""
  Semantic Cache V2 (Hybrid Cosine + BGE) Evaluation:
  
  ‚úÖ Accuracy:     {accuracy:.1f}% ({correct_count}/{total_count})
  ‚úÖ Recall:       {recall:.1f}% (similar queries correctly matched)
  ‚úÖ Precision:    {100-false_positive_rate:.1f}% (different topics correctly rejected)
  ‚úÖ Avg Latency:  {avg_latency:.1f}ms
  
  Config: cosine_threshold={cache.cosine_threshold}, bge_threshold={cache.bge_threshold}
"""
        )

    return {
        "accuracy": accuracy,
        "recall": recall,
        "precision": 100 - false_positive_rate,
        "avg_latency_ms": avg_latency,
        "failed_count": len(failed),
        "bge_threshold": bge_threshold,
    }


def run_threshold_sweep():
    """Test multiple BGE thresholds to find optimal."""
    print("=" * 80)
    print("BGE THRESHOLD SWEEP ANALYSIS")
    print("=" * 80)
    print()

    thresholds = [0.95, 0.90, 0.85, 0.80, 0.75, 0.70, 0.65, 0.60, 0.55, 0.50]
    results = []

    for threshold in thresholds:
        print(f"Testing BGE threshold = {threshold}...", end=" ", flush=True)
        result = run_evaluation(bge_threshold=threshold, verbose=False)
        if result:
            results.append(result)
            print(
                f"Accuracy={result['accuracy']:.1f}%, Recall={result['recall']:.1f}%, Precision={result['precision']:.1f}%"
            )

    print()
    print("=" * 80)
    print("THRESHOLD COMPARISON")
    print("=" * 80)
    print()
    print(
        f"{'Threshold':<10} {'Accuracy':<12} {'Recall':<12} {'Precision':<12} {'Failed':<8}"
    )
    print("-" * 60)

    best_accuracy = 0
    best_threshold = 0.85

    for r in results:
        print(
            f"{r['bge_threshold']:<10.2f} {r['accuracy']:<12.1f} {r['recall']:<12.1f} {r['precision']:<12.1f} {r['failed_count']:<8}"
        )
        if r["accuracy"] > best_accuracy:
            best_accuracy = r["accuracy"]
            best_threshold = r["bge_threshold"]

    print()
    print(f"üéØ BEST THRESHOLD: {best_threshold} (Accuracy: {best_accuracy:.1f}%)")
    print()

    return best_threshold


if __name__ == "__main__":
    import sys

    if len(sys.argv) > 1 and sys.argv[1] == "--sweep":
        # Run threshold sweep
        best = run_threshold_sweep()
        print(f"\nRe-running with best threshold ({best})...")
        run_evaluation(bge_threshold=best, verbose=True)
    else:
        # Default: run single evaluation
        run_evaluation()

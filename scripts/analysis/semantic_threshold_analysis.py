"""
Semantic Similarity Threshold Analysis Script

This script tests multiple pairs of semantically similar questions
to determine the optimal threshold for the semantic cache.

Usage:
    cd RAG-bidding
    source .venv/bin/activate
    python scripts/analysis/semantic_threshold_analysis.py
"""

import numpy as np
from src.embedding.embedders.openai_embedder import OpenAIEmbedder


def cosine_similarity(a: np.ndarray, b: np.ndarray) -> float:
    """Compute cosine similarity between two vectors."""
    return float(np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b)))


def main():
    embedder = OpenAIEmbedder()

    # Test cases: pairs of semantically similar questions about bidding law
    test_pairs = [
        # =====================================================================
        # SIMILAR PAIRS (should match with semantic cache)
        # =====================================================================
        # Pair 1 - NƒÉng l·ª±c t√†i ch√≠nh (original case)
        (
            "Y√™u c·∫ßu v·ªÅ nƒÉng l·ª±c t√†i ch√≠nh c·ªßa nh√† th·∫ßu g·ªìm nh·ªØng g√¨",
            "ƒêi·ªÅu ki·ªán v·ªÅ nƒÉng l·ª±c t√†i ch√≠nh khi tham gia ƒë·∫•u th·∫ßu y√™u c·∫ßu nh·ªØng g√¨",
            "similar",
        ),
        # Pair 2 - H·ªì s∆° m·ªùi th·∫ßu
        (
            "H·ªì s∆° m·ªùi th·∫ßu bao g·ªìm nh·ªØng n·ªôi dung g√¨",
            "Th√†nh ph·∫ßn c·ªßa h·ªì s∆° m·ªùi th·∫ßu g·ªìm nh·ªØng g√¨",
            "similar",
        ),
        # Pair 3 - Th·ªùi gian ƒë·∫•u th·∫ßu
        (
            "Th·ªùi gian n·ªôp h·ªì s∆° d·ª± th·∫ßu l√† bao l√¢u",
            "Nh√† th·∫ßu c√≥ bao nhi√™u ng√†y ƒë·ªÉ n·ªôp h·ªì s∆°",
            "similar",
        ),
        # Pair 4 - B·∫£o l√£nh d·ª± th·∫ßu
        (
            "Quy ƒë·ªãnh v·ªÅ b·∫£o l√£nh d·ª± th·∫ßu nh∆∞ th·∫ø n√†o",
            "Y√™u c·∫ßu b·∫£o ƒë·∫£m d·ª± th·∫ßu theo quy ƒë·ªãnh l√† g√¨",
            "similar",
        ),
        # Pair 5 - ƒê√°nh gi√° h·ªì s∆°
        (
            "Ti√™u ch√≠ ƒë√°nh gi√° h·ªì s∆° d·ª± th·∫ßu g·ªìm nh·ªØng g√¨",
            "C√°c ti√™u chu·∫©n ƒë·ªÉ ch·∫•m ƒëi·ªÉm h·ªì s∆° th·∫ßu",
            "similar",
        ),
        # Pair 6 - NƒÉng l·ª±c kinh nghi·ªám
        (
            "Y√™u c·∫ßu v·ªÅ nƒÉng l·ª±c kinh nghi·ªám c·ªßa nh√† th·∫ßu",
            "Nh√† th·∫ßu c·∫ßn c√≥ kinh nghi·ªám g√¨ ƒë·ªÉ tham gia ƒë·∫•u th·∫ßu",
            "similar",
        ),
        # Pair 7 - H·ª£p ƒë·ªìng
        (
            "C√°c lo·∫°i h·ª£p ƒë·ªìng trong ƒë·∫•u th·∫ßu",
            "Ph√¢n lo·∫°i h·ª£p ƒë·ªìng ƒë·∫•u th·∫ßu theo quy ƒë·ªãnh",
            "similar",
        ),
        # Pair 8 - Gi√° d·ª± th·∫ßu
        (
            "C√°ch t√≠nh gi√° d·ª± th·∫ßu nh∆∞ th·∫ø n√†o",
            "Ph∆∞∆°ng ph√°p x√°c ƒë·ªãnh gi√° trong h·ªì s∆° d·ª± th·∫ßu",
            "similar",
        ),
        # Pair 9 - M·ªü th·∫ßu
        (
            "Quy tr√¨nh m·ªü th·∫ßu di·ªÖn ra nh∆∞ th·∫ø n√†o",
            "C√°c b∆∞·ªõc trong bu·ªïi m·ªü h·ªì s∆° d·ª± th·∫ßu",
            "similar",
        ),
        # Pair 10 - Nh√† th·∫ßu ph·ª•
        (
            "Quy ƒë·ªãnh v·ªÅ s·ª≠ d·ª•ng nh√† th·∫ßu ph·ª•",
            "Nh√† th·∫ßu ph·ª• ƒë∆∞·ª£c s·ª≠ d·ª•ng trong tr∆∞·ªùng h·ª£p n√†o",
            "similar",
        ),
        # Pair 11 - Khi·∫øu n·∫°i
        (
            "Quy tr√¨nh khi·∫øu n·∫°i k·∫øt qu·∫£ ƒë·∫•u th·∫ßu",
            "C√°ch th·ª©c gi·∫£i quy·∫øt tranh ch·∫•p trong ƒë·∫•u th·∫ßu",
            "similar",
        ),
        # Pair 12 - H·ªßy th·∫ßu
        ("Tr∆∞·ªùng h·ª£p n√†o ph·∫£i h·ªßy th·∫ßu", "ƒêi·ªÅu ki·ªán h·ªßy b·ªè cu·ªôc ƒë·∫•u th·∫ßu", "similar"),
        # =====================================================================
        # DIFFERENT TOPIC PAIRS (should NOT match)
        # =====================================================================
        # Pair 13 - Different topics
        (
            "Y√™u c·∫ßu v·ªÅ nƒÉng l·ª±c t√†i ch√≠nh c·ªßa nh√† th·∫ßu",
            "Quy tr√¨nh m·ªü th·∫ßu di·ªÖn ra nh∆∞ th·∫ø n√†o",
            "different",
        ),
        # Pair 14 - Very different topics
        ("ƒêi·ªÅu ki·ªán tham gia ƒë·∫•u th·∫ßu", "Quy ƒë·ªãnh v·ªÅ b·∫£o h√†nh c√¥ng tr√¨nh", "different"),
        # =====================================================================
        # IDENTICAL PAIRS (should always match - baseline)
        # =====================================================================
        # Pair 15 - Identical
        (
            "Y√™u c·∫ßu v·ªÅ nƒÉng l·ª±c t√†i ch√≠nh c·ªßa nh√† th·∫ßu g·ªìm nh·ªØng g√¨",
            "Y√™u c·∫ßu v·ªÅ nƒÉng l·ª±c t√†i ch√≠nh c·ªßa nh√† th·∫ßu g·ªìm nh·ªØng g√¨",
            "identical",
        ),
        # =====================================================================
        # SLIGHTLY DIFFERENT WORDING (edge cases)
        # =====================================================================
        # Pair 16
        ("ƒêi·ªÅu ki·ªán tham gia ƒë·∫•u th·∫ßu", "Y√™u c·∫ßu ƒë·ªÉ ƒë∆∞·ª£c tham d·ª± ƒë·∫•u th·∫ßu", "similar"),
        # Pair 17 - Synonym usage
        (
            "Nh√† th·∫ßu c·∫ßn ƒë√°p ·ª©ng ƒëi·ªÅu ki·ªán g√¨",
            "Y√™u c·∫ßu ƒë·ªëi v·ªõi nh√† th·∫ßu khi tham gia",
            "similar",
        ),
        # Pair 18 - Question form variation
        (
            "B·∫£o l√£nh th·ª±c hi·ªán h·ª£p ƒë·ªìng l√† bao nhi√™u ph·∫ßn trƒÉm",
            "T·ª∑ l·ªá b·∫£o ƒë·∫£m th·ª±c hi·ªán h·ª£p ƒë·ªìng theo quy ƒë·ªãnh",
            "similar",
        ),
        (
            "C√≥ bao nhi√™u h√¨nh th·ª©c l·ª±a ch·ªçn nh√† th·∫ßu theo lu·∫≠t m·ªõi",
            "C√°c ph∆∞∆°ng th·ª©c tuy·ªÉn ch·ªçn nh√† th·∫ßu hi·ªán nay bao g·ªìm nh·ªØng g√¨",
            "similar",
        ),
        # Pair 20 - Ch·ªâ ƒë·ªãnh th·∫ßu (Tr∆∞·ªùng h·ª£p √°p d·ª•ng)
        (
            "Tr∆∞·ªùng h·ª£p n√†o ƒë∆∞·ª£c ph√©p √°p d·ª•ng ch·ªâ ƒë·ªãnh th·∫ßu",
            "ƒêi·ªÅu ki·ªán ƒë·ªÉ th·ª±c hi·ªán ch·ªâ ƒë·ªãnh th·∫ßu tr·ª±c ti·∫øp l√† g√¨",
            "similar",
        ),
        # Pair 21 - ƒê·∫•u th·∫ßu qua m·∫°ng
        (
            "Quy tr√¨nh th·ª±c hi·ªán ƒë·∫•u th·∫ßu qua m·∫°ng nh∆∞ th·∫ø n√†o",
            "C√°c b∆∞·ªõc ƒë·∫•u th·∫ßu tr√™n H·ªá th·ªëng m·∫°ng ƒë·∫•u th·∫ßu qu·ªëc gia",
            "similar",
        ),
        # Pair 22 - ∆Øu ƒë√£i trong ƒë·∫•u th·∫ßu
        (
            "ƒê·ªëi t∆∞·ª£ng n√†o ƒë∆∞·ª£c h∆∞·ªüng ∆∞u ƒë√£i trong l·ª±a ch·ªçn nh√† th·∫ßu",
            "Quy ƒë·ªãnh v·ªÅ vi·ªác ∆∞u ti√™n cho h√†ng h√≥a s·∫£n xu·∫•t trong n∆∞·ªõc",
            "similar",
        ),
        # Pair 23 - T·ªï chuy√™n gia
        (
            "Ti√™u chu·∫©n ƒë·ªëi v·ªõi th√†nh vi√™n t·ªï chuy√™n gia ƒë·∫•u th·∫ßu",
            "Quy ƒë·ªãnh v·ªÅ nƒÉng l·ª±c v√† ch·ª©ng ch·ªâ c·ªßa ng∆∞·ªùi ch·∫•m th·∫ßu",
            "similar",
        ),
        # Pair 24 - ƒêi·ªÅu ch·ªânh h·ª£p ƒë·ªìng
        (
            "Khi n√†o ƒë∆∞·ª£c ph√©p ƒëi·ªÅu ch·ªânh gi√° h·ª£p ƒë·ªìng ƒë·∫•u th·∫ßu",
            "Quy ƒë·ªãnh v·ªÅ vi·ªác thay ƒë·ªïi ƒë∆°n gi√° trong h·ª£p ƒë·ªìng",
            "similar",
        ),
        # Pair 25 - Ch√†o h√†ng c·∫°nh tranh
        (
            "Quy tr√¨nh ch√†o h√†ng c·∫°nh tranh r√∫t g·ªçn th·ª±c hi·ªán nh∆∞ th·∫ø n√†o",
            "C√°c b∆∞·ªõc l√†m ch√†o h√†ng c·∫°nh tranh cho g√≥i mua s·∫Øm h√†ng h√≥a",
            "similar",
        ),
        # Pair 26 - C√°c h√†nh vi b·ªã c·∫•m
        (
            "Nh·ªØng h√†nh vi n√†o b·ªã nghi√™m c·∫•m trong ƒë·∫•u th·∫ßu",
            "C√°c l·ªói vi ph·∫°m d·∫´n ƒë·∫øn b·ªã c·∫•m tham gia ho·∫°t ƒë·ªông ƒë·∫•u th·∫ßu",
            "similar",
        ),
        # Pair 27 - Th·ªùi gian c√≥ hi·ªáu l·ª±c c·ªßa h·ªì s∆°
        (
            "Hi·ªáu l·ª±c c·ªßa h·ªì s∆° d·ª± th·∫ßu ƒë∆∞·ª£c quy ƒë·ªãnh l√† bao nhi√™u ng√†y",
            "Th·ªùi gian b·∫£o ƒë·∫£m gi√° tr·ªã c·ªßa h·ªì s∆° th·∫ßu t√≠nh t·ª´ th·ªùi ƒëi·ªÉm n√†o",
            "similar",
        ),
        # Pair 28 - Gi·∫£i quy·∫øt ki·∫øn ngh·ªã
        (
            "Quy tr√¨nh gi·∫£i quy·∫øt ki·∫øn ngh·ªã trong ƒë·∫•u th·∫ßu",
            "C√°c b∆∞·ªõc khi nh√† th·∫ßu mu·ªën khi·∫øu n·∫°i v·ªÅ k·∫øt qu·∫£ l·ª±a ch·ªçn nh√† th·∫ßu",
            "similar",
        ),
        # Pair 29 - C√πng t·ª´ kh√≥a nh∆∞ng ƒë·ªëi t∆∞·ª£ng kh√°c nhau (DIFFERENT)
        (
            "Quy ƒë·ªãnh v·ªÅ b·∫£o ƒë·∫£m d·ª± th·∫ßu",
            "Quy ƒë·ªãnh v·ªÅ b·∫£o ƒë·∫£m th·ª±c hi·ªán h·ª£p ƒë·ªìng",
            "different",
        ),
        # Pair 30 - C√πng t·ª´ kh√≥a nh∆∞ng giai ƒëo·∫°n kh√°c nhau (DIFFERENT)
        (
            "N·ªôi dung ch√≠nh c·ªßa h·ªì s∆° m·ªùi th·∫ßu (HSMT)",
            "N·ªôi dung ch√≠nh c·ªßa h·ªì s∆° d·ª± th·∫ßu (HSDT)",
            "different",
        ),
        # Pair 31 - T·ª´ ng·ªØ kh√°c ho√†n to√†n nh∆∞ng c√πng √Ω nghƒ©a (SIMILAR)
        (
            "T∆∞ c√°ch h·ª£p l·ªá c·ªßa nh√† th·∫ßu",
            "ƒêi·ªÅu ki·ªán ƒë·ªÉ doanh nghi·ªáp kh√¥ng b·ªã lo·∫°i khi x√©t duy·ªát ph√°p l√Ω",
            "similar",
        ),
        # Pair 32 - Ph·ªß ƒë·ªãnh/Kh·∫≥ng ƒë·ªãnh (DIFFERENT)
        (
            "C√°c tr∆∞·ªùng h·ª£p ƒë∆∞·ª£c ph√©p ch·ªâ ƒë·ªãnh th·∫ßu",
            "C√°c tr∆∞·ªùng h·ª£p kh√¥ng ƒë∆∞·ª£c ph√©p ch·ªâ ƒë·ªãnh th·∫ßu",
            "different",
        ),
        # Pair 33 - Vi·∫øt t·∫Øt vs Vi·∫øt ƒë·∫ßy ƒë·ªß (SIMILAR)
        (
            "H∆∞·ªõng d·∫´n n·ªôp E-HSDT tr√™n h·ªá th·ªëng",
            "C√°ch th·ª©c g·ª≠i h·ªì s∆° d·ª± th·∫ßu qua m·∫°ng",
            "similar",
        ),
        # Pair 34 - Kh√°c bi·ªát v·ªÅ ƒë∆°n v·ªã th·ªùi gian (DIFFERENT)
        (
            "Th·ªùi gian c√≥ hi·ªáu l·ª±c l√† 90 ng√†y",
            "Th·ªùi gian c√≥ hi·ªáu l·ª±c l√† 120 ng√†y",
            "different",
        ),
        # Pair 35 - Nh√† th·∫ßu ch√≠nh vs Nh√† th·∫ßu ph·ª• (DIFFERENT)
        (
            "Tr√°ch nhi·ªám c·ªßa nh√† th·∫ßu ch√≠nh trong g√≥i th·∫ßu",
            "Quy ƒë·ªãnh v·ªÅ ph·∫ßn vi·ªác c·ªßa nh√† th·∫ßu ph·ª•",
            "different",
        ),
        # Pair 36 - T·ªïng qu√°t vs Chi ti·∫øt (SIMILAR - Th∆∞·ªùng b·ªã ƒëi·ªÉm th·∫•p)
        (
            "Ch·ª©ng minh nƒÉng l·ª±c t√†i ch√≠nh",
            "Cung c·∫•p b√°o c√°o t√†i ch√≠nh ki·ªÉm to√°n trong 3 nƒÉm g·∫ßn nh·∫•t",
            "similar",
        ),
        # Pair 37 - ƒê·∫£o c·∫•u tr√∫c c√¢u (SIMILAR)
        (
            "Ai l√† ng∆∞·ªùi c√≥ th·∫©m quy·ªÅn quy·∫øt ƒë·ªãnh h·ªßy th·∫ßu",
            "Vi·ªác h·ªßy th·∫ßu do c·∫•p n√†o c√≥ th·∫©m quy·ªÅn ph√™ duy·ªát",
            "similar",
        ),
        # Pair 38 - Thay ƒë·ªïi thu·∫≠t ng·ªØ chuy√™n m√¥n (DIFFERENT)
        ("Ph∆∞∆°ng ph√°p gi√° th·∫•p nh·∫•t", "Ph∆∞∆°ng ph√°p gi√° ƒë√°nh gi√°", "different"),
    ]

    print("=" * 80)
    print("SEMANTIC SIMILARITY ANALYSIS FOR THRESHOLD OPTIMIZATION")
    print("=" * 80)
    print()

    similar_sims = []
    different_sims = []
    identical_sims = []

    for i, (q1, q2, category) in enumerate(test_pairs):
        e1 = np.array(embedder.embed_query(q1))
        e2 = np.array(embedder.embed_query(q2))
        sim = cosine_similarity(e1, e2)

        # Categorize
        if category == "similar":
            similar_sims.append(sim)
            marker = "[SIMILAR]"
        elif category == "different":
            different_sims.append(sim)
            marker = "[DIFFERENT TOPIC]"
        else:
            identical_sims.append(sim)
            marker = "[IDENTICAL]"

        print(f"Pair {i+1}: {marker}")
        print(f"  Q1: {q1[:60]}{'...' if len(q1) > 60 else ''}")
        print(f"  Q2: {q2[:60]}{'...' if len(q2) > 60 else ''}")
        print(f"  Similarity: {sim:.4f}")
        print()

    print("=" * 80)
    print("STATISTICS")
    print("=" * 80)

    print(f"\nüìä SIMILAR pairs (should match): {len(similar_sims)}")
    print(f"   Min:    {min(similar_sims):.4f}")
    print(f"   Max:    {max(similar_sims):.4f}")
    print(f"   Mean:   {np.mean(similar_sims):.4f}")
    print(f"   Median: {np.median(similar_sims):.4f}")
    print(f"   Std:    {np.std(similar_sims):.4f}")

    print(f"\nüìä DIFFERENT topic pairs (should NOT match): {len(different_sims)}")
    print(f"   Max:    {max(different_sims):.4f}")
    print(f"   Mean:   {np.mean(different_sims):.4f}")

    print(f"\nüìä IDENTICAL pairs (baseline): {len(identical_sims)}")
    print(f"   Mean:   {np.mean(identical_sims):.4f}")

    print("\n" + "=" * 80)
    print("THRESHOLD ANALYSIS")
    print("=" * 80)

    # Calculate how many similar pairs would be caught at different thresholds
    thresholds = [0.95, 0.90, 0.85, 0.80, 0.75, 0.70, 0.65]

    print("\nThreshold | Similar Caught | Different Caught | Recommendation")
    print("-" * 65)

    for t in thresholds:
        similar_caught = sum(1 for s in similar_sims if s >= t)
        similar_pct = similar_caught / len(similar_sims) * 100
        different_caught = sum(1 for s in different_sims if s >= t)
        different_pct = different_caught / len(different_sims) * 100

        recommendation = ""
        if different_pct > 0:
            recommendation = "‚ùå Too low (false positives)"
        elif similar_pct < 50:
            recommendation = "‚ùå Too high (misses most)"
        elif similar_pct < 80:
            recommendation = "‚ö†Ô∏è High (misses some)"
        else:
            recommendation = "‚úÖ Good"

        print(
            f"   {t:.2f}   |     {similar_caught:2d}/{len(similar_sims)} ({similar_pct:5.1f}%) |      {different_caught}/{len(different_sims)} ({different_pct:5.1f}%)  | {recommendation}"
        )

    print("\n" + "=" * 80)
    print("RECOMMENDATIONS")
    print("=" * 80)

    # Find optimal threshold
    # Should catch most similar pairs but not different topic pairs
    max_different = max(different_sims)
    safe_margin = 0.03  # 3% margin above max different

    # Threshold should be above max_different + margin
    min_safe_threshold = max_different + safe_margin

    # Find threshold that catches at least 70% of similar pairs
    sorted_similar = sorted(similar_sims)
    threshold_70pct = sorted_similar[
        int(len(sorted_similar) * 0.30)
    ]  # 30th percentile = catches 70%
    threshold_80pct = sorted_similar[
        int(len(sorted_similar) * 0.20)
    ]  # 20th percentile = catches 80%

    print(f"\n  Max 'different topic' similarity: {max_different:.4f}")
    print(f"  Min safe threshold (max + 3%):    {min_safe_threshold:.4f}")
    print(f"  Threshold for 70% recall:         {threshold_70pct:.4f}")
    print(f"  Threshold for 80% recall:         {threshold_80pct:.4f}")

    # Recommended threshold
    recommended = max(min_safe_threshold, threshold_70pct)

    print(f"\n  üéØ RECOMMENDED THRESHOLD: {recommended:.2f}")
    print(f"     (Ensures no false positives while catching ~70%+ of similar queries)")

    # Show what current 0.95 threshold would catch
    current_caught = sum(1 for s in similar_sims if s >= 0.95)
    print(
        f"\n  ‚ö†Ô∏è Current threshold (0.95) catches only {current_caught}/{len(similar_sims)} similar pairs ({current_caught/len(similar_sims)*100:.1f}%)"
    )


if __name__ == "__main__":
    main()

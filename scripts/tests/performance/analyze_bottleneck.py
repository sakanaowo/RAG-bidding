#!/usr/bin/env python3
"""
Bottleneck Analysis Script
Ph√¢n t√≠ch nguy√™n nh√¢n BE x·ª≠ l√Ω ch·∫≠m m·∫∑c d√π ƒë√£ tƒÉng connection pool
"""

import sys
import os
import time
import asyncio
import aiohttp
from datetime import datetime
from typing import Dict, List
from collections import defaultdict

sys.path.insert(0, os.path.join(os.path.dirname(__file__), "../../.."))

API_BASE_URL = "http://localhost:8000"
API_PREFIX = "/api"


def print_header(title: str):
    print(f"\n{'='*70}")
    print(f"üîç {title}")
    print(f"{'='*70}")


async def check_server_status():
    """Ki·ªÉm tra status server"""
    print_header("SERVER STATUS CHECK")

    endpoints = [
        ("/health", "Health Check"),
        ("/", "Root"),
    ]

    async with aiohttp.ClientSession() as session:
        for endpoint, name in endpoints:
            try:
                start = time.time()
                async with session.get(f"{API_BASE_URL}{endpoint}", timeout=5) as resp:
                    elapsed = (time.time() - start) * 1000
                    print(f"  ‚úÖ {name}: {resp.status} ({elapsed:.0f}ms)")
            except Exception as e:
                print(f"  ‚ùå {name}: {e}")


async def test_single_request_latency(email: str, password: str):
    """Test latency c·ªßa t·ª´ng lo·∫°i request khi server idle"""
    print_header("SINGLE REQUEST LATENCY (Server Idle)")

    async with aiohttp.ClientSession() as session:
        # Login first
        print("\n  üìç Login...")
        start = time.time()
        async with session.post(
            f"{API_BASE_URL}{API_PREFIX}/auth/login",
            json={"email": email, "password": password},
        ) as resp:
            login_time = (time.time() - start) * 1000
            if resp.status != 200:
                print(f"  ‚ùå Login failed: {await resp.text()}")
                return
            data = await resp.json()
            token = data["tokens"]["access_token"]
            print(f"  ‚úÖ Login: {login_time:.0f}ms")

        headers = {"Authorization": f"Bearer {token}"}

        # Test each endpoint 3 times
        endpoints = [
            ("GET", f"{API_PREFIX}/auth/me", None, "User Profile"),
            ("GET", f"{API_PREFIX}/conversations", None, "List Conversations"),
            (
                "POST",
                f"{API_PREFIX}/conversations",
                {"title": "Test", "rag_mode": "fast"},
                "Create Conversation",
            ),
        ]

        print("\n  üìç Endpoint Latencies (3 runs each):")

        for method, path, body, name in endpoints:
            times = []
            for _ in range(3):
                start = time.time()
                if method == "GET":
                    async with session.get(
                        f"{API_BASE_URL}{path}", headers=headers
                    ) as resp:
                        elapsed = (time.time() - start) * 1000
                        times.append(elapsed)
                else:
                    async with session.post(
                        f"{API_BASE_URL}{path}", json=body, headers=headers
                    ) as resp:
                        elapsed = (time.time() - start) * 1000
                        times.append(elapsed)
                        if name == "Create Conversation" and resp.status == 201:
                            data = await resp.json()
                            conv_id = data.get("id")

            avg = sum(times) / len(times)
            print(
                f"     ‚Ä¢ {name:<25}: {avg:>8.0f}ms (min: {min(times):.0f}, max: {max(times):.0f})"
            )

        # Test RAG query
        if conv_id:
            print("\n  üìç RAG Query Latencies (3 runs, mode=fast):")
            queries = [
                "ch·ªâ ƒë·ªãnh th·∫ßu",
                "h·ªì s∆° m·ªùi th·∫ßu",
                "quy tr√¨nh ƒë·∫•u th·∫ßu",
            ]

            for query in queries:
                start = time.time()
                async with session.post(
                    f"{API_BASE_URL}{API_PREFIX}/conversations/{conv_id}/messages",
                    json={"content": query},
                    headers=headers,
                    timeout=aiohttp.ClientTimeout(total=120),
                ) as resp:
                    elapsed = (time.time() - start) * 1000
                    if resp.status == 200:
                        data = await resp.json()
                        server_time = data.get("assistant_message", {}).get(
                            "processing_time_ms", 0
                        )
                        print(
                            f'     ‚Ä¢ "{query[:20]}..." : {elapsed:>8.0f}ms (server reported: {server_time}ms)'
                        )
                    else:
                        print(f'     ‚Ä¢ "{query[:20]}..." : ‚ùå {resp.status}')


async def test_concurrent_latency(
    email_prefix: str, password: str, num_concurrent: int = 10
):
    """Test latency khi c√≥ nhi·ªÅu requests ƒë·ªìng th·ªùi"""
    print_header(f"CONCURRENT REQUEST LATENCY ({num_concurrent} simultaneous)")

    async def single_login(session, email):
        start = time.time()
        try:
            async with session.post(
                f"{API_BASE_URL}{API_PREFIX}/auth/login",
                json={"email": email, "password": password},
                timeout=aiohttp.ClientTimeout(total=30),
            ) as resp:
                elapsed = (time.time() - start) * 1000
                return elapsed, resp.status == 200
        except Exception as e:
            return (time.time() - start) * 1000, False

    async with aiohttp.ClientSession() as session:
        # Concurrent logins
        print(f"\n  üìç {num_concurrent} Concurrent Logins:")

        emails = [f"test{i:03d}@testmail.com" for i in range(1, num_concurrent + 1)]

        start_all = time.time()
        tasks = [single_login(session, email) for email in emails]
        results = await asyncio.gather(*tasks)
        total_time = (time.time() - start_all) * 1000

        times = [r[0] for r in results]
        successes = sum(1 for r in results if r[1])

        print(f"     ‚Ä¢ Success: {successes}/{num_concurrent}")
        print(f"     ‚Ä¢ Total wall time: {total_time:.0f}ms")
        print(f"     ‚Ä¢ Avg per request: {sum(times)/len(times):.0f}ms")
        print(f"     ‚Ä¢ Min: {min(times):.0f}ms, Max: {max(times):.0f}ms")
        print(f"     ‚Ä¢ Throughput: {num_concurrent / (total_time/1000):.1f} req/s")


async def analyze_rag_bottleneck(email: str, password: str):
    """Ph√¢n t√≠ch bottleneck trong RAG pipeline"""
    print_header("RAG PIPELINE BOTTLENECK ANALYSIS")

    print(
        """
  üîç RAG Pipeline c√≥ c√°c b∆∞·ªõc sau:
     1. Query Enhancement (Multi-Query, HyDE, etc.)
     2. Vector Search (pgvector similarity search)
     3. Reranking (BGE-reranker or OpenAI)
     4. LLM Generation (OpenAI API call)
  
  ‚ö†Ô∏è  C√°c bottleneck ti·ªÅm nƒÉng:
     ‚Ä¢ OpenAI API latency (network + processing): 2-10s
     ‚Ä¢ Vector search v·ªõi large dataset: 100-500ms
     ‚Ä¢ Reranking v·ªõi many chunks: 500-2000ms
     ‚Ä¢ Database connection pool: n·∫øu qu√° t·∫£i
  
  üí° TƒÉng DB pool KH√îNG gi√∫p n·∫øu bottleneck l√† OpenAI API!
     OpenAI c√≥ rate limits v√† latency ri√™ng.
"""
    )


async def check_database_stats():
    """Ki·ªÉm tra database connection stats (y√™u c·∫ßu endpoint ri√™ng)"""
    print_header("DATABASE CONNECTION ANALYSIS")

    print(
        """
  üìä ƒê·ªÉ ki·ªÉm tra database connections, c·∫ßn:
  
  1. Ki·ªÉm tra PostgreSQL:
     psql -c "SELECT count(*) FROM pg_stat_activity;"
     psql -c "SELECT state, count(*) FROM pg_stat_activity GROUP BY state;"
  
  2. Ki·ªÉm tra SQLAlchemy pool:
     Th√™m endpoint /debug/pool-status v√†o API ƒë·ªÉ xem pool stats
  
  3. Ki·ªÉm tra max_connections trong PostgreSQL:
     psql -c "SHOW max_connections;"
  
  ‚ö†Ô∏è  N·∫øu pool_size=100 nh∆∞ng PostgreSQL max_connections=100,
     th√¨ ch·ªâ c√≥ th·ªÉ c√≥ 100 connections t·ªëi ƒëa!
"""
    )


def print_recommendations():
    """In c√°c ƒë·ªÅ xu·∫•t kh·∫Øc ph·ª•c"""
    print_header("RECOMMENDATIONS")

    print(
        """
  üéØ C√ÅC NGUY√äN NH√ÇN CH√çNH G√ÇY CH·∫¨M:
  
  1. ‚è±Ô∏è  OPENAI API LATENCY (Bottleneck ch√≠nh cho RAG)
     ‚Ä¢ M·ªói RAG query c·∫ßn 1-3 OpenAI API calls
     ‚Ä¢ OpenAI latency: 2-10s m·ªói call
     ‚Ä¢ Concurrent OpenAI calls c√≥ th·ªÉ b·ªã rate limited
     
     ‚úÖ Gi·∫£i ph√°p:
     ‚Ä¢ D√πng mode "fast" thay v√¨ "balanced/quality" 
     ‚Ä¢ Implement caching cho similar queries
     ‚Ä¢ D√πng streaming response
     ‚Ä¢ D√πng local LLM (Ollama) cho testing
  
  2. üîÑ CONNECTION POOL CONFIGURATION
     ‚Ä¢ pool_size=100, max_overflow=20 ‚Üí 120 max connections
     ‚Ä¢ PostgreSQL max_connections=200 ‚Üí OK
     ‚Ä¢ Nh∆∞ng m·ªói RAG request gi·ªØ connection l√¢u (ch·ªù OpenAI)
     
     ‚úÖ Gi·∫£i ph√°p:
     ‚Ä¢ TƒÉng pool_timeout t·ª´ 30 ‚Üí 60
     ‚Ä¢ Gi·∫£m s·ªë concurrent users trong test
     ‚Ä¢ D√πng async database sessions
  
  3. üîç VECTOR SEARCH PERFORMANCE
     ‚Ä¢ pgvector c·∫ßn optimize cho large datasets
     
     ‚úÖ Gi·∫£i ph√°p:
     ‚Ä¢ Th√™m HNSW index cho vector column
     ‚Ä¢ TƒÉng work_mem cho PostgreSQL
     ‚Ä¢ Ki·ªÉm tra EXPLAIN ANALYZE c·ªßa queries
  
  4. üé≠ FASTAPI WORKERS
     ‚Ä¢ Default ch·ªâ c√≥ 1 worker
     
     ‚úÖ Gi·∫£i ph√°p:
     ‚Ä¢ Ch·∫°y v·ªõi nhi·ªÅu workers: uvicorn --workers 4
     ‚Ä¢ Ho·∫∑c d√πng gunicorn v·ªõi uvicorn workers
  
  üìù QUICK TEST:
     # Test v·ªõi √≠t users h∆°n v√† mode fast
     python test_authenticated_users.py --users 10 --requests 5 --batch-size 5
     
     # So s√°nh v·ªõi mode balanced
     # N·∫øu mode fast nhanh h∆°n nhi·ªÅu ‚Üí bottleneck l√† OpenAI
"""
    )


async def main():
    print("\n" + "=" * 70)
    print("üî¨ BACKEND PERFORMANCE BOTTLENECK ANALYZER")
    print("=" * 70)
    print(f"üìÖ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"üåê Target: {API_BASE_URL}")

    # Check server
    await check_server_status()

    # Test single request latency
    await test_single_request_latency("test001@testmail.com", "TestPass123!")

    # Test concurrent latency
    await test_concurrent_latency("test", "TestPass123!", num_concurrent=20)

    # Analyze RAG
    await analyze_rag_bottleneck("test001@testmail.com", "TestPass123!")

    # Database stats
    await check_database_stats()

    # Recommendations
    print_recommendations()

    print("\n" + "=" * 70)
    print("‚úÖ Analysis complete!")
    print("=" * 70 + "\n")


if __name__ == "__main__":
    asyncio.run(main())

"""
Test Parallel vs Sequential OpenAI Reranking Performance

So sÃ¡nh:
1. Sequential reranking (original): ~300ms Ã— N docs
2. Parallel reranking (new): ~500ms for all docs
3. Expected speedup: 10-20x

YÃªu cáº§u: OPENAI_API_KEY environment variable
"""

import os
import sys
import time

import pytest
from langchain_core.documents import Document

try:
    from dotenv import load_dotenv
except ImportError:
    load_dotenv = None

if load_dotenv is not None:
    load_dotenv()

# Add src to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", ".."))

from src.retrieval.ranking import OpenAIReranker


def test_parallel_vs_sequential_performance():
    """
    Test chÃ­nh: So sÃ¡nh performance parallel vs sequential.

    Expected:
    - Sequential: ~300ms Ã— 10 docs = 3000ms (3 giÃ¢y)
    - Parallel: ~500-800ms cho 10 docs
    - Speedup: 4-6x (minimum)
    """

    if not os.getenv("OPENAI_API_KEY"):
        pytest.skip("OPENAI_API_KEY not set")

    # Prepare test documents
    docs = [
        Document(
            page_content="Luáº­t Äáº¥u tháº§u 2023 quy Ä‘á»‹nh vá» quy trÃ¬nh Ä‘áº¥u tháº§u cÃ´ng khai.",
            metadata={"title": "Luáº­t Äáº¥u tháº§u 2023", "dieu": "10"},
        ),
        Document(
            page_content="Nghá»‹ Ä‘á»‹nh 24/2024 hÆ°á»›ng dáº«n chi tiáº¿t Luáº­t Äáº¥u tháº§u.",
            metadata={"title": "Nghá»‹ Ä‘á»‹nh 24/2024", "dieu": "5"},
        ),
        Document(
            page_content="Quy trÃ¬nh mua sáº¯m cÃ´ng Ä‘Æ°á»£c quy Ä‘á»‹nh táº¡i Luáº­t Äáº¥u tháº§u.",
            metadata={"title": "Luáº­t Äáº¥u tháº§u 2023", "dieu": "15"},
        ),
        Document(
            page_content="ThÃ´ng tÆ° 05/2024 quy Ä‘á»‹nh chi tiáº¿t vá» há»“ sÆ¡ má»i tháº§u.",
            metadata={"title": "ThÃ´ng tÆ° 05/2024", "dieu": "3"},
        ),
        Document(
            page_content="Äiá»u kiá»‡n tham gia Ä‘áº¥u tháº§u Ä‘Æ°á»£c quy Ä‘á»‹nh rÃµ rÃ ng.",
            metadata={"title": "Luáº­t Äáº¥u tháº§u 2023", "dieu": "6"},
        ),
        Document(
            page_content="Há»“ sÆ¡ dá»± tháº§u pháº£i Ä‘áº£m báº£o Ä‘áº§y Ä‘á»§ cÃ¡c yÃªu cáº§u.",
            metadata={"title": "Nghá»‹ Ä‘á»‹nh 24/2024", "dieu": "8"},
        ),
        Document(
            page_content="ÄÃ¡nh giÃ¡ há»“ sÆ¡ dá»± tháº§u theo quy trÃ¬nh chuáº©n.",
            metadata={"title": "ThÃ´ng tÆ° 05/2024", "dieu": "12"},
        ),
        Document(
            page_content="CÃ´ng bá»‘ káº¿t quáº£ Ä‘áº¥u tháº§u trÃªn há»‡ thá»‘ng máº¡ng.",
            metadata={"title": "Luáº­t Äáº¥u tháº§u 2023", "dieu": "45"},
        ),
        Document(
            page_content="KÃ½ káº¿t há»£p Ä‘á»“ng vá»›i nhÃ  tháº§u trÃºng tháº§u.",
            metadata={"title": "Nghá»‹ Ä‘á»‹nh 24/2024", "dieu": "20"},
        ),
        Document(
            page_content="GiÃ¡m sÃ¡t thá»±c hiá»‡n há»£p Ä‘á»“ng Ä‘áº¥u tháº§u.",
            metadata={"title": "Luáº­t Äáº¥u tháº§u 2023", "dieu": "50"},
        ),
    ]

    query = "quy trÃ¬nh Ä‘áº¥u tháº§u cÃ´ng khai"

    print("\n" + "=" * 70)
    print("ðŸ§ª PARALLEL vs SEQUENTIAL PERFORMANCE TEST")
    print("=" * 70)

    # Test 1: Sequential (use_parallel=False)
    print("\nðŸ“Š Test 1: Sequential Reranking")
    print("-" * 70)

    reranker_seq = OpenAIReranker(use_parallel=False)

    start_seq = time.time()
    results_seq = reranker_seq.rerank(query, docs, top_k=5)
    time_seq = (time.time() - start_seq) * 1000

    print(f"   â±ï¸  Sequential time: {time_seq:.1f}ms")
    print(f"   ðŸ“„ Results: {len(results_seq)} documents")
    print(f"   ðŸ† Top score: {results_seq[0][1]:.4f}")

    # Test 2: Parallel (use_parallel=True)
    print("\nðŸ“Š Test 2: Parallel Reranking")
    print("-" * 70)

    reranker_par = OpenAIReranker(use_parallel=True)

    start_par = time.time()
    results_par = reranker_par.rerank(query, docs, top_k=5)
    time_par = (time.time() - start_par) * 1000

    print(f"   â±ï¸  Parallel time: {time_par:.1f}ms")
    print(f"   ðŸ“„ Results: {len(results_par)} documents")
    print(f"   ðŸ† Top score: {results_par[0][1]:.4f}")

    # Compare
    print("\n" + "=" * 70)
    print("ðŸ“ˆ PERFORMANCE COMPARISON")
    print("=" * 70)

    speedup = time_seq / time_par if time_par > 0 else 0
    time_saved = time_seq - time_par

    print(f"\n   Sequential:  {time_seq:>8.1f}ms")
    print(f"   Parallel:    {time_par:>8.1f}ms")
    print(f"   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    print(f"   Speedup:     {speedup:>8.2f}x")
    print(f"   Time saved:  {time_saved:>8.1f}ms")

    if speedup >= 3.0:
        print(f"\n   âœ… EXCELLENT! {speedup:.1f}x speedup achieved!")
    elif speedup >= 2.0:
        print(f"\n   âœ… GOOD! {speedup:.1f}x speedup")
    elif speedup >= 1.5:
        print(f"\n   âš ï¸  MODERATE! {speedup:.1f}x speedup (expected >3x)")
    else:
        print(f"\n   âŒ POOR! {speedup:.1f}x speedup (expected >3x)")

    print("\n" + "=" * 70)

    # Assertions
    assert len(results_seq) == 5, "Sequential should return 5 docs"
    assert len(results_par) == 5, "Parallel should return 5 docs"
    assert speedup >= 2.0, f"Expected at least 2x speedup, got {speedup:.2f}x"

    # Scores should be similar (might differ slightly due to API variance)
    score_diff = abs(results_seq[0][1] - results_par[0][1])
    assert score_diff < 0.3, f"Scores differ too much: {score_diff:.4f}"

    print("âœ… All assertions passed!")


def test_parallel_scaling():
    """
    Test scalability: 5, 10, 15, 20 documents.

    Expected: Parallel time should stay relatively constant (~500-800ms)
    while sequential time grows linearly.
    """

    if not os.getenv("OPENAI_API_KEY"):
        pytest.skip("OPENAI_API_KEY not set")

    print("\n" + "=" * 70)
    print("ðŸ“Š PARALLEL SCALING TEST")
    print("=" * 70)

    # Create 20 test documents
    all_docs = []
    for i in range(20):
        all_docs.append(
            Document(
                page_content=f"VÄƒn báº£n phÃ¡p luáº­t sá»‘ {i+1} vá» Ä‘áº¥u tháº§u vÃ  mua sáº¯m cÃ´ng.",
                metadata={"doc_id": i + 1},
            )
        )

    query = "quy trÃ¬nh Ä‘áº¥u tháº§u"

    reranker = OpenAIReranker(use_parallel=True)

    doc_counts = [5, 10, 15, 20]
    times = []

    print(f"\n{'Docs':<10} {'Time (ms)':<15} {'Time/Doc (ms)'}")
    print("-" * 70)

    for count in doc_counts:
        docs = all_docs[:count]

        start = time.time()
        results = reranker.rerank(query, docs, top_k=5)
        elapsed = (time.time() - start) * 1000
        times.append(elapsed)

        time_per_doc = elapsed / count

        print(f"{count:<10} {elapsed:<15.1f} {time_per_doc:.1f}")

    print("\n" + "=" * 70)
    print("ðŸ“ˆ SCALING ANALYSIS")
    print("=" * 70)

    # Check that time doesn't grow linearly
    # Linear: time(20) / time(5) = 4x
    # Parallel: time(20) / time(5) should be < 2x

    scaling_factor = times[-1] / times[0]

    print(f"\n   Time for 5 docs:  {times[0]:.1f}ms")
    print(f"   Time for 20 docs: {times[-1]:.1f}ms")
    print(f"   Scaling factor:   {scaling_factor:.2f}x")
    print(f"\n   Expected linear:  4.0x (bad)")
    print(f"   Expected parallel: <2.0x (good)")

    if scaling_factor < 2.0:
        print(f"\n   âœ… EXCELLENT! Parallel scaling works! ({scaling_factor:.2f}x)")
    elif scaling_factor < 3.0:
        print(f"\n   âš ï¸  MODERATE! Some parallelism ({scaling_factor:.2f}x)")
    else:
        print(f"\n   âŒ POOR! Nearly linear scaling ({scaling_factor:.2f}x)")

    print("\n" + "=" * 70)

    assert scaling_factor < 3.0, f"Scaling too linear: {scaling_factor:.2f}x"


def test_parallel_correctness():
    """
    Test correctness: Parallel vÃ  sequential pháº£i cho káº¿t quáº£ tÆ°Æ¡ng tá»±.
    """

    if not os.getenv("OPENAI_API_KEY"):
        pytest.skip("OPENAI_API_KEY not set")

    docs = [
        Document(
            page_content="Luáº­t Äáº¥u tháº§u 2023 quy Ä‘á»‹nh vá» quy trÃ¬nh Ä‘áº¥u tháº§u cÃ´ng khai."
        ),
        Document(page_content="Nghá»‹ Ä‘á»‹nh 24/2024 hÆ°á»›ng dáº«n chi tiáº¿t Luáº­t Äáº¥u tháº§u."),
        Document(page_content="ThÃ´ng tÆ° 05/2024 quy Ä‘á»‹nh vá» há»“ sÆ¡ má»i tháº§u."),
    ]

    query = "quy trÃ¬nh Ä‘áº¥u tháº§u cÃ´ng khai"

    # Sequential
    reranker_seq = OpenAIReranker(use_parallel=False)
    results_seq = reranker_seq.rerank(query, docs, top_k=3)

    # Parallel
    reranker_par = OpenAIReranker(use_parallel=True)
    results_par = reranker_par.rerank(query, docs, top_k=3)

    print("\n" + "=" * 70)
    print("ðŸ” CORRECTNESS TEST")
    print("=" * 70)

    print("\nSequential scores:")
    for i, (doc, score) in enumerate(results_seq, 1):
        print(f"  [{i}] {score:.4f} - {doc.page_content[:50]}...")

    print("\nParallel scores:")
    for i, (doc, score) in enumerate(results_par, 1):
        print(f"  [{i}] {score:.4f} - {doc.page_content[:50]}...")

    # Scores should be similar (allow some variance due to API randomness)
    for i in range(len(results_seq)):
        score_seq = results_seq[i][1]
        score_par = results_par[i][1]
        diff = abs(score_seq - score_par)

        print(f"\nDoc {i+1} score difference: {diff:.4f}")
        assert diff < 0.5, f"Score difference too large: {diff:.4f}"

    print("\nâœ… Correctness verified!")


if __name__ == "__main__":
    print("=" * 70)
    print("ðŸ§ª OpenAI Parallel Reranking Performance Tests")
    print("=" * 70)

    # Check API key
    if not os.getenv("OPENAI_API_KEY"):
        print("âŒ OPENAI_API_KEY not set!")
        print("   Set it with: export OPENAI_API_KEY=sk-...")
        sys.exit(1)

    print(f"âœ… API key found: {os.getenv('OPENAI_API_KEY')[:20]}...")
    print()

    # Run tests
    pytest.main([__file__, "-v", "-s"])

"""
Pytest suite for chunking strategies.

Tests:
1. HierarchicalChunker with legal documents
2. SemanticChunker with bidding/report/exam
3. Chunk size validation
4. Schema integration (UniversalChunk â†’ UnifiedLegalChunk)
5. ChunkFactory conversion

Run:
    pytest scripts/test/test_chunk_pipeline.py -v
"""

import pytest
from pathlib import Path
from typing import List

from src.preprocessing.chunking import (
    create_chunker,
    ChunkFactory,
    UniversalChunk,
    HierarchicalChunker,
    SemanticChunker,
)
from src.preprocessing.base.models import ProcessedDocument


# ============================================================
# FIXTURES
# ============================================================


@pytest.fixture
def sample_legal_document():
    """Sample legal document (Law/Decree)"""
    return ProcessedDocument(
        metadata={
            "document_type": "decree",
            "title": "Nghá»‹ Ä‘á»‹nh 63/2014/NÄ-CP",
            "issued_by": "chinh_phu",  # Changed from "ChÃ­nh phá»§" to enum value
            "issued_date": "2014-06-26",
            "effective_date": "2014-08-10",
            "file_path": "/data/raw/Nghi dinh/63-2014-ND-CP.docx",
            "legal_metadata": {
                "legal_id": "63/2014/NÄ-CP",  # Changed to correct format
                "legal_level": 3,
                "status": "con_hieu_luc",  # Changed from "active" to enum value
                "domain": ["dau_thau"],
            },
        },
        content={
            "full_text": """
CHÆ¯Æ NG I - QUY Äá»ŠNH CHUNG

Äiá»u 1. Pháº¡m vi Ä‘iá»u chá»‰nh
1. Nghá»‹ Ä‘á»‹nh nÃ y quy Ä‘á»‹nh chi tiáº¿t thi hÃ nh má»™t sá»‘ Ä‘iá»u cá»§a Luáº­t Äáº¥u tháº§u.
2. Nghá»‹ Ä‘á»‹nh nÃ y Ã¡p dá»¥ng Ä‘á»‘i vá»›i cÃ¡c hoáº¡t Ä‘á»™ng Ä‘áº¥u tháº§u.

Äiá»u 2. Äá»‘i tÆ°á»£ng Ã¡p dá»¥ng
1. CÆ¡ quan cÃ³ tháº©m quyá»n trong hoáº¡t Ä‘á»™ng Ä‘áº¥u tháº§u.
2. NhÃ  tháº§u, tÆ° váº¥n tham gia Ä‘áº¥u tháº§u.
3. CÃ¡c tá»• chá»©c, cÃ¡ nhÃ¢n cÃ³ liÃªn quan.

CHÆ¯Æ NG II - Há»’ SÆ  Má»œI THáº¦U

Má»¥c 1 - Ná»™i dung há»“ sÆ¡ má»i tháº§u

Äiá»u 3. ThÃ nh pháº§n há»“ sÆ¡ má»i tháº§u
1. Há»“ sÆ¡ má»i tháº§u bao gá»“m:
a) ThÃ´ng tin tá»•ng quÃ¡t vá» gÃ³i tháº§u;
b) YÃªu cáº§u vá» nÄƒng lá»±c, kinh nghiá»‡m;
c) TiÃªu chuáº©n Ä‘Ã¡nh giÃ¡;
d) Äiá»u kiá»‡n há»£p Ä‘á»“ng.
2. BÃªn má»i tháº§u chá»‹u trÃ¡ch nhiá»‡m láº­p há»“ sÆ¡ má»i tháº§u.

Äiá»u 4. YÃªu cáº§u Ä‘á»‘i vá»›i há»“ sÆ¡ má»i tháº§u
1. Há»“ sÆ¡ má»i tháº§u pháº£i rÃµ rÃ ng, Ä‘áº§y Ä‘á»§.
2. KhÃ´ng Ä‘Æ°á»£c cÃ³ Ä‘iá»u kiá»‡n phÃ¢n biá»‡t Ä‘á»‘i xá»­.
3. Pháº£i cÃ´ng bá»‘ cÃ´ng khai trÃªn há»‡ thá»‘ng máº¡ng Ä‘áº¥u tháº§u quá»‘c gia.
            """.strip(),
        },
    )


@pytest.fixture
def sample_exam_document():
    """Sample exam document"""
    return ProcessedDocument(
        metadata={
            "document_type": "exam",
            "title": "NgÃ¢n hÃ ng cÃ¢u há»i thi CCDT",
            "file_path": "/data/raw/Cau hoi thi/exam.pdf",
        },
        content={
            "full_text": """
CÃ¢u 1: Luáº­t Äáº¥u tháº§u sá»‘ 43/2013/QH13 cÃ³ hiá»‡u lá»±c tá»« ngÃ y nÃ o?
A. 01/07/2014
B. 01/01/2014
C. 01/07/2013
D. 01/01/2015

CÃ¢u 2: HÃ¬nh thá»©c nÃ o KHÃ”NG pháº£i lÃ  hÃ¬nh thá»©c lá»±a chá»n nhÃ  tháº§u theo Luáº­t Äáº¥u tháº§u?
A. Äáº¥u tháº§u rá»™ng rÃ£i
B. Äáº¥u tháº§u háº¡n cháº¿
C. Chá»‰ Ä‘á»‹nh tháº§u
D. Mua sáº¯m trá»±c tiáº¿p

CÃ¢u 3: GiÃ¡ trá»‹ gÃ³i tháº§u Ä‘Æ°á»£c tÃ­nh báº±ng?
A. GiÃ¡ gÃ³i tháº§u Ä‘Æ°á»£c duyá»‡t
B. GiÃ¡ trÃºng tháº§u
C. GiÃ¡ dá»± tháº§u tháº¥p nháº¥t
D. GiÃ¡ dá»± toÃ¡n Ä‘Æ°á»£c duyá»‡t
            """.strip(),
        },
    )


# ============================================================
# TEST BASIC FUNCTIONALITY
# ============================================================


def test_create_chunker_factory():
    """Test chunker factory function"""
    # Legal documents â†’ HierarchicalChunker
    for doc_type in ["law", "decree", "circular", "decision"]:
        chunker = create_chunker(doc_type)
        assert isinstance(chunker, HierarchicalChunker)

    # Bidding â†’ SemanticChunker
    chunker = create_chunker("bidding")
    assert isinstance(chunker, SemanticChunker)
    assert chunker.document_type == "bidding"

    # Exam â†’ SemanticChunker
    chunker = create_chunker("exam")
    assert isinstance(chunker, SemanticChunker)
    assert chunker.document_type == "exam"


def test_hierarchical_chunker_basic(sample_legal_document):
    """Test HierarchicalChunker basic functionality"""
    chunker = HierarchicalChunker()
    chunks = chunker.chunk(sample_legal_document)

    # Should have chunks for Äiá»u 1-4
    assert len(chunks) >= 4, f"Expected at least 4 chunks, got {len(chunks)}"

    # All chunks should be UniversalChunk
    for chunk in chunks:
        assert isinstance(chunk, UniversalChunk)
        assert chunk.content is not None
        assert chunk.document_type == "decree"


def test_semantic_chunker_exam(sample_exam_document):
    """Test SemanticChunker with exam questions"""
    chunker = SemanticChunker(document_type="exam")
    chunks = chunker.chunk(sample_exam_document)

    # Should have 3 chunks (3 questions)
    assert len(chunks) == 3, f"Expected 3 chunks, got {len(chunks)}"

    # Each chunk should be a complete question
    for chunk in chunks:
        assert chunk.level == "question"
        assert "CÃ¢u" in chunk.section_title


def test_chunk_size_constraints(sample_legal_document):
    """Test that chunks respect size constraints"""
    chunker = HierarchicalChunker(
        min_size=300,
        max_size=1500,
        target_size=800,
    )
    chunks = chunker.chunk(sample_legal_document)

    # Check size distribution
    sizes = [c.char_count for c in chunks]

    # Most chunks should be in acceptable range
    # Note: Small test data (4 chunks) may have lower ratio
    # Real production data will have much higher ratio
    in_range = [s for s in sizes if 300 <= s <= 1500]
    ratio = len(in_range) / len(sizes)

    assert ratio >= 0.5, f"Only {ratio:.0%} of chunks in size range"

    # No chunk should be excessively large
    assert all(s <= 2000 for s in sizes), "Some chunks exceed safety limit"


def test_chunk_factory_conversion(sample_legal_document):
    """Test ChunkFactory converts UniversalChunk to UnifiedLegalChunk"""
    # Create chunks
    chunker = create_chunker("decree")
    universal_chunks = chunker.chunk(sample_legal_document)

    # Convert
    factory = ChunkFactory()
    unified_chunks = factory.convert_batch(universal_chunks, sample_legal_document)

    # Should have same count
    assert len(unified_chunks) == len(universal_chunks)

    # Check schema structure
    for unified in unified_chunks:
        assert unified.document_info is not None
        assert unified.content_structure is not None
        assert unified.processing_metadata is not None
        assert unified.quality_metrics is not None


# ============================================================
# SUMMARY TEST
# ============================================================


def test_full_pipeline(sample_legal_document, sample_exam_document):
    """Integration test: Full pipeline from document to UnifiedLegalChunk"""

    print("\n" + "=" * 70)
    print("CHUNKING PIPELINE TEST SUMMARY")
    print("=" * 70)

    # Test 1: Legal document
    print("\nðŸ“‹ Test 1: Legal Document (Decree)")
    chunker_legal = create_chunker("decree")
    chunks_legal = chunker_legal.chunk(sample_legal_document)
    print(f"  âœ… Created {len(chunks_legal)} chunks")

    factory = ChunkFactory()
    unified_legal = factory.convert_batch(chunks_legal, sample_legal_document)
    print(f"  âœ… Converted to {len(unified_legal)} UnifiedLegalChunks")

    stats_legal = chunker_legal.get_statistics()
    print(
        f"  ðŸ“Š Stats: {stats_legal['in_range']}/{stats_legal['total_chunks']} chunks in range"
    )
    print(f"  ðŸ“ Avg size: {stats_legal['avg_size']:.0f} chars")

    # Test 2: Exam document
    print("\nðŸ“ Test 2: Exam Questions")
    chunker_exam = create_chunker("exam")
    chunks_exam = chunker_exam.chunk(sample_exam_document)
    print(f"  âœ… Created {len(chunks_exam)} chunks")

    unified_exam = factory.convert_batch(chunks_exam, sample_exam_document)
    print(f"  âœ… Converted to {len(unified_exam)} UnifiedLegalChunks")

    # Verify schemas
    print("\nðŸ” Schema Validation:")
    for unified in unified_legal[:1]:  # Check first chunk
        print(f"  âœ… DocumentInfo: {unified.document_info.doc_type.value}")
        print(f"  âœ… LegalMetadata: {unified.legal_metadata is not None}")
        print(f"  âœ… ContentStructure: chunk_id={unified.get_chunk_id()}")
        print(f"  âœ… QualityMetrics: {unified.quality_metrics.overall_quality}")

    print("\n" + "=" * 70)
    print("âœ… ALL TESTS PASSED")
    print("=" * 70)


if __name__ == "__main__":
    pytest.main([__file__, "-v", "-s"])

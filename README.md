# ğŸ“š RAG Bidding System

**AI-Powered Vietnamese Legal Document Retrieval & Question Answering System**

Advanced RAG system for Vietnamese bidding law documents with semantic enrichment, multi-tier caching, and BGE reranking.

---

## âš¡ Quick Start

### 1ï¸âƒ£ Automated Setup (Recommended)

```bash
# Clone repository
git clone https://github.com/sakanaowo/RAG-bidding.git
cd RAG-bidding

# Run database setup
chmod +x setup_db.sh
./setup_db.sh

# Create environment
conda env create -f environment.yaml
conda activate rag-bidding

# Configure API keys
cp .env.example .env
nano .env  # Add OPENAI_API_KEY

# Initialize database
python scripts/bootstrap_db.py

# Import preprocessed data (4,512 enriched chunks)
python scripts/import_processed_chunks.py
```

**Time:** ~10 minutes | **See:** [Quick Setup Guide](documents/setup/QUICK_SETUP.md)

### 2ï¸âƒ£ Manual Setup

**See:** [Complete Database Setup Guide](documents/setup/DATABASE_SETUP.md) for detailed instructions.

---

## ğŸ¯ Key Features

### ğŸ” Advanced Retrieval
- **Native 3072-dim embeddings** (text-embedding-3-large)
- **BGE Reranker** (Vietnamese multilingual support)
- **Semantic enrichment** with NER, concepts, keywords
- **Multi-tier caching** (Redis + PostgreSQL)
- **Adaptive retrieval** modes (fast/balanced/quality)

### ğŸ“Š Document Processing
- **Multi-file upload API** with Postman compatibility  
- **Auto-classification** (Law, Decree, Circular, Bidding documents)
- **Background processing** with real-time progress tracking
- **Hierarchical chunking** preserving legal structure
- **Entity extraction** (laws, decrees, circulars, dates)
- **TF-IDF keyword extraction** with legal term boosting

### ğŸ—„ï¸ Database
- **PostgreSQL 18** with pgvector extension
- **Vector search** with cosine similarity
- **JSONB metadata** for rich filtering
- **Optimized indexes** for production workloads

---

## ğŸ“Š Current System Status

| Metric | Value |
|--------|-------|
| **Documents** | 63 legal documents |
| **Chunks** | 4,512+ enriched chunks |
| **Embeddings** | 3,072 dimensions (native) |
| **Upload System** | âœ… Multi-file upload with auto-classification |
| **Database** | PostgreSQL 18 + pgvector 0.8.1 |
| **API Endpoints** | Upload, Status Tracking, Query & Search |
| **Processing Pipeline** | DOCX/PDF â†’ Classification â†’ Chunking â†’ Embedding â†’ Storage |
| **Background Tasks** | Async processing with progress tracking |

---

## ğŸ—‚ï¸ Project Structure

```
RAG-bidding/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Raw DOCX/DOC files
â”‚   â”œâ”€â”€ processed/              # Enriched chunks (JSONL)
â”‚   â”‚   â”œâ”€â”€ chunks/            # 4,512 chunks with metadata
â”‚   â”‚   â””â”€â”€ metadata/          # Document metadata
â”‚   â””â”€â”€ outputs/               # Processing reports
â”œâ”€â”€ documents/                  # ğŸ“š Documentation
â”‚   â”œâ”€â”€ setup/                 # Setup guides
â”‚   â”œâ”€â”€ technical/             # Architecture & optimization
â”‚   â”œâ”€â”€ phase-reports/         # Project milestones
â”‚   â”œâ”€â”€ verification/          # Test reports
â”‚   â””â”€â”€ planning/              # Roadmaps & analysis
â”œâ”€â”€ scripts/                    # ğŸ”§ Utility scripts
â”‚   â”œâ”€â”€ batch_reprocess_all.py        # Batch processing with enrichment
â”‚   â”œâ”€â”€ import_processed_chunks.py    # Import to database
â”‚   â”œâ”€â”€ bootstrap_db.py              # Initialize database
â”‚   â””â”€â”€ test/                        # Test suite
â”‚       â”œâ”€â”€ integration/             # E2E tests
â”‚       â”œâ”€â”€ preprocessing/           # Document loading tests
â”‚       â”œâ”€â”€ chunking/               # Chunking strategy tests
â”‚       â””â”€â”€ pipeline/               # Pipeline tests
â”œâ”€â”€ src/                        # ğŸ“¦ Source code
â”‚   â”œâ”€â”€ api/                   # FastAPI endpoints
â”‚   â”œâ”€â”€ preprocessing/         # Document processing
â”‚   â”‚   â”œâ”€â”€ loaders/          # DOCX/DOC/PDF loaders
â”‚   â”‚   â”œâ”€â”€ parsers/          # Document parsers
â”‚   â”‚   â””â”€â”€ enrichment/       # Semantic enrichment
â”‚   â”œâ”€â”€ chunking/              # Chunking strategies
â”‚   â”œâ”€â”€ embedding/             # Embeddings & vector store
â”‚   â”œâ”€â”€ retrieval/             # Retrieval & reranking
â”‚   â””â”€â”€ generation/            # LLM generation
â”œâ”€â”€ tests/                      # ğŸ§ª Component tests
â”‚   â”œâ”€â”€ integration/           # Multi-component tests
â”‚   â”œâ”€â”€ retrieval/            # Search & filtering
â”‚   â””â”€â”€ reranking/            # Reranking models
â”œâ”€â”€ .env.example               # Environment template
â”œâ”€â”€ environment.yaml           # Conda environment
â””â”€â”€ setup_db.sh               # Database setup script
```

---

## ğŸ”‘ Environment Configuration

### Essential Variables

```bash
# Database (Required)
DATABASE_URL=postgresql://rag_user:password@localhost:5432/rag_bidding_v2
LC_COLLECTION=docs

# OpenAI API (Required)
OPENAI_API_KEY=sk-your-openai-api-key-here

# Embedding & LLM Models
EMBED_MODEL=text-embedding-3-large  # 3072 dims (native)
LLM_MODEL=gpt-4o-mini

# Retrieval Configuration
RETRIEVAL_K=5
RAG_MODE=balanced  # fast, balanced, quality
ENABLE_RERANKING=true
RERANKER_MODEL=BAAI/bge-reranker-v2-m3
```

**Full reference:** See [.env.example](.env.example)

---

## ğŸš€ Usage

### Start API Server

```bash
conda activate venv  # Updated environment name
chmod +x start_server.sh
./start_server.sh
# OR manually: uvicorn src.api.main:app --reload --host 0.0.0.0 --port 8000
```

### Upload New Documents (NEW!)

```bash
# Via API (Postman or curl)
curl -X POST "http://localhost:8000/upload/files" \
  -F "files=@path/to/document.docx" \
  -F "batch_name=my_batch" \
  -F "auto_classify=true"

# Check processing status
curl "http://localhost:8000/upload/status?upload_id={upload_id}"
```

### Query Documents

```bash
# Via API - Ask questions
curl -X POST "http://localhost:8000/ask" \
  -H "Content-Type: application/json" \
  -d '{"question": "Quy trÃ¬nh Ä‘áº¥u tháº§u rá»™ng rÃ£i lÃ  gÃ¬?", "mode": "balanced"}'

# Check system stats
curl "http://localhost:8000/stats"

# Health check
curl "http://localhost:8000/health"
```

### Process Documents (Batch - Legacy)

```bash
# Add DOCX files to data/raw/
# Then run batch processing with enrichment
python scripts/batch_reprocess_all.py \
  --raw-dir data/raw \
  --output-dir data/processed

# Import to database
python scripts/import_processed_chunks.py \
  --chunks-dir data/processed/chunks
```

---

## ï¿½ Documentation

### Setup Guides
- ğŸš€ [Quick Setup (10 min)](documents/setup/QUICK_SETUP.md)
- ğŸ“– [Complete Database Setup](documents/setup/DATABASE_SETUP.md)
- âš™ï¸ [Environment Configuration](.env.example)

### Technical Documentation
- ğŸ—ï¸ [Pipeline Integration Summary](documents/technical/PIPELINE_INTEGRATION_SUMMARY.md)
- âš¡ [Optimization Strategy](documents/technical/OPTIMIZATION_STRATEGY.md)
- ğŸ’¾ [Cache & HNSW Explained](documents/technical/CACHE_AND_HNSW_EXPLAINED.md)

### Development
- ğŸ—ºï¸ [Roadmap](documents/planning/preprocess-plan/ROADMAP.md)
- ğŸ“Š [Architecture](documents/planning/preprocess-plan/PREPROCESSING_ARCHITECTURE.md)
- ğŸ§ª [Test Suite](scripts/test/README.md)

---

## ğŸ› ï¸ Technology Stack

| Category | Technology |
|----------|-----------|
| **Language** | Python 3.10 |
| **Framework** | FastAPI, LangChain 0.3.x |
| **Database** | PostgreSQL 18 + pgvector |
| **Embeddings** | OpenAI text-embedding-3-large (3072d) |
| **LLM** | GPT-4o-mini |
| **Reranker** | BGE-reranker-v2-m3 (Vietnamese) |
| **NLP** | spaCy, sentence-transformers |
| **Caching** | Redis (optional), PostgreSQL |

---

## ğŸ§ª Testing

```bash
# Run all tests
python -m pytest scripts/test/ -v

# Run specific category
python -m pytest scripts/test/integration/ -v
python -m pytest tests/reranking/ -v

# Run single test
python scripts/test/integration/test_e2e_pipeline.py
```

**See:** [Test Suite Documentation](scripts/test/README.md)

---

## ğŸ“ˆ Performance

| Operation | Time | Notes |
|-----------|------|-------|
| **Document Processing** | ~0.35s/file | With enrichment |
| **Chunk Import** | ~20 chunks/s | 3072-dim embeddings |
| **Vector Search** | ~50ms | Native cosine similarity |
| **With Reranking** | ~200ms | BGE-reranker-v2-m3 |
| **Full Pipeline** | ~250ms | Retrieval + Rerank + Generation |

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'feat: add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open Pull Request

---

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

---

## ğŸ†˜ Support

- **Setup Issues:** Check [Troubleshooting Guide](documents/setup/DATABASE_SETUP.md#-troubleshooting)
- **Documentation:** Browse [documents/](documents/) folder
- **GitHub Issues:** Report bugs or request features
- **Quick Help:** See [Quick Setup Guide](documents/setup/QUICK_SETUP.md)

---

**Version:** 2.0.0  
**Last Updated:** November 4, 2025  
**Status:** âœ… Production Ready

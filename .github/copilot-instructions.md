# GitHub Copilot Instructions - RAG Bidding System

## ğŸ¯ Project Overview

RAG-based Vietnamese Legal Document Q&A system vá»›i semantic search, document reranking, vÃ  multi-tier caching.

## ğŸ—ï¸ Architecture & Key Components

### Core Pipeline Flow

```
Query â†’ Enhancement (Multi-Query/HyDE/Step-Back) â†’ Vector Retrieval â†’ Reranking (BGE) â†’ LLM Generation
```

**4 RAG Modes** (`src/config/models.py`):

- `fast`: No enhancement, no reranking (~1s)
- `balanced`: Multi-Query + Step-Back + BGE reranking (~2-3s) â­ Default
- `quality`: All 4 strategies + RRF fusion (~3-5s)
- `adaptive`: Dynamic K selection based on query complexity

### Reranking Strategy (PRODUCTION)

**Currently Used**: `BGEReranker` (`src/retrieval/ranking/bge_reranker.py`)

- Model: `BAAI/bge-reranker-v2-m3` (fine-tuned cross-encoder)
- Device: Auto-detect GPU/CPU
- Batch size: 32 (GPU) / 16 (CPU)
- Latency: ~100-150ms cho 10 docs

**Alternatives** (chÆ°a implement production):

- `cross_encoder_reranker.py`: Empty file
- `legal_score_reranker.py`: Empty file
- `llm_reranker.py`: Empty file (chá»‰ demo)

**Industry Practice**:

- Perplexity: Cohere Rerank API
- You.com: Custom reranker
- Typical flow: Retrieve 20-50 docs â†’ Rerank â†’ Top 5

## ğŸ”§ Development Workflows

### Environment Setup

```bash
conda activate venv  # NOT rag-bidding!
./start_server.sh    # uvicorn on port 8000
```

### Configuration Management

**Settings**: `src/config/models.py`

- Dataclass-based settings
- Environment variables via `.env`
- Preset modes: `RAGPresets.get_balanced_mode()`

## ğŸš« Avoid These Mistakes

1. **KhÃ´ng modify code trong `*-deprecated` folders**
2. **KhÃ´ng táº¡o retriever/reranker má»›i má»—i request** (memory leak)
3. **KhÃ´ng run API tests mÃ  khÃ´ng start server trÆ°á»›c**
4. **KhÃ´ng assume environment name lÃ  "rag-bidding"** (thá»±c táº¿ lÃ  "venv")
5. **KhÃ´ng skip reranker singleton khi optimize performance**

## ğŸ” Debugging Tips

### Memory Issues

```bash
# Check model cache
ls -lh ~/.cache/huggingface/hub/  # BGE model ~1.2GB

# Monitor GPU memory
nvidia-smi -l 1

# Clear CUDA cache (náº¿u OOM)
# ThÃªm vÃ o BGEReranker.rerank():
torch.cuda.empty_cache()
```

### Performance Profiling

```python
# Logs hiá»‡n cÃ³ timing info:
# [2025-11-08 08:55:35] [INFO] src.retrieval.ranking.bge_reranker:
# Initializing reranker: BAAI/bge-reranker-v2-m3
```

## Nhá»¯ng Ä‘iá»u cáº§n lÆ°u Ã½:

- Khi cÃ³ lá»—i xáº£y ra, kiá»ƒm tra code logic liÃªn quan Ä‘á»ƒ hiá»ƒu nguyÃªn nhÃ¢n gá»‘c rá»…
- Æ¯u tiÃªn singleton pattern cho heavy resources (embeddings, rerankers)
- Performance tests pháº£i Ä‘Æ°á»£c monitor memory usage
- API changes cáº§n update cáº£ test suite

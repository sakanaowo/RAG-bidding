# ğŸ“– Thuvienphapluat Crawler Module

Module Python Ä‘á»ƒ crawl vÃ  trÃ­ch xuáº¥t ná»™i dung tá»« website thuvienphapluat.vn, chuyá»ƒn Ä‘á»•i sang Ä‘á»‹nh dáº¡ng Markdown.

## ğŸš€ CÃ i Ä‘áº·t

### 1. CÃ i Ä‘áº·t dependencies:
```bash
pip install -r requirements.txt
```

### 2. Import module:
```python
from thuvienphapluat_crawler import ThuvienphapluatCrawler, crawl_and_export_to_markdown, batch_crawl_urls
```

## ğŸ¯ TÃ­nh nÄƒng chÃ­nh

- âœ… **Crawl ná»™i dung** tá»« thuvienphapluat.vn
- âœ… **TrÃ­ch xuáº¥t ná»™i dung sáº¡ch** tá»« div cÃ³ class 'content1'
- âœ… **Chuyá»ƒn Ä‘á»•i sang Markdown** vá»›i headers, paragraphs, lists
- âœ… **Export ra file .md** vá»›i metadata vÃ  timestamp
- âœ… **Há»— trá»£ crawl hÃ ng loáº¡t** nhiá»u URL
- âœ… **Error handling** vÃ  logging chi tiáº¿t
- âœ… **Rate limiting** Ä‘á»ƒ trÃ¡nh bá»‹ block

## ğŸ“š CÃ¡ch sá»­ dá»¥ng

### 1. Sá»­ dá»¥ng convenience functions (Ä‘Æ¡n giáº£n)

```python
from thuvienphapluat_crawler import crawl_and_export_to_markdown, batch_crawl_urls

# Crawl má»™t URL
url = 'https://thuvienphapluat.vn/van-ban/Dau-tu/Nghi-dinh-214-2025-ND-CP-huong-dan-Luat-Dau-thau-ve-lua-chon-nha-thau-668157.aspx'
output_file = crawl_and_export_to_markdown(url, output_dir="./data/")

# Crawl nhiá»u URL
urls = [
    'https://thuvienphapluat.vn/van-ban/url1',
    'https://thuvienphapluat.vn/van-ban/url2',
]
results = batch_crawl_urls(urls, output_dir="./data/", delay=3)
```

### 2. Sá»­ dá»¥ng class (nÃ¢ng cao)

```python
from thuvienphapluat_crawler import ThuvienphapluatCrawler

# Khá»Ÿi táº¡o crawler vá»›i cáº¥u hÃ¬nh tÃ¹y chá»‰nh
crawler = ThuvienphapluatCrawler(
    user_agent='Custom User Agent',
    timeout=60,
    default_output_dir='./custom_data/'
)

# Crawl má»™t URL
result = crawler.crawl_single_url('https://thuvienphapluat.vn/van-ban/...')

# Crawl nhiá»u URL vá»›i delay tÃ¹y chá»‰nh
urls = ['url1', 'url2', 'url3']
results = crawler.crawl_multiple_urls(urls, delay=5)

# Chá»‰ trÃ­ch xuáº¥t ná»™i dung khÃ´ng export
soup = BeautifulSoup(html_content, 'html.parser')
content_div = soup.find('div', class_='content1')
clean_content = crawler.extract_clean_content(content_div)
```

## ğŸ“ Cáº¥u trÃºc Output

File markdown Ä‘Æ°á»£c táº¡o cÃ³ cáº¥u trÃºc:

```markdown
---
title: "Ná»™i dung tá»« thuvienphapluat.vn"
url: https://thuvienphapluat.vn/van-ban/...
crawled_at: 2025-09-29 12:09:57
source: thuvienphapluat.vn
---

# Ná»™i dung chÃ­nh á»Ÿ Ä‘Ã¢y...
```

TÃªn file: `{original_name}_{timestamp}.md`

## ğŸ”§ API Reference

### Class: ThuvienphapluatCrawler

#### Constructor
```python
ThuvienphapluatCrawler(
    user_agent: str = 'Mozilla/5.0...',
    timeout: int = 30,
    default_output_dir: str = "../processed/"
)
```

#### Methods

**crawl_single_url(url, output_dir=None)**
- Crawl má»™t URL vÃ  export sang markdown
- Returns: ÄÆ°á»ng dáº«n file Ä‘Ã£ táº¡o hoáº·c None

**crawl_multiple_urls(urls, output_dir=None, delay=2)**
- Crawl nhiá»u URL vá»›i delay
- Returns: List cÃ¡c káº¿t quáº£ crawling

**extract_clean_content(content_div)**
- TrÃ­ch xuáº¥t ná»™i dung sáº¡ch tá»« BeautifulSoup element
- Returns: String markdown

**export_to_markdown(content, url, output_dir=None)**
- Export ná»™i dung ra file markdown
- Returns: ÄÆ°á»ng dáº«n file Ä‘Ã£ táº¡o hoáº·c None

### Convenience Functions

**crawl_and_export_to_markdown(url, output_dir="../processed/")**
- Function Ä‘Æ¡n giáº£n Ä‘á»ƒ crawl má»™t URL

**batch_crawl_urls(urls, output_dir="../processed/", delay=2)**  
- Function Ä‘Æ¡n giáº£n Ä‘á»ƒ crawl nhiá»u URL

## âš ï¸ LÆ°u Ã½ quan trá»ng

1. **Respect robots.txt** - LuÃ´n tuÃ¢n thá»§ robots.txt cá»§a website
2. **Rate limiting** - Sá»­ dá»¥ng delay há»£p lÃ½ (2-5 giÃ¢y) giá»¯a cÃ¡c request
3. **Error handling** - Kiá»ƒm tra return value trÆ°á»›c khi sá»­ dá»¥ng
4. **Content validation** - Verify ná»™i dung trÆ°á»›c khi process tiáº¿p

## ğŸ“Š Examples vá»›i káº¿t quáº£ thá»±c táº¿

```python
# Test vá»›i URL thá»±c táº¿
url = 'https://thuvienphapluat.vn/van-ban/Dau-tu/Nghi-dinh-214-2025-ND-CP-huong-dan-Luat-Dau-thau-ve-lua-chon-nha-thau-668157.aspx'

result = crawl_and_export_to_markdown(url)
# Output: 
# ğŸ”„ Báº¯t Ä‘áº§u crawl: https://thuvienphapluat.vn/van-ban/...
# ğŸ“¡ Status code: 200
# âœ… TÃ¬m tháº¥y ná»™i dung
# ğŸ“ ÄÃ£ trÃ­ch xuáº¥t 423621 kÃ½ tá»±
# âœ… ÄÃ£ export thÃ nh cÃ´ng vÃ o file: ../processed/Nghi-dinh-214-2025-ND-CP-huong-dan-Luat-Dau-thau-ve-lua-chon-nha-thau-668157_20250929_120957.md
# ğŸ“„ KÃ­ch thÆ°á»›c file: 573,613 bytes
```

## ğŸ› ï¸ Troubleshooting

**Lá»—i HTTP 403/429:**
- TÄƒng delay giá»¯a cÃ¡c request
- Thay Ä‘á»•i User-Agent
- Kiá»ƒm tra robots.txt

**KhÃ´ng tÃ¬m tháº¥y ná»™i dung:**
- Website cÃ³ thá»ƒ Ä‘Ã£ thay Ä‘á»•i cáº¥u trÃºc HTML
- Kiá»ƒm tra CSS selector 'div.content1'

**Lá»—i encoding:**
- File Ä‘Æ°á»£c lÆ°u vá»›i encoding UTF-8
- Äáº£m báº£o há»‡ thá»‘ng há»— trá»£ UTF-8

## ğŸ”„ PhÃ¡t triá»ƒn vÃ  má»Ÿ rá»™ng

Module cÃ³ thá»ƒ Ä‘Æ°á»£c má»Ÿ rá»™ng Ä‘á»ƒ:
- Há»— trá»£ thÃªm website khÃ¡c
- ThÃªm format output (JSON, XML, etc.)  
- Cáº£i thiá»‡n parsing logic
- ThÃªm tÃ­nh nÄƒng cache
- TÃ­ch há»£p database storage

## ğŸ“ License

MIT License - CÃ³ thá»ƒ sá»­ dá»¥ng tá»± do cho dá»± Ã¡n cÃ¡ nhÃ¢n vÃ  thÆ°Æ¡ng máº¡i.
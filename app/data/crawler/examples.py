#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Example script cho Thuvienphapluat Crawler Module

File nÃ y minh há»a cÃ¡c cÃ¡ch sá»­ dá»¥ng khÃ¡c nhau cá»§a crawler module.
"""

import os
import sys

# ThÃªm thÆ° má»¥c hiá»‡n táº¡i vÃ o Python path
sys.path.insert(0, os.path.dirname(__file__))

from thuvienphapluat_crawler import (
    ThuvienphapluatCrawler,
    crawl_and_export_to_markdown,
    batch_crawl_urls,
)


def example_1_simple_usage():
    """
    Example 1: Sá»­ dá»¥ng Ä‘Æ¡n giáº£n vá»›i convenience functions
    """
    print("ğŸ“– Example 1: Sá»­ dá»¥ng Ä‘Æ¡n giáº£n")
    print("=" * 40)

    # URL Ä‘á»ƒ test
    url = "https://thuvienphapluat.vn/van-ban/Dau-tu/Nghi-dinh-214-2025-ND-CP-huong-dan-Luat-Dau-thau-ve-lua-chon-nha-thau-668157.aspx"

    # Crawl vÃ  export
    result = crawl_and_export_to_markdown(url=url, output_dir="./examples_output/")

    if result:
        print(f"âœ… ThÃ nh cÃ´ng! File Ä‘Æ°á»£c lÆ°u táº¡i: {result}")
    else:
        print("âŒ Crawl tháº¥t báº¡i!")

    return result is not None


def example_2_batch_crawling():
    """
    Example 2: Crawl nhiá»u URL cÃ¹ng lÃºc
    """
    print("\nğŸ“– Example 2: Batch crawling")
    print("=" * 40)

    # Danh sÃ¡ch URL (chá»‰ dÃ¹ng 1 URL Ä‘á»ƒ demo, trÃ¡nh spam)
    urls = [
        "https://thuvienphapluat.vn/van-ban/Dau-tu/Nghi-dinh-214-2025-ND-CP-huong-dan-Luat-Dau-thau-ve-lua-chon-nha-thau-668157.aspx",
        # CÃ³ thá»ƒ thÃªm URLs khÃ¡c á»Ÿ Ä‘Ã¢y
    ]

    # Batch crawl vá»›i delay 2 giÃ¢y
    results = batch_crawl_urls(urls=urls, output_dir="./examples_output/", delay=2)

    # Kiá»ƒm tra káº¿t quáº£
    successful = sum(1 for r in results if r["success"])
    print(f"\nKáº¿t quáº£: {successful}/{len(urls)} URLs thÃ nh cÃ´ng")

    return successful > 0


def example_3_advanced_usage():
    """
    Example 3: Sá»­ dá»¥ng nÃ¢ng cao vá»›i ThuvienphapluatCrawler class
    """
    print("\nğŸ“– Example 3: Sá»­ dá»¥ng nÃ¢ng cao")
    print("=" * 40)

    # Khá»Ÿi táº¡o crawler vá»›i cáº¥u hÃ¬nh tÃ¹y chá»‰nh
    crawler = ThuvienphapluatCrawler(
        user_agent="RAG-Bidding-Bot/1.0",
        timeout=60,
        default_output_dir="./examples_output/",
    )

    # URL Ä‘á»ƒ test
    url = "https://thuvienphapluat.vn/van-ban/Dau-tu/Nghi-dinh-214-2025-ND-CP-huong-dan-Luat-Dau-thau-ve-lua-chon-nha-thau-668157.aspx"

    # Crawl single URL
    result = crawler.crawl_single_url(url)

    if result:
        print(f"âœ… Advanced crawl thÃ nh cÃ´ng! File: {result}")

        # Hiá»ƒn thá»‹ thÃ´ng tin file
        file_size = os.path.getsize(result)
        print(f"ğŸ“„ KÃ­ch thÆ°á»›c file: {file_size:,} bytes")

        return True
    else:
        print("âŒ Advanced crawl tháº¥t báº¡i!")
        return False


def example_4_custom_processing():
    """
    Example 4: Xá»­ lÃ½ tÃ¹y chá»‰nh - chá»‰ trÃ­ch xuáº¥t ná»™i dung khÃ´ng lÆ°u file
    """
    print("\nğŸ“– Example 4: Custom processing")
    print("=" * 40)

    import requests
    from bs4 import BeautifulSoup

    # Khá»Ÿi táº¡o crawler
    crawler = ThuvienphapluatCrawler()

    url = "https://thuvienphapluat.vn/van-ban/Dau-tu/Nghi-dinh-214-2025-ND-CP-huong-dan-Luat-Dau-thau-ve-lua-chon-nha-thau-668157.aspx"

    try:
        # Manual request
        response = requests.get(url, headers=crawler.headers, timeout=crawler.timeout)
        print(f"ğŸ“¡ Response status: {response.status_code}")

        if response.status_code == 200:
            # Parse HTML
            soup = BeautifulSoup(response.content, "html.parser")
            content_div = soup.find("div", class_="content1")

            if content_div:
                # Chá»‰ trÃ­ch xuáº¥t ná»™i dung, khÃ´ng lÆ°u file
                clean_content = crawler.extract_clean_content(content_div)

                print(f"ğŸ“ ÄÃ£ trÃ­ch xuáº¥t {len(clean_content)} kÃ½ tá»±")
                print(f"ğŸ“„ Preview ná»™i dung (500 kÃ½ tá»± Ä‘áº§u):")
                print("-" * 40)
                print(
                    clean_content[:500] + "..."
                    if len(clean_content) > 500
                    else clean_content
                )
                print("-" * 40)

                # CÃ³ thá»ƒ xá»­ lÃ½ ná»™i dung theo Ã½ muá»‘n táº¡i Ä‘Ã¢y
                # VÃ­ dá»¥: lÆ°u vÃ o database, gá»­i qua API, etc.

                return True
            else:
                print("âŒ KhÃ´ng tÃ¬m tháº¥y ná»™i dung")
                return False
        else:
            print(f"âŒ HTTP Error: {response.status_code}")
            return False

    except Exception as e:
        print(f"âŒ Lá»—i: {str(e)}")
        return False


def main():
    """
    Main function Ä‘á»ƒ cháº¡y táº¥t cáº£ examples
    """
    print("ğŸš€ Thuvienphapluat Crawler - Examples")
    print("=" * 50)

    # Táº¡o thÆ° má»¥c output
    os.makedirs("./examples_output/", exist_ok=True)

    examples = [
        ("Simple Usage", example_1_simple_usage),
        ("Batch Crawling", example_2_batch_crawling),
        ("Advanced Usage", example_3_advanced_usage),
        ("Custom Processing", example_4_custom_processing),
    ]

    results = []

    for name, example_func in examples:
        try:
            success = example_func()
            results.append((name, success))
        except Exception as e:
            print(f"âŒ Lá»—i trong {name}: {str(e)}")
            results.append((name, False))

    # TÃ³m táº¯t
    print("\n" + "=" * 50)
    print("ğŸ“Š Káº¾T QUáº¢ EXAMPLES:")
    print("=" * 50)

    for name, success in results:
        status = "âœ… OK" if success else "âŒ FAIL"
        print(f"{status} - {name}")

    print("\nğŸ“ Examples hoÃ n thÃ nh!")
    print("ğŸ“ Kiá»ƒm tra thÆ° má»¥c './examples_output/' Ä‘á»ƒ xem cÃ¡c file Ä‘Ã£ táº¡o.")

    # Hiá»ƒn thá»‹ danh sÃ¡ch file Ä‘Ã£ táº¡o
    output_dir = "./examples_output/"
    if os.path.exists(output_dir):
        files = [f for f in os.listdir(output_dir) if f.endswith(".md")]
        if files:
            print(f"\nğŸ“„ CÃ¡c file markdown Ä‘Ã£ táº¡o ({len(files)} files):")
            for file in files:
                file_path = os.path.join(output_dir, file)
                file_size = os.path.getsize(file_path)
                print(f"  - {file} ({file_size:,} bytes)")


if __name__ == "__main__":
    main()

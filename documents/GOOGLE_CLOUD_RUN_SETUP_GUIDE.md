# H∆∞·ªõng D·∫´n Tri·ªÉn Khai RAG-Bidding Backend l√™n Google Cloud Run

> **üìÖ C·∫≠p nh·∫≠t**: 26/01/2026  
> **üîç Tr·∫°ng th√°i**: ƒê√£ ph√¢n t√≠ch to√†n b·ªô codebase v√† verified

---

## üéØ EXECUTIVE SUMMARY - ƒê·ªçc Tr∆∞·ªõc Khi B·∫Øt ƒê·∫ßu

### ‚ö†Ô∏è Critical Decisions (QUAN TR·ªåNG)

| Quy·∫øt ƒë·ªãnh | Khuy·∫øn ngh·ªã | L√Ω do |
|------------|-------------|-------|
| **Gunicorn Workers** | `GUNICORN_WORKERS=1` | M·ªói worker load BGE model (~1.5GB) ri√™ng bi·ªát |
| **Memory** | `4Gi` minimum | BGE model + FastAPI + buffers |
| **Min Instances** | `1` (production) | Tr√°nh cold start 50-60s (do BGE loading) |
| **Scaling** | Cloud Run instances | Kh√¥ng d√πng nhi·ªÅu workers trong 1 container |

### üìä Quick Start - Ch·ªçn Configuration

| Scenario | Memory | Workers | Reranking | Command |
|----------|--------|---------|-----------|---------|
| **Dev/Test** | 2Gi | 1 | false | `--memory=2Gi --set-env-vars="ENABLE_RERANKING=false"` |
| **Staging** | 4Gi | 1 | bge | `--memory=4Gi --min-instances=0` |
| **Prod (Balanced)** | 4Gi | 1 | bge | `--memory=4Gi --min-instances=1` |
| **Prod (High Quality)** | 4Gi | 1 | openai | `--memory=4Gi --set-env-vars="RERANKER_TYPE=openai"` |
| **Prod (Max Perf)** | 8Gi | 1 | bge | `--memory=8Gi --cpu=4 --min-instances=2` |

### ‚úÖ Fallback Mechanism (ƒê√£ Verified)

```
BGE GPU OOM ‚Üí BGE CPU ‚Üí OpenAI API ‚Üí Dummy scores
      ‚Üì              ‚Üì            ‚Üì
   (1.5GB)      (1.5GB)       (API call)
```

**K·∫øt lu·∫≠n**: System t·ª± ƒë·ªông fallback, **kh√¥ng c·∫ßn lo crash** khi OOM.

---

## üìã Th√¥ng Tin Project

| Th√¥ng s·ªë         | Gi√° tr·ªã                                                             |
| ---------------- | ------------------------------------------------------------------- |
| **Framework**    | FastAPI 0.112.4                                                     |
| **Python**       | 3.10                                                                |
| **Database**     | PostgreSQL 15+ v·ªõi pgvector extension (NullPool - no connection pooling) |
| **Cache**        | Redis (5 databases: DB0=cache, DB1=sessions, DB2=answers, DB3=semantic, DB4=rate-limit) |
| **ML Models**    | BGE Reranker (BAAI/bge-reranker-v2-m3) v·ªõi auto-fallback to OpenAI |
| **Entry Point**  | `src.api.main:app`                                                  |
| **Default Port** | 8000                                                                |
| **Cold Start**   | ~50-60s (v·ªõi BGE model loading)                                     |

## M·ª•c L·ª•c

1. [T·ªïng Quan](#1-t·ªïng-quan)
2. [Y√™u C·∫ßu Tr∆∞·ªõc Khi B·∫Øt ƒê·∫ßu](#2-y√™u-c·∫ßu-tr∆∞·ªõc-khi-b·∫Øt-ƒë·∫ßu)
3. [C·∫•u H√¨nh Google Cloud Project](#3-c·∫•u-h√¨nh-google-cloud-project)
4. [T·∫°o Dockerfile cho Backend](#4-t·∫°o-dockerfile-cho-backend)
5. [Build v√† Push Container Image](#5-build-v√†-push-container-image)
6. [Deploy l√™n Cloud Run](#6-deploy-l√™n-cloud-run)
7. [C·∫•u H√¨nh K·∫øt N·ªëi Database (Cloud SQL)](#7-c·∫•u-h√¨nh-k·∫øt-n·ªëi-database-cloud-sql)
8. [C·∫•u H√¨nh Redis (Memorystore)](#8-c·∫•u-h√¨nh-redis-memorystore)
9. [C·∫•u H√¨nh Secret Manager](#9-c·∫•u-h√¨nh-secret-manager)
10. [C·∫•u H√¨nh Domain v√† SSL](#10-c·∫•u-h√¨nh-domain-v√†-ssl)
11. [Monitoring v√† Logging](#11-monitoring-v√†-logging)
12. [CI/CD v·ªõi Cloud Build](#12-cicd-v·ªõi-cloud-build)
13. [Troubleshooting](#13-troubleshooting)

---

## 1. T·ªïng Quan

### 1.1 Ki·∫øn tr√∫c RAG-Bidding System

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      Google Cloud Run                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ  FastAPI Application (src.api.main:app)                   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ‚îÄ /api/auth/* (Authentication - JWT)                   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ‚îÄ /api/conversations/* (Chat with RAG)                 ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ‚îÄ /api/documents/* (Document Management)               ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ‚îÄ /api/analytics/* (Usage Analytics)                   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ‚îÄ /api/cache/* (Cache Management)                      ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ‚îÄ /ask (Quick Q&A - No Auth)                          ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ /health, /stats, /features (System)                  ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ                    ‚îÇ                    ‚îÇ
          ‚ñº                    ‚ñº                    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Cloud SQL     ‚îÇ  ‚îÇ   Memorystore   ‚îÇ  ‚îÇ   OpenAI API    ‚îÇ
‚îÇ   PostgreSQL    ‚îÇ  ‚îÇ     Redis       ‚îÇ  ‚îÇ   Embeddings    ‚îÇ
‚îÇ   + pgvector    ‚îÇ  ‚îÇ   5 Databases   ‚îÇ  ‚îÇ   + GPT-4o-mini ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 1.2 ∆Øu ƒëi·ªÉm c·ªßa Cloud Run:

- **Serverless**: Kh√¥ng c·∫ßn qu·∫£n l√Ω infrastructure
- **Auto-scaling**: T·ª± ƒë·ªông scale t·ª´ 0 ƒë·∫øn N instances
- **Pay-per-use**: Ch·ªâ tr·∫£ ti·ªÅn khi c√≥ request
- **HTTPS m·∫∑c ƒë·ªãnh**: SSL/TLS ƒë∆∞·ª£c cung c·∫•p t·ª± ƒë·ªông
- **Container-based**: Ch·∫°y b·∫•t k·ª≥ language/framework n√†o
- **GPU Support**: H·ªó tr·ª£ NVIDIA L4 GPU cho BGE Reranker (optional)

---

## 2. Y√™u C·∫ßu Tr∆∞·ªõc Khi B·∫Øt ƒê·∫ßu

### 2.1 C√†i ƒë·∫∑t Google Cloud SDK

```bash
# Tr√™n Linux/macOS
curl https://sdk.cloud.google.com | bash
exec -l $SHELL

# Ho·∫∑c tr√™n Ubuntu/Debian
sudo apt-get install apt-transport-https ca-certificates gnupg curl
curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo gpg --dearmor -o /usr/share/keyrings/cloud.google.gpg
echo "deb [signed-by=/usr/share/keyrings/cloud.google.gpg] https://packages.cloud.google.com/apt cloud-sdk main" | sudo tee -a /etc/apt/sources.list.d/google-cloud-sdk.list
sudo apt-get update && sudo apt-get install google-cloud-cli
```

### 2.2 ƒêƒÉng nh·∫≠p v√† c·∫•u h√¨nh

```bash
# ƒêƒÉng nh·∫≠p v√†o Google Cloud
gcloud auth login

# ƒê·∫∑t project m·∫∑c ƒë·ªãnh
gcloud config set project YOUR_PROJECT_ID

# X√°c minh c·∫•u h√¨nh
gcloud config list
```

### 2.3 Y√™u c·∫ßu kh√°c

- T√†i kho·∫£n Google Cloud v·ªõi billing enabled
- Docker ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t (n·∫øu build local)
- RAG-Bidding backend code (FastAPI + LangChain)

### 2.4 Danh s√°ch Environment Variables c·∫ßn thi·∫øt

Project RAG-Bidding y√™u c·∫ßu c√°c bi·∫øn m√¥i tr∆∞·ªùng sau:

| Bi·∫øn                 | M√¥ t·∫£                               | V√≠ d·ª•                                         |
| -------------------- | ----------------------------------- | --------------------------------------------- |
| `DATABASE_URL`       | PostgreSQL connection string        | `postgresql+psycopg://user:pass@host:5432/db` |
| `OPENAI_API_KEY`     | OpenAI API key cho embeddings & LLM | `sk-proj-...`                                 |
| `JWT_SECRET_KEY`     | Secret key cho JWT authentication   | `your-256-bit-secret`                         |
| `LC_COLLECTION`      | LangChain collection name           | `docs`                                        |
| `EMBED_MODEL`        | OpenAI embedding model              | `text-embedding-3-small`                      |
| `LLM_MODEL`          | OpenAI LLM model                    | `gpt-4o-mini`                                 |
| `REDIS_HOST`         | Redis server host                   | `10.0.0.3` (internal IP)                      |
| `REDIS_PORT`         | Redis server port                   | `6379`                                        |
| `CORS_ORIGINS`       | Allowed CORS origins                | `https://your-frontend.com`                   |
| `ENABLE_REDIS_CACHE` | Enable Redis caching                | `true`                                        |
| `ENABLE_RERANKING`   | Enable BGE reranker                 | `true`                                        |
| `RERANKER_TYPE`      | Force reranker type                 | `openai` (skip BGE, go direct to API)        |
| `RAG_MODE`           | RAG processing mode                 | `balanced`                                    |

> üí° **Fallback Control**: 
> - `ENABLE_RERANKING=false`: T·∫Øt reranking ho√†n to√†n
> - `RERANKER_TYPE=openai`: B·ªè qua BGE, d√πng OpenAI API ngay t·ª´ ƒë·∫ßu  
> - `RERANKER_TYPE=bge`: Force d√πng BGE (default, c√≥ fallback to OpenAI n·∫øu OOM)

---

## 3. C·∫•u H√¨nh Google Cloud Project

### 3.1 T·∫°o Project m·ªõi (n·∫øu ch∆∞a c√≥)

**Qua Console:**

1. Truy c·∫≠p [Google Cloud Console](https://console.cloud.google.com)
2. Click v√†o dropdown project ·ªü g√≥c tr√™n b√™n tr√°i
3. Click "New Project"
4. Nh·∫≠p t√™n project v√† ch·ªçn organization (n·∫øu c√≥)
5. Click "Create"

**Qua CLI:**

```bash
gcloud projects create YOUR_PROJECT_ID --name="RAG Bidding Project"
gcloud config set project YOUR_PROJECT_ID
```

### 3.2 Enable c√°c API c·∫ßn thi·∫øt

```bash
# Enable t·∫•t c·∫£ API c·∫ßn thi·∫øt cho Cloud Run
gcloud services enable \
    run.googleapis.com \
    cloudbuild.googleapis.com \
    artifactregistry.googleapis.com \
    secretmanager.googleapis.com \
    sqladmin.googleapis.com \
    compute.googleapis.com \
    vpcaccess.googleapis.com \
    redis.googleapis.com
```

**Gi·∫£i th√≠ch:**

- `run.googleapis.com`: Cloud Run API
- `cloudbuild.googleapis.com`: Cloud Build ƒë·ªÉ build container
- `artifactregistry.googleapis.com`: L∆∞u tr·ªØ Docker images
- `secretmanager.googleapis.com`: Qu·∫£n l√Ω secrets (API keys, passwords)
- `sqladmin.googleapis.com`: Cloud SQL PostgreSQL
- `compute.googleapis.com`: Compute Engine (cho VPC)
- `vpcaccess.googleapis.com`: Serverless VPC Access
- `redis.googleapis.com`: Memorystore for Redis

### 3.3 T·∫°o Artifact Registry Repository

```bash
# T·∫°o repository ƒë·ªÉ l∆∞u Docker images
gcloud artifacts repositories create rag-bidding \
    --repository-format=docker \
    --location=asia-southeast1 \
    --description="RAG Bidding Backend Docker Repository"

# C·∫•u h√¨nh Docker ƒë·ªÉ push l√™n Artifact Registry
gcloud auth configure-docker asia-southeast1-docker.pkg.dev
```

---

## 4. T·∫°o Dockerfile cho Backend

### ‚ö†Ô∏è L∆ØU √ù QUAN TR·ªåNG: Memory v·ªõi BGE Reranker v√† Gunicorn Workers

**V·∫•n ƒë·ªÅ:**

- BGE Reranker model (`BAAI/bge-reranker-v2-m3`) c·∫ßn **~1.2-1.5GB RAM** ƒë·ªÉ load
- Gunicorn fork workers, m·ªói worker load model **RI√äNG** (kh√¥ng share gi·ªØa processes)
- `preload_app=True` ch·ªâ share code Python, **KH√îNG share model ƒë√£ load v√†o RAM**

**T√≠nh to√°n memory:**

| Workers   | Model Memory | App Overhead | T·ªïng RAM c·∫ßn |
| --------- | ------------ | ------------ | ------------ |
| 1 worker  | 1.5GB        | 500MB        | ~2GB         |
| 2 workers | 3GB          | 1GB          | ~4GB         |
| 4 workers | 6GB          | 2GB          | **~8GB**     |

### üîÑ Logic Fallback GPU -> API

**RAG-Bidding c√≥ automatic fallback mechanism r·∫•t th√¥ng minh:**

```python
# Trong bge_reranker.py - C√≥ 3 l·ªõp fallback:

# 1. INIT TIME: N·∫øu kh√¥ng load ƒë∆∞·ª£c BGE model  
try:
    _reranker_instance = BGEReranker(device="cuda")
except Exception as e:
    if "cuda out of memory" in str(e).lower():
        _cuda_oom_fallback = True
        return OpenAIReranker()  # ‚úÖ Fallback to API

# 2. RUNTIME: N·∫øu CUDA OOM khi rerank
try:
    scores = model.predict(pairs)  # BGE prediction  
except Exception as e:
    if "cuda out of memory" in str(e).lower():
        _cuda_oom_fallback = True  # Set global flag
        openai_reranker = OpenAIReranker()
        return openai_reranker.rerank(query, docs)  # ‚úÖ Immediate fallback

# 3. FUTURE CALLS: Global flag prevents BGE loading
if _cuda_oom_fallback:
    return OpenAIReranker()  # ‚úÖ Skip BGE entirely  
```

**Fallback tiers:**
1. **BGE GPU** (Fastest, 100-150ms, c·∫ßn 1.5GB VRAM)
2. **BGE CPU** (Medium, 300-500ms, c·∫ßn 1.5GB RAM)  
3. **OpenAI API** (Slowest, 500-2000ms, kh√¥ng c·∫ßn local memory)
4. **Dummy scores** (Fallback cu·ªëi, tr·∫£ v·ªÅ original order)

**Production recommendation:**

| Scenario | Memory | CPU | Env Vars |
|----------|--------|-----|----------|
| **Trust BGE** | `8Gi` | `2` | `ENABLE_RERANKING=true` |
| **OpenAI only** | `2Gi` | `1` | `ENABLE_RERANKING=true,RERANKER_TYPE=openai` |
| **No rerank** | `2Gi` | `1` | `ENABLE_RERANKING=false` |

**Khuy·∫øn ngh·ªã cho Cloud Run:**

```bash
# Option 1: 1 Worker (KHUY·∫æN NGH·ªä cho Cloud Run)
# - ƒê∆°n gi·∫£n nh·∫•t, ph√π h·ª£p auto-scaling
# - M·ªói instance = 1 worker, Cloud Run scale b·∫±ng c√°ch th√™m instances
--memory=4Gi --cpu=2 --set-env-vars="GUNICORN_WORKERS=1"

# Option 2: 2 Workers v·ªõi memory cao
# - Ph√π h·ª£p n·∫øu mu·ªën handle nhi·ªÅu concurrent requests trong 1 instance
--memory=8Gi --cpu=4 --set-env-vars="GUNICORN_WORKERS=2"

# Option 3: Disable Reranking (d√πng OpenAI fallback ho·∫∑c kh√¥ng rerank)
# - Ti·∫øt ki·ªám memory, API response nhanh h∆°n
--memory=2Gi --cpu=1 --set-env-vars="ENABLE_RERANKING=false"
```

> üí° **Best Practice cho Cloud Run**: D√πng **1 worker per container instance** v√† ƒë·ªÉ Cloud Run auto-scale b·∫±ng c√°ch spawn nhi·ªÅu instances. ƒêi·ªÅu n√†y gi√∫p:
>
> - T·∫≠n d·ª•ng auto-scaling c·ªßa Cloud Run
> - ƒê∆°n gi·∫£n h√≥a memory management
> - Tr√°nh memory issues v·ªõi large models

### 4.1 Dockerfile cho RAG-Bidding (CPU Version)

T·∫°o file `Dockerfile` trong th∆∞ m·ª•c `RAG-bidding/`:

```dockerfile
# =============================================================================
# RAG-Bidding Backend Dockerfile
# Python 3.10 + FastAPI + LangChain + BGE Reranker
# =============================================================================

FROM python:3.10-slim as builder

WORKDIR /app

# C√†i ƒë·∫∑t build dependencies
RUN apt-get update && apt-get install -y \
    build-essential \
    curl \
    libpq-dev \
    git \
    && rm -rf /var/lib/apt/lists/*

# T·∫°o virtual environment
RUN python -m venv /opt/venv
ENV PATH="/opt/venv/bin:$PATH"

# Copy v√† c√†i ƒë·∫∑t Python dependencies t·ª´ environment.yaml
# T·∫°o requirements.txt t·ª´ environment.yaml pip dependencies
COPY environment.yaml .
RUN pip install --no-cache-dir --upgrade pip && \
    pip install pyyaml && \
    python -c "import yaml; deps = yaml.safe_load(open('environment.yaml'))['dependencies']; pip_deps = [d for d in deps if isinstance(d, dict) and 'pip' in d][0]['pip']; print('\n'.join(pip_deps))" > requirements.txt && \
    pip install --no-cache-dir -r requirements.txt

# =============================================================================
# Runtime Stage
# =============================================================================
FROM python:3.10-slim as runtime

WORKDIR /app

# C√†i ƒë·∫∑t runtime dependencies
RUN apt-get update && apt-get install -y \
    libpq5 \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Copy virtual environment t·ª´ builder
COPY --from=builder /opt/venv /opt/venv
ENV PATH="/opt/venv/bin:$PATH"

# Copy application code
COPY src/ ./src/
COPY alembic/ ./alembic/
COPY alembic.ini .
COPY gunicorn_config.py .

# T·∫°o th∆∞ m·ª•c logs
RUN mkdir -p logs

# T·∫°o non-root user (security best practice)
RUN useradd -m -u 1000 appuser && chown -R appuser:appuser /app
USER appuser

# Cloud Run s·ª≠ d·ª•ng PORT environment variable
ENV PORT=8000
ENV PYTHONUNBUFFERED=1
ENV PYTHONDONTWRITEBYTECODE=1

EXPOSE $PORT

# Health check endpoint
HEALTHCHECK --interval=30s --timeout=30s --start-period=60s --retries=3 \
    CMD curl -f http://localhost:${PORT}/health || exit 1

# Start v·ªõi Gunicorn + Uvicorn workers
# ‚ö†Ô∏è QUAN TR·ªåNG: D√πng 1 worker cho Cloud Run ƒë·ªÉ ti·∫øt ki·ªám memory
# Cloud Run s·∫Ω auto-scale b·∫±ng c√°ch spawn nhi·ªÅu container instances
# N·∫øu c·∫ßn 2 workers, ph·∫£i set memory=8Gi
CMD exec gunicorn \
    --bind 0.0.0.0:${PORT} \
    --workers ${GUNICORN_WORKERS:-1} \
    --worker-class uvicorn.workers.UvicornWorker \
    --timeout 300 \
    --keep-alive 5 \
    --max-requests 1000 \
    --max-requests-jitter 100 \
    --access-logfile - \
    --error-logfile - \
    --capture-output \
    src.api.main:app
```

> ‚ö†Ô∏è **N·∫øu mu·ªën d√πng 2+ workers**, c·∫ßn set env var `GUNICORN_WORKERS=2` v√† tƒÉng memory l√™n `8Gi`:
>
> ```bash
> gcloud run deploy ... --memory=8Gi --set-env-vars="GUNICORN_WORKERS=2"
> ```

### 4.2 Dockerfile v·ªõi GPU Support (Optional - cho BGE Reranker)

N·∫øu c·∫ßn s·ª≠ d·ª•ng GPU cho BGE Reranker ƒë·ªÉ c√≥ performance t·ªët h∆°n:

```dockerfile
# =============================================================================
# RAG-Bidding Backend Dockerfile - GPU Version
# Y√™u c·∫ßu Cloud Run GPU (NVIDIA L4)
# =============================================================================

FROM nvidia/cuda:12.1-runtime-ubuntu22.04 as runtime

# Install Python 3.10
RUN apt-get update && apt-get install -y \
    python3.10 \
    python3.10-venv \
    python3-pip \
    libpq5 \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Symlink python
RUN ln -s /usr/bin/python3.10 /usr/bin/python

WORKDIR /app

# Copy requirements v√† install
COPY requirements.txt .
RUN pip install --no-cache-dir --upgrade pip && \
    pip install --no-cache-dir -r requirements.txt

# Install PyTorch v·ªõi CUDA support
RUN pip install --no-cache-dir torch==2.1.0+cu121 -f https://download.pytorch.org/whl/cu121/torch_stable.html

# Copy application
COPY src/ ./src/
COPY alembic/ ./alembic/
COPY alembic.ini .
COPY gunicorn_config.py .

RUN mkdir -p logs

RUN useradd -m -u 1000 appuser && chown -R appuser:appuser /app
USER appuser

ENV PORT=8000
ENV PYTHONUNBUFFERED=1
ENV RERANKER_DEVICE=cuda

EXPOSE $PORT

CMD exec gunicorn \
    --bind 0.0.0.0:${PORT} \
    --workers 1 \
    --worker-class uvicorn.workers.UvicornWorker \
    --timeout 300 \
    src.api.main:app
```

### 4.3 T·∫°o requirements.txt t·ª´ environment.yaml

Project s·ª≠ d·ª•ng `environment.yaml` thay v√¨ `requirements.txt`. T·∫°o script ƒë·ªÉ extract:

```bash
# T·∫°o requirements.txt t·ª´ environment.yaml
python3 << 'EOF'
import yaml

with open('environment.yaml', 'r') as f:
    env = yaml.safe_load(f)

pip_deps = None
for dep in env.get('dependencies', []):
    if isinstance(dep, dict) and 'pip' in dep:
        pip_deps = dep['pip']
        break

if pip_deps:
    with open('requirements.txt', 'w') as f:
        for pkg in pip_deps:
            f.write(f"{pkg}\n")
    print(f"Created requirements.txt with {len(pip_deps)} packages")
EOF
```

Ho·∫∑c t·∫°o `requirements.txt` tr·ª±c ti·∫øp v·ªõi c√°c dependencies ch√≠nh:

```txt
# Web Framework
fastapi==0.112.4
uvicorn[standard]==0.30.6
gunicorn==21.2.0
httpx==0.28.*

# LangChain Ecosystem
langchain==0.3.27
langchain-core==0.3.76
langchain-community==0.3.30
langchain-openai==0.3.33
langchain-postgres==0.0.15
langchain-text-splitters==0.3.11

# OpenAI
openai==1.109.1

# Database & Vector Store
psycopg==3.2.10
psycopg-binary==3.2.10
psycopg-pool==3.2.6
pgvector==0.3.6
sqlalchemy==2.0.*
alembic==1.13.*
python-multipart
redis

# Validation
pydantic[email]==2.11.9
pydantic-settings==2.11.0
python-dotenv==1.0.*

# NLP & Embeddings (BGE Reranker)
sentence-transformers==5.1.2
transformers==4.56.2
torch==2.8.0

# Document Processing
tiktoken==0.11.*
pypdf==6.0.*
python-docx==1.1.*
beautifulsoup4>=4.11.0
lxml>=4.9.0

# Data Processing
numpy==2.2.6
pandas==2.3.3

# Authentication
bcrypt==4.2.*
PyJWT==2.9.*
```

### 4.4 File .dockerignore

T·∫°o file `.dockerignore`:

```
# Git
.git
.gitignore

# Python
__pycache__
*.py[cod]
*$py.class
*.so
.Python
.env
.venv
env/
venv/
*.egg-info/
dist/
build/

# IDE
.vscode/
.idea/
*.swp
*.swo

# Testing
.pytest_cache/
tests/
*.coverage
htmlcov/

# Documentation
documents/
*.md
!README.md

# Data (kh√¥ng include trong container - mount t·ª´ Cloud Storage)
data/
logs/
*.log

# Notebooks
notebooks/
*.ipynb

# Postman
postman/

# Scripts kh√¥ng c·∫ßn thi·∫øt cho runtime
scripts/

# Local config
.env
.env.local
.env.*.local

# OS
.DS_Store
Thumbs.db
```

---

## 5. Build v√† Push Container Image

### 5.1 Build Local v√† Push

```bash
# Set environment variables
export PROJECT_ID=your-project-id
export REGION=asia-southeast1
export IMAGE_NAME=rag-bidding
export IMAGE_TAG=v1.0.0

# T·∫°o requirements.txt t·ª´ environment.yaml (n·∫øu ch∆∞a c√≥)
python3 -c "
import yaml
with open('environment.yaml') as f:
    env = yaml.safe_load(f)
pip_deps = [d['pip'] for d in env['dependencies'] if isinstance(d, dict) and 'pip' in d][0]
with open('requirements.txt', 'w') as f:
    f.write('\n'.join(pip_deps))
"

# Build image
docker build -t ${REGION}-docker.pkg.dev/${PROJECT_ID}/rag-bidding/${IMAGE_NAME}:${IMAGE_TAG} .

# Test locally (c·∫ßn c√≥ PostgreSQL v√† Redis running)
docker run -p 8000:8000 \
    -e DATABASE_URL="postgresql+psycopg://user:pass@host.docker.internal:5432/rag_bidding_v3" \
    -e OPENAI_API_KEY="sk-your-key" \
    -e JWT_SECRET_KEY="test-secret" \
    -e LC_COLLECTION="docs" \
    -e REDIS_HOST="host.docker.internal" \
    -e ENABLE_REDIS_CACHE="false" \
    ${REGION}-docker.pkg.dev/${PROJECT_ID}/rag-bidding/${IMAGE_NAME}:${IMAGE_TAG}

# Verify health endpoint
curl http://localhost:8000/health

# Push l√™n Artifact Registry
docker push ${REGION}-docker.pkg.dev/${PROJECT_ID}/rag-bidding/${IMAGE_NAME}:${IMAGE_TAG}
```

### 5.2 Build v·ªõi Cloud Build (Recommended)

T·∫°o file `cloudbuild.yaml` cho RAG-Bidding:

```yaml
steps:
  # T·∫°o requirements.txt t·ª´ environment.yaml
  - name: "python:3.10-slim"
    entrypoint: "bash"
    args:
      - "-c"
      - |
        pip install pyyaml
        python -c "
        import yaml
        with open('environment.yaml') as f:
            env = yaml.safe_load(f)
        pip_deps = [d['pip'] for d in env['dependencies'] if isinstance(d, dict) and 'pip' in d][0]
        with open('requirements.txt', 'w') as f:
            f.write('\n'.join(pip_deps))
        "

  # Build Docker image
  - name: "gcr.io/cloud-builders/docker"
    args:
      - "build"
      - "-t"
      - "${_REGION}-docker.pkg.dev/${PROJECT_ID}/rag-bidding/${_IMAGE_NAME}:${SHORT_SHA}"
      - "-t"
      - "${_REGION}-docker.pkg.dev/${PROJECT_ID}/rag-bidding/${_IMAGE_NAME}:latest"
      - "."

  # Push image to Artifact Registry
  - name: "gcr.io/cloud-builders/docker"
    args:
      - "push"
      - "--all-tags"
      - "${_REGION}-docker.pkg.dev/${PROJECT_ID}/rag-bidding/${_IMAGE_NAME}"

  # Deploy to Cloud Run
  - name: "gcr.io/google.com/cloudsdktool/cloud-sdk"
    entrypoint: gcloud
    args:
      - "run"
      - "deploy"
      - "${_SERVICE_NAME}"
      - "--image=${_REGION}-docker.pkg.dev/${PROJECT_ID}/rag-bidding/${_IMAGE_NAME}:${SHORT_SHA}"
      - "--region=${_REGION}"
      - "--platform=managed"
      - "--port=8000"
      - "--memory=4Gi"
      - "--cpu=2"
      - "--min-instances=0"
      - "--max-instances=10"
      - "--timeout=300"
      - "--concurrency=50"

substitutions:
  _REGION: asia-southeast1
  _IMAGE_NAME: rag-bidding
  _SERVICE_NAME: rag-bidding-api

images:
  - "${_REGION}-docker.pkg.dev/${PROJECT_ID}/rag-bidding/${_IMAGE_NAME}:${SHORT_SHA}"
  - "${_REGION}-docker.pkg.dev/${PROJECT_ID}/rag-bidding/${_IMAGE_NAME}:latest"

options:
  logging: CLOUD_LOGGING_ONLY
  machineType: "E2_HIGHCPU_8"

timeout: "1800s"
```

**Ch·∫°y Cloud Build:**

```bash
gcloud builds submit --config=cloudbuild.yaml .
```

---

## 6. Deploy l√™n Cloud Run

### 6.1 Deploy v·ªõi ƒë·∫ßy ƒë·ªß Environment Variables

```bash
export PROJECT_ID=your-project-id
export REGION=asia-southeast1

# Deploy service v·ªõi t·∫•t c·∫£ env vars c·∫ßn thi·∫øt cho RAG-Bidding
gcloud run deploy rag-bidding-api \
    --image=${REGION}-docker.pkg.dev/${PROJECT_ID}/rag-bidding/rag-bidding:latest \
    --region=${REGION} \
    --platform=managed \
    --port=8000 \
    --memory=4Gi \
    --cpu=2 \
    --min-instances=0 \
    --max-instances=10 \
    --timeout=300 \
    --concurrency=50 \
    --set-env-vars="LC_COLLECTION=docs" \
    --set-env-vars="EMBED_MODEL=text-embedding-3-small" \
    --set-env-vars="LLM_MODEL=gpt-4o-mini" \
    --set-env-vars="RAG_MODE=balanced" \
    --set-env-vars="ENABLE_RERANKING=true" \
    --set-env-vars="ENABLE_QUERY_ENHANCEMENT=true" \
    --set-env-vars="ENABLE_REDIS_CACHE=true" \
    --set-env-vars="LOG_LEVEL=INFO" \
    --set-env-vars="CORS_ORIGINS=https://your-frontend.com"
```

### 6.2 Deploy v·ªõi Secrets (Recommended cho Production)

```bash
# Deploy v·ªõi secrets t·ª´ Secret Manager
gcloud run deploy rag-bidding-api \
    --image=${REGION}-docker.pkg.dev/${PROJECT_ID}/rag-bidding/rag-bidding:latest \
    --region=${REGION} \
    --platform=managed \
    --port=8000 \
    --memory=4Gi \
    --cpu=2 \
    --min-instances=1 \
    --max-instances=10 \
    --timeout=300 \
    --concurrency=50 \
    --service-account=rag-bidding-sa@${PROJECT_ID}.iam.gserviceaccount.com \
    --update-secrets=DATABASE_URL=db-connection-string:latest \
    --update-secrets=OPENAI_API_KEY=openai-api-key:latest \
    --update-secrets=JWT_SECRET_KEY=jwt-secret:latest \
    --set-env-vars="LC_COLLECTION=docs" \
    --set-env-vars="EMBED_MODEL=text-embedding-3-small" \
    --set-env-vars="LLM_MODEL=gpt-4o-mini" \
    --set-env-vars="RAG_MODE=balanced" \
    --set-env-vars="ENABLE_RERANKING=true" \
    --set-env-vars="ENABLE_REDIS_CACHE=true" \
    --set-env-vars="REDIS_HOST=10.0.0.3" \
    --set-env-vars="REDIS_PORT=6379" \
    --vpc-connector=rag-vpc-connector \
    --vpc-egress=private-ranges-only
```

### 6.3 Deploy qua Google Cloud Console

1. Truy c·∫≠p [Cloud Run Console](https://console.cloud.google.com/run)
2. Click **"Create Service"**
3. Ch·ªçn **"Deploy one revision from an existing container image"**
4. Click **"Select"** v√† ch·ªçn image t·ª´ Artifact Registry: `rag-bidding/rag-bidding:latest`
5. C·∫•u h√¨nh c∆° b·∫£n:
   - **Service name**: `rag-bidding-api`
   - **Region**: `asia-southeast1`
   - **Autoscaling**: Min 0, Max 10
6. Click **"Container, Networking, Security"**:

   **Container tab:**
   - **Container port**: `8000`
   - **Memory**: `4 GiB` (c·∫ßn cho BGE Reranker model)
   - **CPU**: `2`
   - **Request timeout**: `300` seconds
   - **Maximum concurrent requests**: `50`
   - **Startup CPU boost**: ‚úÖ Enabled (gi√∫p load model nhanh h∆°n)

   **Variables & Secrets tab:**
   - Th√™m environment variables theo b·∫£ng ·ªü m·ª•c 2.4
   - Th√™m secrets t·ª´ Secret Manager

   **Networking tab:**
   - Ch·ªçn VPC connector (n·∫øu c·∫ßn k·∫øt n·ªëi Cloud SQL/Redis qua private IP)
   - Egress: `Send traffic through VPC connector for private IPs only`

7. Click **"Create"**

### 6.4 Deploy v·ªõi YAML Service Configuration

T·∫°o file `cloudrun-service.yaml`:

```yaml
apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: rag-bidding-api
  labels:
    cloud.googleapis.com/location: asia-southeast1
  annotations:
    run.googleapis.com/ingress: all
spec:
  template:
    metadata:
      annotations:
        autoscaling.knative.dev/minScale: "0"
        autoscaling.knative.dev/maxScale: "10"
        run.googleapis.com/cpu-throttling: "false"
        run.googleapis.com/startup-cpu-boost: "true"
        run.googleapis.com/vpc-access-connector: projects/PROJECT_ID/locations/asia-southeast1/connectors/rag-vpc-connector
        run.googleapis.com/vpc-access-egress: private-ranges-only
    spec:
      containerConcurrency: 50
      timeoutSeconds: 300
      serviceAccountName: rag-bidding-sa@PROJECT_ID.iam.gserviceaccount.com
      containers:
        - image: asia-southeast1-docker.pkg.dev/PROJECT_ID/rag-bidding/rag-bidding:latest
          ports:
            - name: http1
              containerPort: 8000
          env:
            # Application Config
            - name: LC_COLLECTION
              value: "docs"
            - name: EMBED_MODEL
              value: "text-embedding-3-small"
            - name: LLM_MODEL
              value: "gpt-4o-mini"
            - name: RAG_MODE
              value: "balanced"
            - name: LOG_LEVEL
              value: "INFO"
            # Feature Flags
            - name: ENABLE_RERANKING
              value: "true"
            - name: ENABLE_QUERY_ENHANCEMENT
              value: "true"
            - name: ENABLE_REDIS_CACHE
              value: "true"
            - name: ENABLE_ANSWER_CACHE
              value: "true"
            - name: ENABLE_SEMANTIC_CACHE
              value: "true"
            # Redis Config (Memorystore)
            - name: REDIS_HOST
              value: "10.0.0.3"
            - name: REDIS_PORT
              value: "6379"
            # CORS
            - name: CORS_ORIGINS
              value: "https://your-frontend.com,https://your-admin.com"
            # Secrets (mounted from Secret Manager)
            - name: DATABASE_URL
              valueFrom:
                secretKeyRef:
                  name: db-connection-string
                  key: latest
            - name: OPENAI_API_KEY
              valueFrom:
                secretKeyRef:
                  name: openai-api-key
                  key: latest
            - name: JWT_SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: jwt-secret
                  key: latest
          resources:
            limits:
              cpu: "2"
              memory: "4Gi"
          startupProbe:
            httpGet:
              path: /health
              port: 8000
            initialDelaySeconds: 30
            periodSeconds: 10
            failureThreshold: 6
            timeoutSeconds: 10
          livenessProbe:
            httpGet:
              path: /health
              port: 8000
            periodSeconds: 30
            timeoutSeconds: 10
```

**Deploy v·ªõi YAML:**

```bash
# Thay th·∫ø PROJECT_ID
sed -i 's/PROJECT_ID/your-actual-project-id/g' cloudrun-service.yaml

# Deploy
gcloud run services replace cloudrun-service.yaml --region=asia-southeast1
```

---

## 7. C·∫•u H√¨nh K·∫øt N·ªëi Database (Cloud SQL v·ªõi pgvector)

> ‚ö†Ô∏è **QUAN TR·ªåNG**: RAG-Bidding s·ª≠ d·ª•ng PostgreSQL v·ªõi extension **pgvector** ƒë·ªÉ l∆∞u tr·ªØ v√† t√¨m ki·∫øm vector embeddings. Cloud SQL h·ªó tr·ª£ pgvector t·ª´ PostgreSQL 15+.

### 7.1 T·∫°o Cloud SQL Instance v·ªõi pgvector Support

**Qua Console:**

1. Truy c·∫≠p [Cloud SQL Console](https://console.cloud.google.com/sql)
2. Click **"Create Instance"**
3. Ch·ªçn **PostgreSQL**
4. C·∫•u h√¨nh:
   - **Instance ID**: `rag-bidding-db`
   - **Password**: ƒê·∫∑t password m·∫°nh
   - **Region**: `asia-southeast1`
   - **Database version**: **PostgreSQL 15** (ho·∫∑c m·ªõi h∆°n - b·∫Øt bu·ªôc cho pgvector)
   - **Machine type**: `db-custom-2-8192` (2 vCPU, 8GB RAM - khuy·∫øn ngh·ªã cho vector operations)
   - **Storage**: 50GB SSD (vector data c·∫ßn nhi·ªÅu space h∆°n)
5. **Database flags** (quan tr·ªçng cho performance):
   - `max_connections`: `200`
   - `shared_buffers`: `2GB`
   - `work_mem`: `64MB`
   - `maintenance_work_mem`: `512MB`
6. Click **"Create Instance"**

**Qua CLI:**

```bash
export PROJECT_ID=your-project-id
export REGION=asia-southeast1

# T·∫°o Cloud SQL instance v·ªõi PostgreSQL 15+ (h·ªó tr·ª£ pgvector)
gcloud sql instances create rag-bidding-db \
    --database-version=POSTGRES_15 \
    --tier=db-custom-2-8192 \
    --region=${REGION} \
    --storage-size=50GB \
    --storage-type=SSD \
    --storage-auto-increase \
    --database-flags="max_connections=200,shared_buffers=2048MB,work_mem=64MB" \
    --availability-type=zonal

# ƒê·∫∑t password cho user postgres
gcloud sql users set-password postgres \
    --instance=rag-bidding-db \
    --password=YOUR_SECURE_PASSWORD

# T·∫°o database
gcloud sql databases create rag_bidding_v3 --instance=rag-bidding-db

# T·∫°o user ri√™ng cho application (recommended)
gcloud sql users create sakana \
    --instance=rag-bidding-db \
    --password=YOUR_APP_PASSWORD
```

### 7.2 C√†i ƒë·∫∑t Extension pgvector

K·∫øt n·ªëi v√†o database v√† ch·∫°y:

```bash
# K·∫øt n·ªëi qua Cloud SQL Proxy
./cloud-sql-proxy ${PROJECT_ID}:${REGION}:rag-bidding-db &

# Ho·∫∑c qua gcloud
gcloud sql connect rag-bidding-db --user=postgres

# Trong psql, ch·∫°y:
```

```sql
-- Enable pgvector extension
CREATE EXTENSION IF NOT EXISTS vector;

-- Verify installation
SELECT * FROM pg_extension WHERE extname = 'vector';

-- Grant permissions cho app user
GRANT ALL PRIVILEGES ON DATABASE rag_bidding_v3 TO sakana;
GRANT USAGE ON SCHEMA public TO sakana;
GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA public TO sakana;
```

### 7.3 K·∫øt N·ªëi Cloud Run v·ªõi Cloud SQL

**C√°ch 1: Cloud SQL Connector (Recommended)**

RAG-Bidding s·ª≠ d·ª•ng `psycopg` driver (kh√¥ng ph·∫£i asyncpg). Connection string format:

```bash
# Deploy v·ªõi Cloud SQL connection
gcloud run deploy rag-bidding-api \
    --image=${REGION}-docker.pkg.dev/${PROJECT_ID}/rag-bidding/rag-bidding:latest \
    --region=${REGION} \
    --port=8000 \
    --add-cloudsql-instances=${PROJECT_ID}:${REGION}:rag-bidding-db \
    --set-env-vars="DATABASE_URL=postgresql+psycopg://sakana:PASSWORD@/rag_bidding_v3?host=/cloudsql/${PROJECT_ID}:${REGION}:rag-bidding-db"
```

**C√°ch 2: Private IP v·ªõi VPC Connector (Production Recommended)**

```bash
# Enable private IP for Cloud SQL instance
gcloud sql instances patch rag-bidding-db \
    --assign-ip \
    --network=default

# L·∫•y private IP
gcloud sql instances describe rag-bidding-db --format="value(ipAddresses[0].ipAddress)"

# T·∫°o VPC Connector (n·∫øu ch∆∞a c√≥)
gcloud compute networks vpc-access connectors create rag-vpc-connector \
    --region=${REGION} \
    --network=default \
    --range=10.8.0.0/28 \
    --min-instances=2 \
    --max-instances=10

# Deploy v·ªõi VPC connector v√† private IP
gcloud run deploy rag-bidding-api \
    --image=${REGION}-docker.pkg.dev/${PROJECT_ID}/rag-bidding/rag-bidding:latest \
    --region=${REGION} \
    --port=8000 \
    --vpc-connector=rag-vpc-connector \
    --vpc-egress=private-ranges-only \
    --set-env-vars="DATABASE_URL=postgresql+psycopg://sakana:PASSWORD@PRIVATE_IP:5432/rag_bidding_v3"
```

### 7.4 Database Migrations v·ªõi Alembic

RAG-Bidding s·ª≠ d·ª•ng Alembic cho database migrations. T·∫°o Cloud Run Job ƒë·ªÉ ch·∫°y migrations:

```bash
# T·∫°o migration job
gcloud run jobs create rag-db-migration \
    --image=${REGION}-docker.pkg.dev/${PROJECT_ID}/rag-bidding/rag-bidding:latest \
    --region=${REGION} \
    --add-cloudsql-instances=${PROJECT_ID}:${REGION}:rag-bidding-db \
    --set-env-vars="DATABASE_URL=postgresql+psycopg://sakana:PASSWORD@/rag_bidding_v3?host=/cloudsql/${PROJECT_ID}:${REGION}:rag-bidding-db" \
    --command="alembic" \
    --args="upgrade,head" \
    --max-retries=3

# Ch·∫°y migration
gcloud run jobs execute rag-db-migration --region=${REGION} --wait
```

### 7.5 C·∫•u h√¨nh hi·ªán c√≥ trong Project

Project ƒë√£ c√≥ c·∫•u h√¨nh database t·∫°i `src/config/database.py`:

```python
# C·∫•u h√¨nh hi·ªán t·∫°i (ƒë√£ optimize cho production)
from sqlalchemy.ext.asyncio import create_async_engine
from sqlalchemy.pool import NullPool

# NullPool cho async operations (recommended cho serverless)
self._async_engine = create_async_engine(
    self.connection_string,
    echo=False,
    poolclass=NullPool,  # T·ªët cho Cloud Run scaling
)
```

> üí° **Tip**: `NullPool` ƒë∆∞·ª£c recommend cho Cloud Run v√¨ m·ªói container instance ƒë∆∞·ª£c scale ƒë·ªôc l·∫≠p, tr√°nh connection pool conflicts.

---

## 8. C·∫•u H√¨nh Redis (Memorystore)

> ‚ö†Ô∏è **QUAN TR·ªåNG**: RAG-Bidding s·ª≠ d·ª•ng Redis cho **5 databases** kh√°c nhau:
>
> - DB0: General cache
> - DB1: Session storage
> - DB2: Answer cache
> - DB3: Semantic cache
> - DB4: Rate limiting

### 8.1 T·∫°o Memorystore for Redis Instance

**Qua Console:**

1. Truy c·∫≠p [Memorystore Console](https://console.cloud.google.com/memorystore/redis)
2. Click **"Create Instance"**
3. C·∫•u h√¨nh:
   - **Instance ID**: `rag-bidding-redis`
   - **Region**: `asia-southeast1`
   - **Tier**: **Standard** (cho production v·ªõi high availability)
   - **Capacity**: `2 GB` (ƒë·ªß cho caching + sessions)
   - **Version**: Redis 7.0
   - **Network**: Ch·ªçn VPC network (default ho·∫∑c custom)
4. Click **"Create"**

**Qua CLI:**

```bash
export PROJECT_ID=your-project-id
export REGION=asia-southeast1

# T·∫°o Memorystore Redis instance
gcloud redis instances create rag-bidding-redis \
    --size=2 \
    --region=${REGION} \
    --redis-version=redis_7_0 \
    --tier=standard \
    --network=default

# L·∫•y th√¥ng tin connection (c·∫ßn cho Cloud Run)
gcloud redis instances describe rag-bidding-redis --region=${REGION}

# Output s·∫Ω c√≥:
# host: 10.x.x.x (Private IP)
# port: 6379
```

### 8.2 K·∫øt N·ªëi Cloud Run v·ªõi Memorystore

> ‚ö†Ô∏è Memorystore ch·ªâ c√≥ Private IP, **B·∫ÆT BU·ªòC** ph·∫£i d√πng VPC Connector.

```bash
# L·∫•y Redis host IP
export REDIS_HOST=$(gcloud redis instances describe rag-bidding-redis \
    --region=${REGION} \
    --format="value(host)")

echo "Redis Host: ${REDIS_HOST}"

# Deploy v·ªõi VPC connector v√† Redis config
gcloud run deploy rag-bidding-api \
    --image=${REGION}-docker.pkg.dev/${PROJECT_ID}/rag-bidding/rag-bidding:latest \
    --region=${REGION} \
    --port=8000 \
    --vpc-connector=rag-vpc-connector \
    --vpc-egress=private-ranges-only \
    --set-env-vars="REDIS_HOST=${REDIS_HOST}" \
    --set-env-vars="REDIS_PORT=6379" \
    --set-env-vars="ENABLE_REDIS_CACHE=true" \
    --set-env-vars="ENABLE_ANSWER_CACHE=true" \
    --set-env-vars="ENABLE_SEMANTIC_CACHE=true" \
    --set-env-vars="RATE_LIMIT_ENABLED=true"
```

### 8.3 C·∫•u h√¨nh Redis trong Project

Project ƒë√£ c√≥ c·∫•u h√¨nh t·∫°i `src/config/feature_flags.py`:

```python
# Redis Database assignments (ƒë√£ c·∫•u h√¨nh)
REDIS_DATABASES = {
    "cache": 0,      # General cache
    "sessions": 1,   # User sessions
    "answers": 2,    # Answer cache
    "semantic": 3,   # Semantic cache
    "rate_limit": 4  # Rate limiting
}

# Feature flags
ENABLE_REDIS_CACHE = os.getenv("ENABLE_REDIS_CACHE", "true").lower() == "true"
ENABLE_ANSWER_CACHE = os.getenv("ENABLE_ANSWER_CACHE", "true").lower() == "true"
ENABLE_SEMANTIC_CACHE = os.getenv("ENABLE_SEMANTIC_CACHE", "true").lower() == "true"
RATE_LIMIT_ENABLED = os.getenv("RATE_LIMIT_ENABLED", "true").lower() == "true"
```

### 8.4 Test Redis Connection

```python
# Script test connection
import redis

redis_host = "10.x.x.x"  # Thay b·∫±ng IP th·ª±c
redis_port = 6379

# Test t·ª´ng database
for db_name, db_num in {"cache": 0, "sessions": 1, "answers": 2, "semantic": 3, "rate_limit": 4}.items():
    r = redis.Redis(host=redis_host, port=redis_port, db=db_num)
    r.ping()
    print(f"‚úÖ Redis DB{db_num} ({db_name}): Connected")
```

### 8.5 T√πy ch·ªçn: Redis Cluster (High Availability)

Cho production v·ªõi high traffic:

```bash
gcloud redis instances create rag-bidding-redis-ha \
    --size=4 \
    --region=${REGION} \
    --redis-version=redis_7_0 \
    --tier=standard \
    --replica-count=1 \
    --read-replicas-mode=read-replicas-enabled \
    --network=default
```

---

## 9. C·∫•u H√¨nh Secret Manager

### 9.1 T·∫°o Secrets cho RAG-Bidding

RAG-Bidding c·∫ßn c√°c secrets sau:

```bash
export PROJECT_ID=your-project-id

# 1. Database connection string (quan tr·ªçng nh·∫•t)
echo -n "postgresql+psycopg://sakana:YOUR_PASSWORD@/rag_bidding_v3?host=/cloudsql/${PROJECT_ID}:asia-southeast1:rag-bidding-db" | \
    gcloud secrets create db-connection-string --data-file=-

# 2. OpenAI API Key (cho embeddings v√† LLM)
echo -n "sk-your-openai-api-key" | gcloud secrets create openai-api-key --data-file=-

# 3. JWT Secret Key (cho authentication)
openssl rand -base64 64 | gcloud secrets create jwt-secret --data-file=-

# Verify secrets ƒë√£ t·∫°o
gcloud secrets list
```

### 9.2 T·∫°o v√† C·∫•u h√¨nh Service Account

```bash
export PROJECT_ID=your-project-id
export PROJECT_NUMBER=$(gcloud projects describe ${PROJECT_ID} --format="value(projectNumber)")

# T·∫°o service account ri√™ng cho RAG-Bidding
gcloud iam service-accounts create rag-bidding-sa \
    --display-name="RAG Bidding Service Account" \
    --description="Service account for RAG Bidding Cloud Run service"

export SERVICE_ACCOUNT="rag-bidding-sa@${PROJECT_ID}.iam.gserviceaccount.com"

# C·∫•p quy·ªÅn truy c·∫≠p secrets
for secret in db-connection-string openai-api-key jwt-secret; do
    gcloud secrets add-iam-policy-binding ${secret} \
        --member="serviceAccount:${SERVICE_ACCOUNT}" \
        --role="roles/secretmanager.secretAccessor"
done

# C·∫•p quy·ªÅn Cloud SQL Client (n·∫øu d√πng Cloud SQL Connector)
gcloud projects add-iam-policy-binding ${PROJECT_ID} \
    --member="serviceAccount:${SERVICE_ACCOUNT}" \
    --role="roles/cloudsql.client"

# C·∫•p quy·ªÅn Cloud Storage (n·∫øu l∆∞u documents tr√™n GCS)
gcloud projects add-iam-policy-binding ${PROJECT_ID} \
    --member="serviceAccount:${SERVICE_ACCOUNT}" \
    --role="roles/storage.objectViewer"
```

### 9.3 Deploy v·ªõi t·∫•t c·∫£ Secrets

```bash
export PROJECT_ID=your-project-id
export REGION=asia-southeast1
export REDIS_HOST=$(gcloud redis instances describe rag-bidding-redis --region=${REGION} --format="value(host)")

# Deploy ho√†n ch·ªânh v·ªõi secrets v√† env vars
gcloud run deploy rag-bidding-api \
    --image=${REGION}-docker.pkg.dev/${PROJECT_ID}/rag-bidding/rag-bidding:latest \
    --region=${REGION} \
    --platform=managed \
    --port=8000 \
    --memory=4Gi \
    --cpu=2 \
    --min-instances=1 \
    --max-instances=10 \
    --timeout=300 \
    --concurrency=50 \
    --service-account=rag-bidding-sa@${PROJECT_ID}.iam.gserviceaccount.com \
    --vpc-connector=rag-vpc-connector \
    --vpc-egress=private-ranges-only \
    --add-cloudsql-instances=${PROJECT_ID}:${REGION}:rag-bidding-db \
    --update-secrets=DATABASE_URL=db-connection-string:latest \
    --update-secrets=OPENAI_API_KEY=openai-api-key:latest \
    --update-secrets=JWT_SECRET_KEY=jwt-secret:latest \
    --set-env-vars="LC_COLLECTION=docs" \
    --set-env-vars="EMBED_MODEL=text-embedding-3-small" \
    --set-env-vars="LLM_MODEL=gpt-4o-mini" \
    --set-env-vars="RAG_MODE=balanced" \
    --set-env-vars="ENABLE_RERANKING=true" \
    --set-env-vars="ENABLE_QUERY_ENHANCEMENT=true" \
    --set-env-vars="ENABLE_REDIS_CACHE=true" \
    --set-env-vars="ENABLE_ANSWER_CACHE=true" \
    --set-env-vars="ENABLE_SEMANTIC_CACHE=true" \
    --set-env-vars="RATE_LIMIT_ENABLED=true" \
    --set-env-vars="REDIS_HOST=${REDIS_HOST}" \
    --set-env-vars="REDIS_PORT=6379" \
    --set-env-vars="LOG_LEVEL=INFO"
```

### 9.4 Rotate Secrets

```bash
# Update secret v·ªõi version m·ªõi
echo -n "new-openai-api-key" | gcloud secrets versions add openai-api-key --data-file=-

# Deploy l·∫°i service ƒë·ªÉ l·∫•y secret m·ªõi
gcloud run services update rag-bidding-api \
    --region=${REGION} \
    --update-secrets=OPENAI_API_KEY=openai-api-key:latest
```

---

## 10. C·∫•u H√¨nh Domain v√† SSL

### 10.1 Custom Domain qua Console

1. Truy c·∫≠p [Cloud Run Console](https://console.cloud.google.com/run)
2. Click v√†o service `rag-bidding-api`
3. Ch·ªçn tab **"INTEGRATIONS"** ho·∫∑c **"DOMAIN MAPPINGS"**
4. Click **"ADD MAPPING"**
5. Ch·ªçn domain ho·∫∑c th√™m domain m·ªõi
6. L√†m theo h∆∞·ªõng d·∫´n ƒë·ªÉ verify domain ownership
7. Th√™m DNS records theo y√™u c·∫ßu

### 10.2 Custom Domain qua CLI

```bash
export REGION=asia-southeast1

# Map custom domain
gcloud run domain-mappings create \
    --service=rag-bidding-api \
    --domain=api.yourdomain.com \
    --region=${REGION}

# Ki·ªÉm tra tr·∫°ng th√°i
gcloud run domain-mappings describe \
    --domain=api.yourdomain.com \
    --region=${REGION}
```

### 10.3 DNS Configuration

Th√™m c√°c DNS records sau v√†o domain c·ªßa b·∫°n:

| Type  | Name | Value                         |
| ----- | ---- | ----------------------------- |
| CNAME | api  | ghs.googlehosted.com          |
| TXT   | api  | google-site-verification=xxxx |

### 10.4 CORS Configuration

RAG-Bidding ƒë√£ c√≥ CORS config trong code. Update `CORS_ORIGINS` env var ƒë·ªÉ cho ph√©p frontend domain:

```bash
gcloud run services update rag-bidding-api \
    --region=${REGION} \
    --set-env-vars="CORS_ORIGINS=https://your-frontend.com,https://admin.your-frontend.com"
```

---

## 11. Monitoring v√† Logging

### 11.1 Cloud Logging

Logs t·ª± ƒë·ªông ƒë∆∞·ª£c g·ª≠i ƒë·∫øn Cloud Logging. Truy c·∫≠p t·∫°i:

- [Logs Explorer](https://console.cloud.google.com/logs)

**Filter logs c·ªßa RAG-Bidding:**

```
resource.type="cloud_run_revision"
resource.labels.service_name="rag-bidding-api"
```

**Filter theo severity:**

```
resource.type="cloud_run_revision"
resource.labels.service_name="rag-bidding-api"
severity>=ERROR
```

### 11.2 Cloud Monitoring Dashboard

1. Truy c·∫≠p [Cloud Monitoring](https://console.cloud.google.com/monitoring)
2. T·∫°o Dashboard m·ªõi: **"RAG-Bidding API"**
3. Th√™m c√°c metrics quan tr·ªçng:

| Metric                                             | Description                          |
| -------------------------------------------------- | ------------------------------------ |
| `run.googleapis.com/request_count`                 | S·ªë requests                          |
| `run.googleapis.com/request_latencies`             | Latency (quan tr·ªçng cho RAG queries) |
| `run.googleapis.com/container/cpu/utilizations`    | CPU usage                            |
| `run.googleapis.com/container/memory/utilizations` | Memory (quan tr·ªçng cho BGE Reranker) |
| `run.googleapis.com/container/instance_count`      | S·ªë instances ƒëang ch·∫°y               |
| `run.googleapis.com/container/startup_latencies`   | Cold start time                      |

### 11.3 Alerting Policies

```bash
export PROJECT_ID=your-project-id

# Alert khi latency > 10s (RAG queries c√≥ th·ªÉ ch·∫≠m)
gcloud alpha monitoring policies create \
    --display-name="RAG-Bidding High Latency" \
    --condition-filter='metric.type="run.googleapis.com/request_latencies" resource.type="cloud_run_revision" resource.labels.service_name="rag-bidding-api"' \
    --condition-threshold-value=10000 \
    --condition-threshold-comparison=COMPARISON_GT \
    --condition-threshold-duration=300s \
    --notification-channels="projects/${PROJECT_ID}/notificationChannels/YOUR_CHANNEL_ID"

# Alert khi memory > 90%
gcloud alpha monitoring policies create \
    --display-name="RAG-Bidding High Memory" \
    --condition-filter='metric.type="run.googleapis.com/container/memory/utilizations" resource.type="cloud_run_revision" resource.labels.service_name="rag-bidding-api"' \
    --condition-threshold-value=0.9 \
    --condition-threshold-comparison=COMPARISON_GT \
    --condition-threshold-duration=60s \
    --notification-channels="projects/${PROJECT_ID}/notificationChannels/YOUR_CHANNEL_ID"
```

### 11.4 Health Check Endpoint

RAG-Bidding ƒë√£ c√≥ endpoint `/health` trong `src/api/main.py`. Verify ho·∫°t ƒë·ªông:

```bash
# L·∫•y service URL
SERVICE_URL=$(gcloud run services describe rag-bidding-api \
    --region=${REGION} \
    --format="value(status.url)")

# Test health endpoint
curl ${SERVICE_URL}/health

# Expected response:
# {"status": "healthy", "version": "1.0.0"}
```

### 11.5 Application Performance Monitoring

ƒê·ªÉ theo d√µi chi ti·∫øt h∆°n (query latency, LLM response time, etc.), c√≥ th·ªÉ t√≠ch h·ª£p OpenTelemetry:

```python
# Th√™m v√†o src/api/main.py
from opentelemetry import trace
from opentelemetry.exporter.cloud_trace import CloudTraceSpanExporter
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor

# Setup tracing
tracer_provider = TracerProvider()
cloud_trace_exporter = CloudTraceSpanExporter()
tracer_provider.add_span_processor(BatchSpanProcessor(cloud_trace_exporter))
trace.set_tracer_provider(tracer_provider)

tracer = trace.get_tracer(__name__)

# Usage in RAG query
with tracer.start_as_current_span("rag_query") as span:
    span.set_attribute("query", user_query)
    span.set_attribute("rag_mode", rag_mode)
    # ... RAG processing
    span.set_attribute("num_documents", len(retrieved_docs))
```

---

## 12. CI/CD v·ªõi Cloud Build

### 12.1 GitHub Integration

1. Truy c·∫≠p [Cloud Build Triggers](https://console.cloud.google.com/cloud-build/triggers)
2. Click **"Connect Repository"**
3. Ch·ªçn **GitHub** v√† authorize
4. Ch·ªçn repository ch·ª©a RAG-Bidding code
5. Click **"Create Trigger"**
6. C·∫•u h√¨nh:
   - **Name**: `rag-bidding-deploy`
   - **Event**: Push to branch `main`
   - **Configuration**: Cloud Build configuration file
   - **Location**: `/RAG-bidding/cloudbuild.yaml`

### 12.2 Complete CI/CD Pipeline cho RAG-Bidding

T·∫°o file `cloudbuild-ci-cd.yaml`:

```yaml
steps:
  # Step 1: T·∫°o requirements.txt t·ª´ environment.yaml
  - name: "python:3.10-slim"
    id: "generate-requirements"
    entrypoint: "bash"
    args:
      - "-c"
      - |
        pip install pyyaml
        python -c "
        import yaml
        with open('environment.yaml') as f:
            env = yaml.safe_load(f)
        pip_deps = [d['pip'] for d in env['dependencies'] if isinstance(d, dict) and 'pip' in d][0]
        with open('requirements.txt', 'w') as f:
            f.write('\n'.join(pip_deps))
        "

  # Step 2: Run tests
  - name: "python:3.10-slim"
    id: "run-tests"
    entrypoint: "bash"
    args:
      - "-c"
      - |
        pip install -r requirements.txt
        pip install pytest pytest-asyncio pytest-cov
        python -m pytest tests/ -v --ignore=tests/integration/ --cov=src --cov-report=xml
    env:
      - "DATABASE_URL=sqlite:///test.db"
      - "ENABLE_REDIS_CACHE=false"
      - "ENABLE_RERANKING=false"

  # Step 3: Build Docker image
  - name: "gcr.io/cloud-builders/docker"
    id: "build-image"
    args:
      - "build"
      - "-t"
      - "${_REGION}-docker.pkg.dev/${PROJECT_ID}/rag-bidding/${_IMAGE_NAME}:${SHORT_SHA}"
      - "-t"
      - "${_REGION}-docker.pkg.dev/${PROJECT_ID}/rag-bidding/${_IMAGE_NAME}:latest"
      - "--cache-from"
      - "${_REGION}-docker.pkg.dev/${PROJECT_ID}/rag-bidding/${_IMAGE_NAME}:latest"
      - "--build-arg"
      - "BUILDKIT_INLINE_CACHE=1"
      - "."

  # Step 4: Push to Artifact Registry
  - name: "gcr.io/cloud-builders/docker"
    id: "push-image"
    args:
      - "push"
      - "--all-tags"
      - "${_REGION}-docker.pkg.dev/${PROJECT_ID}/rag-bidding/${_IMAGE_NAME}"

  # Step 5: Run database migrations
  - name: "gcr.io/google.com/cloudsdktool/cloud-sdk"
    id: "run-migrations"
    entrypoint: "bash"
    args:
      - "-c"
      - |
        gcloud run jobs execute rag-db-migration \
          --region=${_REGION} \
          --wait \
          || echo "Migration job not found, skipping..."

  # Step 6: Deploy to Cloud Run
  - name: "gcr.io/google.com/cloudsdktool/cloud-sdk"
    id: "deploy"
    entrypoint: "gcloud"
    args:
      - "run"
      - "deploy"
      - "${_SERVICE_NAME}"
      - "--image=${_REGION}-docker.pkg.dev/${PROJECT_ID}/rag-bidding/${_IMAGE_NAME}:${SHORT_SHA}"
      - "--region=${_REGION}"
      - "--platform=managed"
      - "--port=8000"
      - "--memory=4Gi"
      - "--cpu=2"
      - "--min-instances=1"
      - "--max-instances=10"
      - "--timeout=300"
      - "--concurrency=50"

  # Step 7: Health check after deploy
  - name: "gcr.io/google.com/cloudsdktool/cloud-sdk"
    id: "health-check"
    entrypoint: "bash"
    args:
      - "-c"
      - |
        SERVICE_URL=$(gcloud run services describe ${_SERVICE_NAME} \
          --region=${_REGION} \
          --format="value(status.url)")

        echo "Testing health endpoint: ${SERVICE_URL}/health"

        for i in {1..10}; do
          HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" ${SERVICE_URL}/health)
          if [ "$HTTP_CODE" = "200" ]; then
            echo "‚úÖ Health check passed!"
            exit 0
          fi
          echo "Attempt $i: HTTP $HTTP_CODE, waiting..."
          sleep 10
        done

        echo "‚ùå Health check failed after 10 attempts"
        exit 1

substitutions:
  _REGION: asia-southeast1
  _IMAGE_NAME: rag-bidding
  _SERVICE_NAME: rag-bidding-api

images:
  - "${_REGION}-docker.pkg.dev/${PROJECT_ID}/rag-bidding/${_IMAGE_NAME}:${SHORT_SHA}"
  - "${_REGION}-docker.pkg.dev/${PROJECT_ID}/rag-bidding/${_IMAGE_NAME}:latest"

options:
  logging: CLOUD_LOGGING_ONLY
  machineType: "E2_HIGHCPU_8"

timeout: "1800s"
```

### 12.3 Staging/Production Environments

T·∫°o triggers cho multiple environments:

```bash
# Staging trigger (t·ª´ develop branch)
gcloud builds triggers create github \
    --repo-name=your-repo \
    --repo-owner=your-org \
    --branch-pattern="^develop$" \
    --build-config=RAG-bidding/cloudbuild-ci-cd.yaml \
    --substitutions="_SERVICE_NAME=rag-bidding-api-staging,_REGION=asia-southeast1"

# Production trigger (t·ª´ main branch)
gcloud builds triggers create github \
    --repo-name=your-repo \
    --repo-owner=your-org \
    --branch-pattern="^main$" \
    --build-config=RAG-bidding/cloudbuild-ci-cd.yaml \
    --substitutions="_SERVICE_NAME=rag-bidding-api,_REGION=asia-southeast1"
```

### 12.4 Manual Rollback

```bash
# Li·ªát k√™ c√°c revisions
gcloud run revisions list \
    --service=rag-bidding-api \
    --region=asia-southeast1

# Rollback v·ªÅ revision c·ª• th·ªÉ
gcloud run services update-traffic rag-bidding-api \
    --to-revisions=rag-bidding-api-00005-abc=100 \
    --region=asia-southeast1
```

---

## 13. Troubleshooting

### 13.1 Common Issues cho RAG-Bidding

#### ‚ùå Container kh√¥ng start ƒë∆∞·ª£c

```bash
# Ki·ªÉm tra logs chi ti·∫øt
gcloud run services logs read rag-bidding-api \
    --region=asia-southeast1 \
    --limit=100

# Ki·ªÉm tra revision status
gcloud run revisions list \
    --service=rag-bidding-api \
    --region=asia-southeast1

# Xem chi ti·∫øt revision failed
gcloud run revisions describe REVISION_NAME \
    --region=asia-southeast1
```

**Nguy√™n nh√¢n th∆∞·ªùng g·∫∑p:**

- Missing environment variables (ƒë·∫∑c bi·ªát `DATABASE_URL`, `OPENAI_API_KEY`)
- Memory kh√¥ng ƒë·ªß cho BGE Reranker model (c·∫ßn t·ªëi thi·ªÉu 4GB)
- Port kh√¥ng ƒë√∫ng (ph·∫£i l√† 8000, kh√¥ng ph·∫£i 8080)

#### ‚ùå Memory issues (BGE Reranker)

BGE Reranker model (`BAAI/bge-reranker-v2-m3`) c·∫ßn ~2GB memory. N·∫øu g·∫∑p OOM:

```bash
# TƒÉng memory
gcloud run services update rag-bidding-api \
    --memory=8Gi \
    --cpu=4 \
    --region=asia-southeast1

# Ho·∫∑c disable reranking t·∫°m th·ªùi
gcloud run services update rag-bidding-api \
    --set-env-vars="ENABLE_RERANKING=false" \
    --region=asia-southeast1
```

#### ‚ùå Cold start ch·∫≠m (>30s)

RAG-Bidding c·∫ßn load models khi startup, c√≥ th·ªÉ m·∫•t 30-60s:

```bash
# ƒê·∫∑t minimum instances > 0 ƒë·ªÉ tr√°nh cold start
gcloud run services update rag-bidding-api \
    --min-instances=1 \
    --region=asia-southeast1

# Enable startup CPU boost
gcloud run services update rag-bidding-api \
    --cpu-boost \
    --region=asia-southeast1
```

#### ‚ùå Connection timeout ƒë·∫øn Cloud SQL

```bash
# Ki·ªÉm tra Cloud SQL connection name
gcloud sql instances describe rag-bidding-db \
    --format="value(connectionName)"

# Verify IAM permissions
gcloud projects get-iam-policy ${PROJECT_ID} \
    --flatten="bindings[].members" \
    --filter="bindings.members:rag-bidding-sa@${PROJECT_ID}.iam.gserviceaccount.com"

# Ki·ªÉm tra VPC connector status
gcloud compute networks vpc-access connectors describe rag-vpc-connector \
    --region=asia-southeast1
```

**Fix common issues:**

```bash
# C·∫•p quy·ªÅn Cloud SQL Client
gcloud projects add-iam-policy-binding ${PROJECT_ID} \
    --member="serviceAccount:rag-bidding-sa@${PROJECT_ID}.iam.gserviceaccount.com" \
    --role="roles/cloudsql.client"
```

#### ‚ùå Redis connection refused

Memorystore ch·ªâ c√≥ Private IP, **PH·∫¢I** d√πng VPC connector:

```bash
# Ki·ªÉm tra VPC connector
gcloud run services describe rag-bidding-api \
    --region=asia-southeast1 \
    --format="value(spec.template.metadata.annotations['run.googleapis.com/vpc-access-connector'])"

# Ki·ªÉm tra Redis host ƒë√∫ng ch∆∞a
gcloud redis instances describe rag-bidding-redis \
    --region=asia-southeast1 \
    --format="value(host)"

# Update n·∫øu c·∫ßn
export REDIS_HOST=$(gcloud redis instances describe rag-bidding-redis --region=asia-southeast1 --format="value(host)")
gcloud run services update rag-bidding-api \
    --set-env-vars="REDIS_HOST=${REDIS_HOST}" \
    --region=asia-southeast1
```

#### ‚ùå pgvector extension not found

```bash
# K·∫øt n·ªëi v√†o Cloud SQL v√† enable extension
gcloud sql connect rag-bidding-db --user=postgres

# Trong psql:
CREATE EXTENSION IF NOT EXISTS vector;
\dx  -- verify extension
```

#### ‚ùå OpenAI API rate limited

```bash
# Check logs cho rate limit errors
gcloud run services logs read rag-bidding-api \
    --region=asia-southeast1 \
    --filter="textPayload:rate"

# TƒÉng timeout v√† gi·∫£m concurrency
gcloud run services update rag-bidding-api \
    --timeout=600 \
    --concurrency=20 \
    --region=asia-southeast1
```

#### üîÑ BGE Reranker Fallback Issues

**V·∫•n ƒë·ªÅ**: BGE model kh√¥ng load ƒë∆∞·ª£c ho·∫∑c CUDA OOM

**Log patterns c·∫ßn ch√∫ √Ω:**
```bash
# Check fallback logs
gcloud run services logs read rag-bidding-api \
    --region=asia-southeast1 \
    --filter='textPayload:"cuda out of memory" OR textPayload:"OpenAI reranker" OR textPayload:"Falling back"'
```

**Expected log flow khi fallback:**
```
üîß Creating singleton BGEReranker instance (model: BAAI/bge-reranker-v2-m3, device: cuda)
‚ùå CUDA OOM during BGE init: CUDA out of memory
üîÑ Falling back to OpenAI reranker...
‚úÖ OpenAI reranker initialized: gpt-4o-mini
```

**Solutions:**

```bash  
# Option 1: TƒÉng memory cho BGE
gcloud run services update rag-bidding-api \
    --memory=8Gi --cpu=2 \
    --region=asia-southeast1

# Option 2: Force OpenAI t·ª´ ƒë·∫ßu (skip BGE)
gcloud run services update rag-bidding-api \
    --set-env-vars="RERANKER_TYPE=openai" \
    --memory=2Gi --cpu=1 \
    --region=asia-southeast1

# Option 3: Force CPU cho BGE (n·∫øu CUDA issues)  
gcloud run services update rag-bidding-api \
    --set-env-vars="RERANKER_DEVICE=cpu" \
    --memory=4Gi --cpu=2 \
    --region=asia-southeast1

# Option 4: Disable reranking ho√†n to√†n
gcloud run services update rag-bidding-api \
    --set-env-vars="ENABLE_RERANKING=false" \
    --memory=2Gi --cpu=1 \
    --region=asia-southeast1
```

**Verify fallback ho·∫°t ƒë·ªông:**
```bash
# Test API endpoint
SERVICE_URL=$(gcloud run services describe rag-bidding-api --region=asia-southeast1 --format="value(status.url)")

# Send test query to /ask endpoint  
curl -X POST "$SERVICE_URL/ask" \
    -H "Content-Type: application/json" \
    -d '{"query": "test reranking fallback"}' \
    -w "\nResponse time: %{time_total}s\n"

# Check logs for fallback indicators
gcloud run services logs read rag-bidding-api --region=asia-southeast1 --limit=50
```

### 13.2 Debug Commands

```bash
export REGION=asia-southeast1
export SERVICE=rag-bidding-api

# Xem chi ti·∫øt service config
gcloud run services describe ${SERVICE} --region=${REGION}

# Xem t·∫•t c·∫£ environment variables
gcloud run services describe ${SERVICE} --region=${REGION} \
    --format="yaml(spec.template.spec.containers[].env)"

# Xem secrets ƒë√£ mount
gcloud run services describe ${SERVICE} --region=${REGION} \
    --format="yaml(spec.template.spec.containers[].env)" | grep -A2 "secretKeyRef"

# Traffic split (n·∫øu c·∫ßn test revision m·ªõi)
gcloud run services update-traffic ${SERVICE} \
    --to-revisions=REVISION_NEW=10,REVISION_OLD=90 \
    --region=${REGION}

# Rollback ho√†n to√†n
gcloud run services update-traffic ${SERVICE} \
    --to-revisions=REVISION_OLD=100 \
    --region=${REGION}
```

### 13.3 Performance Tuning

```bash
# C·∫•u h√¨nh recommended cho RAG-Bidding
gcloud run services update rag-bidding-api \
    --region=asia-southeast1 \
    --memory=4Gi \
    --cpu=2 \
    --min-instances=1 \
    --max-instances=10 \
    --concurrency=50 \
    --timeout=300 \
    --cpu-boost \
    --set-env-vars="RAG_MODE=balanced" \
    --set-env-vars="ENABLE_RERANKING=true" \
    --set-env-vars="ENABLE_REDIS_CACHE=true"
```

### 13.4 Cost Optimization

```bash
# Development/Staging: Scale to zero
gcloud run services update rag-bidding-api-staging \
    --region=asia-southeast1 \
    --min-instances=0 \
    --memory=2Gi \
    --cpu=1 \
    --set-env-vars="ENABLE_RERANKING=false"

# Production: Keep warm instances
gcloud run services update rag-bidding-api \
    --region=asia-southeast1 \
    --min-instances=1 \
    --max-instances=5
```

---

## 14. Checklist Deployment cho RAG-Bidding

### Pre-deployment

- [ ] Google Cloud Project ƒë√£ t·∫°o v√† billing enabled
- [ ] T·∫•t c·∫£ APIs ƒë√£ enable (Cloud Run, Cloud SQL, Memorystore, Secret Manager, etc.)
- [ ] Service account `rag-bidding-sa` ƒë√£ t·∫°o v·ªõi ƒë·ªß permissions
- [ ] Artifact Registry repository `rag-bidding` ƒë√£ t·∫°o

### Infrastructure

- [ ] Cloud SQL PostgreSQL 15+ instance ƒë√£ t·∫°o
- [ ] pgvector extension ƒë√£ enable
- [ ] Database `rag_bidding_v3` v√† user `sakana` ƒë√£ t·∫°o
- [ ] Memorystore Redis instance ƒë√£ t·∫°o
- [ ] VPC Connector ƒë√£ t·∫°o v√† ho·∫°t ƒë·ªông

### Secrets

- [ ] `db-connection-string` secret ƒë√£ t·∫°o
- [ ] `openai-api-key` secret ƒë√£ t·∫°o
- [ ] `jwt-secret` secret ƒë√£ t·∫°o
- [ ] Service account c√≥ quy·ªÅn `secretmanager.secretAccessor`

### Application

- [ ] Dockerfile ƒë√£ t·∫°o v√† test locally th√†nh c√¥ng
- [ ] Docker image ƒë√£ build v√† push l√™n Artifact Registry
- [ ] `requirements.txt` ƒë√£ generate t·ª´ `environment.yaml`
- [ ] Health check endpoint `/health` ho·∫°t ƒë·ªông

### Deployment

- [ ] Cloud Run service ƒë√£ deploy th√†nh c√¥ng
- [ ] Port 8000 ƒë√£ configure ƒë√∫ng
- [ ] T·∫•t c·∫£ environment variables ƒë√£ set
- [ ] VPC connector ƒë√£ attach
- [ ] Cloud SQL connection ƒë√£ th√™m

### Post-deployment

- [ ] Health check endpoint tr·∫£ v·ªÅ 200
- [ ] API endpoints ho·∫°t ƒë·ªông (`/api/auth`, `/api/conversations`, `/ask`)
- [ ] Database migrations ƒë√£ ch·∫°y th√†nh c√¥ng
- [ ] Redis cache ho·∫°t ƒë·ªông
- [ ] Monitoring dashboard ƒë√£ setup
- [ ] Alerting policies ƒë√£ configure
- [ ] CI/CD pipeline ƒë√£ test

### Optional

- [ ] Custom domain ƒë√£ map
- [ ] SSL certificate ƒë√£ provision
- [ ] CORS origins ƒë√£ configure cho frontend domain

---

## 15. Quick Start Script

T·∫°o file `deploy.sh` ƒë·ªÉ deploy nhanh:

```bash
#!/bin/bash
set -e

# Configuration
export PROJECT_ID="your-project-id"
export REGION="asia-southeast1"
export SERVICE_NAME="rag-bidding-api"
export IMAGE_NAME="rag-bidding"

echo "üöÄ Starting RAG-Bidding deployment..."

# 1. Generate requirements.txt
echo "üì¶ Generating requirements.txt..."
python3 -c "
import yaml
with open('environment.yaml') as f:
    env = yaml.safe_load(f)
pip_deps = [d['pip'] for d in env['dependencies'] if isinstance(d, dict) and 'pip' in d][0]
with open('requirements.txt', 'w') as f:
    f.write('\n'.join(pip_deps))
"

# 2. Build and push image
echo "üê≥ Building Docker image..."
docker build -t ${REGION}-docker.pkg.dev/${PROJECT_ID}/rag-bidding/${IMAGE_NAME}:latest .

echo "üì§ Pushing to Artifact Registry..."
docker push ${REGION}-docker.pkg.dev/${PROJECT_ID}/rag-bidding/${IMAGE_NAME}:latest

# 3. Get Redis host
export REDIS_HOST=$(gcloud redis instances describe rag-bidding-redis --region=${REGION} --format="value(host)" 2>/dev/null || echo "")

# 4. Deploy
echo "üö¢ Deploying to Cloud Run..."
gcloud run deploy ${SERVICE_NAME} \
    --image=${REGION}-docker.pkg.dev/${PROJECT_ID}/rag-bidding/${IMAGE_NAME}:latest \
    --region=${REGION} \
    --platform=managed \
    --port=8000 \
    --memory=4Gi \
    --cpu=2 \
    --min-instances=1 \
    --max-instances=10 \
    --timeout=300 \
    --concurrency=50 \
    --service-account=rag-bidding-sa@${PROJECT_ID}.iam.gserviceaccount.com \
    --vpc-connector=rag-vpc-connector \
    --vpc-egress=private-ranges-only \
    --add-cloudsql-instances=${PROJECT_ID}:${REGION}:rag-bidding-db \
    --update-secrets=DATABASE_URL=db-connection-string:latest \
    --update-secrets=OPENAI_API_KEY=openai-api-key:latest \
    --update-secrets=JWT_SECRET_KEY=jwt-secret:latest \
    --set-env-vars="LC_COLLECTION=docs,EMBED_MODEL=text-embedding-3-small,LLM_MODEL=gpt-4o-mini,RAG_MODE=balanced,ENABLE_RERANKING=true,ENABLE_REDIS_CACHE=true,REDIS_HOST=${REDIS_HOST},REDIS_PORT=6379,LOG_LEVEL=INFO,GUNICORN_WORKERS=1"

# 5. Health check
echo "üè• Running health check..."
SERVICE_URL=$(gcloud run services describe ${SERVICE_NAME} --region=${REGION} --format="value(status.url)")
curl -s ${SERVICE_URL}/health

echo ""
echo "‚úÖ Deployment complete!"
echo "üåê Service URL: ${SERVICE_URL}"
```

---

## 16. Final Recommendations (K·∫øt Lu·∫≠n T·ª´ Ph√¢n T√≠ch Codebase)

### üî¥ CRITICAL WARNINGS

#### 1. Gunicorn Workers vs BGE Model

```
‚ö†Ô∏è LU√îN SET: GUNICORN_WORKERS=1

L√Ω do: 
- Gunicorn fork() t·∫°o memory space RI√äNG cho m·ªói worker
- Singleton pattern trong Python KH√îNG share gi·ªØa processes
- 4 workers = 4 copies c·ªßa BGE model = ~6GB RAM ch·ªâ cho model!

Cloud Run scaling strategy:
- 1 worker PER container instance
- Cloud Run t·ª± ƒë·ªông spawn nhi·ªÅu instances khi c·∫ßn
- KH√îNG d√πng nhi·ªÅu workers trong 1 container
```

#### 2. Cold Start Time (~50-60s)

```
Startup sequence v·ªõi BGE model:
1. Container start: ~5s
2. Python import: ~10s (heavy dependencies)
3. Database init: ~2s
4. Vector store bootstrap: ~3s  
5. BGE model loading: ~30-40s ‚ö†Ô∏è HEAVIEST
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Total: 50-60s

‚Üí Set min-instances=1 ƒë·ªÉ tr√°nh cold start cho production
```

#### 3. Database Connection (NullPool)

```python
# Code s·ª≠ d·ª•ng NullPool - kh√¥ng c√≥ connection pooling
poolclass=NullPool  # M·ªói request t·∫°o connection m·ªõi

‚Üí Cloud SQL Proxy handles pooling externally
‚Üí Ho·∫∑c consider th√™m pgBouncer sidecar
```

### ‚úÖ VERIFIED: Fallback Mechanism

```python
# ƒê√£ verify trong bge_reranker.py - 4 layers fallback:

Layer 1 (Init):     BGE GPU load ‚Üí OOM ‚Üí OpenAIReranker
Layer 2 (Runtime):  BGE predict ‚Üí OOM ‚Üí set flag + OpenAI fallback
Layer 3 (Future):   Global _cuda_oom_fallback=True ‚Üí skip BGE entirely  
Layer 4 (Final):    OpenAI fails ‚Üí return dummy scores (original order)

K·∫øt lu·∫≠n: System t·ª± x·ª≠ l√Ω, kh√¥ng c·∫ßn lo crash!
```

### üìä Configuration Matrix

| Environment | Memory | CPU | Workers | Min Inst | Reranking | Monthly Cost* |
|-------------|--------|-----|---------|----------|-----------|---------------|
| **Dev** | 2Gi | 1 | 1 | 0 | false | ~$10-20 |
| **Staging** | 4Gi | 2 | 1 | 0 | bge (auto-fallback) | ~$30-50 |
| **Prod Light** | 4Gi | 2 | 1 | 1 | openai | ~$80-120 |
| **Prod Standard** | 4Gi | 2 | 1 | 1 | bge | ~$80-120 |
| **Prod Premium** | 8Gi | 4 | 1 | 2 | bge | ~$200-300 |

*Chi ph√≠ ∆∞·ªõc t√≠nh, ph·ª• thu·ªôc v√†o traffic th·ª±c t·∫ø

### üéØ Recommended Production Configuration

```bash
# Balanced cost vs performance
gcloud run deploy rag-bidding-api \
    --memory=4Gi \
    --cpu=2 \
    --min-instances=1 \
    --max-instances=10 \
    --concurrency=50 \
    --timeout=300 \
    --cpu-boost \
    --set-env-vars="\
GUNICORN_WORKERS=1,\
ENABLE_RERANKING=true,\
ENABLE_REDIS_CACHE=true,\
ENABLE_ANSWER_CACHE=true,\
ENABLE_SEMANTIC_CACHE=true,\
RAG_MODE=balanced"
```

### üìù Deployment Verification Checklist

```bash
# After deployment, verify these:

# 1. Health check
curl -s $SERVICE_URL/health | jq

# 2. Check BGE model loaded (should see in logs)
gcloud logging read "resource.type=cloud_run_revision \
  AND resource.labels.service_name=rag-bidding-api \
  AND textPayload:BGEReranker" --limit=5

# 3. Test RAG endpoint
curl -X POST $SERVICE_URL/ask \
  -H "Content-Type: application/json" \
  -d '{"question": "What is RAG?"}'

# 4. Monitor memory usage
gcloud run services describe rag-bidding-api \
  --region=asia-southeast1 \
  --format="value(status.conditions)"
```

---

## T√†i Li·ªáu Tham Kh·∫£o

- [Cloud Run Documentation](https://cloud.google.com/run/docs)
- [Cloud Run Samples](https://github.com/GoogleCloudPlatform/cloud-run-samples)
- [Cloud SQL for PostgreSQL](https://cloud.google.com/sql/docs/postgres)
- [pgvector on Cloud SQL](https://cloud.google.com/sql/docs/postgres/extensions#pgvector)
- [Memorystore for Redis](https://cloud.google.com/memorystore/docs/redis)
- [Secret Manager](https://cloud.google.com/secret-manager/docs)
- [Cloud Build](https://cloud.google.com/build/docs)
- [VPC Connector](https://cloud.google.com/vpc/docs/configure-serverless-vpc-access)

### Project-specific Documentation
- [DEPLOYMENT_ANALYSIS.md](DEPLOYMENT_ANALYSIS.md) - Ph√¢n t√≠ch chi ti·∫øt codebase

---

_T√†i li·ªáu ƒë∆∞·ª£c t·∫°o cho project: **RAG-Bidding Backend**_
_Ng√†y c·∫≠p nh·∫≠t: 26/01/2026_
_Phi√™n b·∫£n: 3.0 (Full Codebase Analysis)_

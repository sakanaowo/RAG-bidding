# âœ… Phase 5 Checklist - Buá»•i SÃ¡ng (3.5h)

**NgÃ y**: 3/11/2025  
**Má»¥c tiÃªu**: Import 4,512 chunks vÃ o database + test retrieval

---

## ğŸ¯ Má»¥c TiÃªu ChÃ­nh

- [ ] Import táº¥t cáº£ 4,512 chunks vÃ o PGVector
- [ ] Test retrieval hoáº¡t Ä‘á»™ng tá»‘t
- [ ] Verify metadata Ä‘Æ°á»£c preserve
- [ ] Benchmark performance

---

## â° Timeline

```
8:00-8:30   Setup & Cost Estimation
8:30-9:30   Import Chunks (main task)
9:30-10:00  Break + Verify
10:00-10:45 Test Retrieval
10:45-11:30 E2E Testing
11:30-12:00 Benchmark + Commit
```

---

## ğŸ“ Checklist Chi Tiáº¿t

### 1ï¸âƒ£ Setup (8:00-8:30) - 30 phÃºt

```bash
cd /home/sakana/Code/RAG-bidding
```

- [ ] Test database connection
  ```bash
  python3 -c "from src.config.models import settings; print(settings.database_url)"
  ```

- [ ] Bootstrap database
  ```bash
  python3 scripts/bootstrap_db.py
  ```

- [ ] Estimate cost
  ```bash
  python3 scripts/calculate_embedding_cost.py \
      --chunks-dir data/processed/chunks \
      --model text-embedding-3-large
  ```
  Expected: ~$0.15

- [ ] (Optional) Create backup
  ```bash
  ./scripts/create_dump.sh
  ```

**Checkpoint**: âœ… Cost < $0.20, Database ready

---

### 2ï¸âƒ£ Import (8:30-9:30) - 60 phÃºt

- [ ] Test vá»›i 10 chunks
  ```bash
  python3 scripts/import_processed_chunks.py \
      --chunks-dir data/processed/chunks \
      --limit 10 \
      --dry-run
  ```

- [ ] Full import (4,512 chunks)
  ```bash
  python3 scripts/import_processed_chunks.py \
      --chunks-dir data/processed/chunks \
      --batch-size 100 \
      --verbose
  ```
  Expected: ~15-20 minutes

- [ ] Verify import
  ```bash
  python3 -c "
  from src.embedding.store.pgvector_store import vector_store
  results = vector_store.similarity_search('test', k=1)
  print(f'âœ… Found {len(results)} documents')
  "
  ```

**Checkpoint**: âœ… 4,512/4,512 chunks imported

---

### 3ï¸âƒ£ Break + Review (9:30-10:00) - 30 phÃºt

â˜• Coffee break!

- [ ] Review import logs
- [ ] Check for errors
- [ ] Quick query test

```bash
python3 -c "
from langchain_postgres import PGVector
from langchain_openai import OpenAIEmbeddings
from src.config.models import settings

embeddings = OpenAIEmbeddings(model=settings.embed_model)
vs = PGVector(
    embeddings=embeddings,
    collection_name=settings.collection,
    connection=settings.database_url,
    use_jsonb=True
)

results = vs.similarity_search('Ä‘iá»u kiá»‡n tham gia Ä‘áº¥u tháº§u', k=3)
print(f'âœ… Retrieved {len(results)} results')
for doc in results:
    print(f'  - {doc.metadata.get(\"chunk_id\", \"unknown\")}')
"
```

**Checkpoint**: âœ… Queries returning results

---

### 4ï¸âƒ£ Test Retrieval (10:00-10:45) - 45 phÃºt

- [ ] Basic retrieval
  ```bash
  python3 scripts/test_retrieval.py
  ```

- [ ] Filtered retrieval
  ```bash
  python3 scripts/test_retrieval_with_filters.py
  ```

- [ ] Create comprehensive test (náº¿u chÆ°a cÃ³)
  ```bash
  python3 scripts/test_phase5_retrieval.py
  ```

**Checkpoint**: âœ… All retrieval tests passed

---

### 5ï¸âƒ£ E2E Testing (10:45-11:30) - 45 phÃºt

- [ ] Test adaptive retriever
  ```bash
  python3 scripts/test_e2e_pipeline.py
  ```

- [ ] Test vá»›i real queries
  - "Äiá»u kiá»‡n tham gia Ä‘áº¥u tháº§u lÃ  gÃ¬?"
  - "Há»“ sÆ¡ yÃªu cáº§u hÃ ng hÃ³a gá»“m nhá»¯ng gÃ¬?"
  - "Quy Ä‘á»‹nh vá» há»£p Ä‘á»“ng xÃ¢y dá»±ng"

- [ ] Verify metadata preserved
  - document_type
  - hierarchy
  - level
  - chunk_id

**Checkpoint**: âœ… E2E pipeline working

---

### 6ï¸âƒ£ Benchmark + Document (11:30-12:00) - 30 phÃºt

- [ ] Run benchmark
  ```bash
  python3 scripts/benchmark_retrieval.py \
      --queries 20 \
      --k 5
  ```

- [ ] Document results
  - Edit `documents/PHASE_5_INTEGRATION_REPORT.md`
  - Add statistics
  - Add test results

- [ ] Git commit
  ```bash
  git add .
  git commit -m "feat: Complete Phase 5 - System Integration
  
  - Imported 4,512 UniversalChunk instances to PGVector
  - All retrieval tests passed
  - Performance: <1s per query
  - Ready for Phase 6"
  
  git push origin data-preprocess
  ```

**Checkpoint**: âœ… Phase 5 complete, documented, committed

---

## ğŸ¯ Success Metrics

| Metric | Target | Actual |
|--------|--------|--------|
| Chunks Imported | 4,512 | ____ |
| Import Errors | 0 | ____ |
| Retrieval Tests Passed | 100% | ____ |
| Average Query Time | <1s | ____ ms |
| Embedding Cost | <$0.20 | $____ |

---

## ğŸ› Quick Troubleshooting

**Import fails?**
```bash
# Check connection
python3 scripts/bootstrap_db.py

# Check chunks format
head -1 data/processed/chunks/Luat_so_90_2025-qh15.jsonl | python3 -m json.tool
```

**No results?**
```bash
# Verify collection
python3 -c "
from src.embedding.store.pgvector_store import vector_store
print(vector_store.similarity_search('test', k=1))
"
```

**Slow queries?**
```bash
# Tune pgvector
python3 scripts/explain_optimizations.py
```

---

## âœ… Káº¿t Luáº­n

Sau 3.5 giá»:

```
âœ… Phase 5 COMPLETE!

- 4,512 chunks imported
- All tests passed
- Performance excellent
- Ready for production!

Next: Phase 6 - Production Deployment
```

---

**Tip**: LÃ m theo Ä‘Ãºng thá»© tá»±, khÃ´ng skip bÆ°á»›c nÃ o! ğŸš€

# üìã POST-MIGRATION UPDATE PLAN
## Plan chi ti·∫øt ƒë·ªÉ c·∫≠p nh·∫≠t t·∫•t c·∫£ endpoints, pipelines v√† tests sau migration document_id

**Migration Context:**
- ‚úÖ ƒê√£ migrate 57/59 documents t·ª´ format c≈© (`bidding_untitled_*`) sang format m·ªõi (FORM-*, LUA-*, TEMPLATE-*, EXAM-*)
- ‚úÖ Vector DB: 6,242 chunks v·ªõi document_id m·ªõi
- ‚úÖ Documents table: 59 documents v·ªõi metadata ƒë·∫ßy ƒë·ªß
- üîß **C·∫ßn update**: API endpoints, retrieval logic, preprocessing, tests

---

## üéØ OBJECTIVES

1. **API Endpoints**: ƒê·∫£m b·∫£o t·∫•t c·∫£ endpoints tr·∫£ v·ªÅ document_id m·ªõi (kh√¥ng c√≤n `bidding_untitled`)
2. **Retrieval Pipelines**: Verify t·∫•t c·∫£ retrievers ho·∫°t ƒë·ªông ƒë√∫ng v·ªõi metadata m·ªõi
3. **Context Formatting**: Hi·ªÉn th·ªã document_id theo format user-friendly
4. **Preprocessing**: C·∫≠p nh·∫≠t pipeline ƒë·ªÉ generate document_id m·ªõi cho documents t∆∞∆°ng lai
5. **Test Suite**: Comprehensive tests cho to√†n b·ªô system v·ªõi document_id m·ªõi
6. **Backward Compatibility**: ƒê·∫£m b·∫£o kh√¥ng break existing queries

---

## üìä CURRENT STATE ANALYSIS

### ‚úÖ Already Working (No Changes Needed)

**1. Vector Database**
- ‚úÖ All chunks c√≥ `cmetadata->>'document_id'` m·ªõi (FORM-*, LUA-*, etc.)
- ‚úÖ All chunks c√≥ `cmetadata->>'source_file'` ƒë·ªÉ trace back to original files
- ‚úÖ Documents table c√≥ full metadata (59 documents)

**2. API Routers - Documents Management**
- ‚úÖ `/api/documents/catalog` - ƒê√£ query theo `document_id` m·ªõi
- ‚úÖ `/api/documents/catalog/{document_id}` - ƒê√£ support document_id m·ªõi
- ‚úÖ `/api/documents/catalog/{document_id}/status` - Update status cho all chunks
- ‚úÖ Document name mapping file: `src/config/document_name_mapping.json`

**3. Basic Retrieval**
- ‚úÖ BaseVectorRetriever query vector DB tr·ª±c ti·∫øp ‚Üí t·ª± ƒë·ªông d√πng document_id m·ªõi
- ‚úÖ MetadataFilter ƒë√£ c√≥ s·∫µn filter logic

### ‚ö†Ô∏è Need Verification (May Work But Need Testing)

**1. QA Chain (`src/generation/chains/qa_chain.py`)**
- üìç Function `format_document_reference()` format metadata cho sources
- üìç Function `answer()` t·∫°o retriever ƒë·ªông + format sources
- ‚ö†Ô∏è **Check**: Sources c√≥ hi·ªÉn th·ªã document_id m·ªõi ƒë√∫ng kh√¥ng?

**2. Context Formatter (`src/generation/formatters/context_formatter.py`)**
- üìç Method `_clean_document_id()` replace old prefixes (`law_`, `decree_`, `bidding_`, `untitled`)
- ‚ö†Ô∏è **Risk**: C√≥ th·ªÉ v·∫´n expect old format ‚Üí c·∫ßn update regex
- ‚ö†Ô∏è **Check**: Format FORM-*, LUA-* c√≥ user-friendly kh√¥ng?

**3. All Retrievers**
- üìç `BaseVectorRetriever` - Query PGVector
- üìç `EnhancedRetriever` - Add query enhancement + reranking
- üìç `FusionRetriever` - RAG-Fusion v·ªõi RRF
- üìç `AdaptiveKRetriever` - Dynamic K selection
- ‚ö†Ô∏è **Check**: T·∫•t c·∫£ ƒë·ªÅu tr·∫£ v·ªÅ chunks v·ªõi document_id m·ªõi?

### üö® Need Updates (Confirmed Issues)

**1. Preprocessing Pipeline**
- üî¥ **Critical**: Khi upload documents m·ªõi, generate document_id theo format c≈© hay m·ªõi?
- üìÅ Files to check:
  - `src/preprocessing/upload_pipeline.py`
  - `src/preprocessing/base/base_pipeline.py`
  - `src/preprocessing/schema/unified_schema.py`

**2. Test Files**
- üî¥ Test assertions expect old format (`bidding_untitled`, `law_untitled`)
- üìÅ Files to update:
  - `scripts/tests/test_api_endpoints.py`
  - `scripts/tests/test_core_system.py`
  - `scripts/test/integration/test_e2e_pipeline.py`
  - `scripts/tests/retrieval/test_api_with_filtering.py`

**3. Example Documents in Code**
- üî¥ Hardcoded example document_ids trong docstrings/comments
- üìÅ Files:
  - `src/generation/formatters/context_formatter.py` (line 210+)
  - `src/preprocessing/schema/models/document_info_types.py`

---

## üìÖ IMPLEMENTATION PLAN

### **Phase 1: Verification & Quick Wins** (2 gi·ªù)

#### Task 1.1: Test Current API Endpoints ‚è±Ô∏è 30 ph√∫t
```bash
# Kh·ªüi ƒë·ªông server
./start_server.sh

# Test health check
curl http://localhost:8000/health

# Test /ask endpoint
curl -X POST http://localhost:8000/ask \
  -H "Content-Type: application/json" \
  -d '{"question": "Lu·∫≠t ƒë·∫•u th·∫ßu 2025 quy ƒë·ªãnh g√¨?", "mode": "balanced"}'

# Verify sources c√≥ document_id m·ªõi
# Expected: FORM-*, LUA-*, kh√¥ng c√≥ bidding_untitled
```

**Success Criteria:**
- ‚úÖ Response c√≥ `sources` v·ªõi document_id format m·ªõi
- ‚úÖ `detailed_sources` hi·ªÉn th·ªã document name r√µ r√†ng
- ‚úÖ Kh√¥ng c√≥ `bidding_untitled` ho·∫∑c `law_untitled` trong output

#### Task 1.2: Test Documents Management API ‚è±Ô∏è 30 ph√∫t
```bash
# List all documents
curl "http://localhost:8000/api/documents/catalog?limit=100"

# Get specific document
curl "http://localhost:8000/api/documents/catalog/LUA-90-2025-QH15"

# Get document stats
curl "http://localhost:8000/api/documents/catalog/LUA-90-2025-QH15/stats"
```

**Success Criteria:**
- ‚úÖ Catalog tr·∫£ v·ªÅ 57-59 documents v·ªõi document_id m·ªõi
- ‚úÖ M·ªói document c√≥ `title` t·ª´ mapping file
- ‚úÖ Status filtering ho·∫°t ƒë·ªông (default: `active`)

#### Task 1.3: Update Context Formatter ‚è±Ô∏è 1 gi·ªù

**File**: `src/generation/formatters/context_formatter.py`

**Changes:**

```python
# OLD (line 172):
def _clean_document_id(self, doc_id: str) -> str:
    """Clean document ID for display."""
    doc_id = (
        doc_id.replace("law_", "").replace("decree_", "").replace("circular_", "")
    )
    doc_id = doc_id.replace("decision_", "").replace("bidding_", "")
    doc_id = doc_id.replace("untitled", "VƒÉn b·∫£n")
    doc_id = doc_id.replace("_", " ")
    return doc_id.strip()

# NEW:
def _clean_document_id(self, doc_id: str) -> str:
    """
    Clean document ID for display.
    
    Handles new format: FORM-*, LUA-*, TEMPLATE-*, EXAM-*
    """
    import re
    
    # New format patterns
    patterns = {
        r'^FORM-(.+)': lambda m: f"Bi·ªÉu m·∫´u: {m.group(1).replace('-', ' ')}",
        r'^LUA-(.+)': lambda m: f"Lu·∫≠t: {m.group(1).replace('-', ' ')}",
        r'^ND-(.+)': lambda m: f"Ngh·ªã ƒë·ªãnh: {m.group(1).replace('-', ' ')}",
        r'^TT-(.+)': lambda m: f"Th√¥ng t∆∞: {m.group(1).replace('-', ' ')}",
        r'^QD-(.+)': lambda m: f"Quy·∫øt ƒë·ªãnh: {m.group(1).replace('-', ' ')}",
        r'^TEMPLATE-(.+)': lambda m: f"M·∫´u: {m.group(1).replace('-', ' ')}",
        r'^EXAM-(.+)': lambda m: f"C√¢u h·ªèi thi: {m.group(1).replace('-', ' ')}",
    }
    
    for pattern, formatter in patterns.items():
        match = re.match(pattern, doc_id)
        if match:
            return formatter(match)
    
    # Fallback for old format (backward compatibility)
    doc_id = (
        doc_id.replace("law_", "Lu·∫≠t ")
        .replace("decree_", "Ngh·ªã ƒë·ªãnh ")
        .replace("circular_", "Th√¥ng t∆∞ ")
        .replace("bidding_", "H·ªì s∆° ")
        .replace("untitled", "VƒÉn b·∫£n")
        .replace("_", " ")
    )
    
    return doc_id.strip()

# Update example document (line 210+)
if __name__ == "__main__":
    from langchain_core.documents import Document

    example_doc = Document(
        page_content="Nh√† th·∫ßu tham d·ª± th·∫ßu ph·∫£i ƒë√°p ·ª©ng c√°c ƒëi·ªÅu ki·ªán v·ªÅ nƒÉng l·ª±c v√† kinh nghi·ªám theo quy ƒë·ªãnh...",
        metadata={
            "chunk_id": "LUA-90-2025-QH15_dieu_0047",  # NEW FORMAT
            "document_id": "LUA-90-2025-QH15",  # NEW FORMAT
            "document_type": "law",
            "title": "Lu·∫≠t ƒê·∫•u th·∫ßu 2025",
            "dieu": "47",
            "khoan": "1",
            # ...
```

---

### **Phase 2: Update Preprocessing Pipeline** (3 gi·ªù)

#### Task 2.1: Analyze Upload Pipeline ‚è±Ô∏è 1 gi·ªù

**Goal**: Hi·ªÉu flow t·∫°o document_id khi upload documents m·ªõi

**Files to Read:**
```
src/preprocessing/upload_pipeline.py
src/preprocessing/base/base_pipeline.py
src/preprocessing/schema/unified_schema.py
src/preprocessing/schema/models/document_info_types.py
```

**Questions to Answer:**
1. Khi upload file m·ªõi, document_id ƒë∆∞·ª£c generate ·ªü ƒë√¢u?
2. Format hi·ªán t·∫°i l√† g√¨? (C√≥ ph·∫£i v·∫´n d√πng `{type}_untitled_{name}`?)
3. C√≥ logic detect document type (law, decree, bidding, template)?
4. Metadata extraction c√≥ ƒë√∫ng v·ªõi new schema kh√¥ng?

#### Task 2.2: Update Document ID Generation ‚è±Ô∏è 1 gi·ªù

**T·∫°o ho·∫∑c update file**: `src/preprocessing/utils/document_id_generator.py`

```python
"""
Generate document_id theo format m·ªõi sau migration.

Format chu·∫©n:
- Lu·∫≠t: LUA-{s·ªë}-{nƒÉm}-{m√£ QH/CP} (e.g., LUA-90-2025-QH15)
- Ngh·ªã ƒë·ªãnh: ND-{s·ªë}-{nƒÉm}-{CP/Nƒê} (e.g., ND-24-2024-Nƒê-CP)
- Th√¥ng t∆∞: TT-{s·ªë}-{nƒÉm}-{TT} (e.g., TT-03-2024-BKH)
- Quy·∫øt ƒë·ªãnh: QD-{s·ªë}-{nƒÉm} (e.g., QD-218-2024-TTg)
- Bi·ªÉu m·∫´u: FORM-{descriptive-name} (e.g., FORM-05-M·∫´u-B√°o-c√°o-ƒë·∫•u-th·∫ßu)
- M·∫´u b√°o c√°o: TEMPLATE-{descriptive-name}
- C√¢u h·ªèi thi: EXAM-{t√™n-ng·∫Øn}
"""

import re
from typing import Optional
from datetime import datetime


class DocumentIDGenerator:
    """Generate standardized document_id for new uploads."""
    
    @staticmethod
    def from_filename(filename: str, doc_type: str) -> str:
        """
        Generate document_id from filename.
        
        Args:
            filename: Original filename (e.g., "Lu·∫≠t 90/2025/QH15.pdf")
            doc_type: Document type (law, decree, circular, bidding, template, exam)
            
        Returns:
            Standardized document_id
        """
        # Remove extension
        name_base = filename.rsplit('.', 1)[0]
        
        # Detect document type from filename patterns
        if doc_type == "law" or "lu·∫≠t" in filename.lower():
            return DocumentIDGenerator._generate_law_id(name_base)
        
        elif doc_type == "decree" or "ngh·ªã ƒë·ªãnh" in filename.lower():
            return DocumentIDGenerator._generate_decree_id(name_base)
        
        elif doc_type == "circular" or "th√¥ng t∆∞" in filename.lower():
            return DocumentIDGenerator._generate_circular_id(name_base)
        
        elif doc_type == "decision" or "quy·∫øt ƒë·ªãnh" in filename.lower():
            return DocumentIDGenerator._generate_decision_id(name_base)
        
        elif doc_type in ["bidding", "bidding_template"]:
            return DocumentIDGenerator._generate_form_id(name_base)
        
        elif doc_type in ["template", "report_template"]:
            return DocumentIDGenerator._generate_template_id(name_base)
        
        elif doc_type == "exam_questions":
            return DocumentIDGenerator._generate_exam_id(name_base)
        
        else:
            # Fallback: sanitize filename
            return DocumentIDGenerator._sanitize_id(name_base)
    
    @staticmethod
    def _generate_law_id(name: str) -> str:
        """
        Generate law ID from name.
        
        Examples:
            "Lu·∫≠t 90/2025/QH15" ‚Üí "LUA-90-2025-QH15"
            "Lu·∫≠t ƒê·∫•u th·∫ßu 2025" ‚Üí "LUA-ƒê·∫•u-th·∫ßu-2025"
        """
        # Pattern 1: "Lu·∫≠t {s·ªë}/{nƒÉm}/{m√£}"
        match = re.search(r'(\d+)[/\-](\d{4})[/\-]([A-Z0-9\-]+)', name, re.IGNORECASE)
        if match:
            num, year, code = match.groups()
            return f"LUA-{num}-{year}-{code}"
        
        # Pattern 2: "Lu·∫≠t {t√™n} {nƒÉm}"
        match = re.search(r'lu·∫≠t\s+(.+?)\s+(\d{4})', name, re.IGNORECASE)
        if match:
            title, year = match.groups()
            title_slug = title.replace(' ', '-')
            return f"LUA-{title_slug}-{year}"
        
        # Fallback: clean name
        clean = name.replace('Lu·∫≠t', '').replace('lu·∫≠t', '').strip()
        return f"LUA-{DocumentIDGenerator._sanitize_id(clean)}"
    
    @staticmethod
    def _generate_decree_id(name: str) -> str:
        """
        Generate decree ID.
        
        Examples:
            "Ngh·ªã ƒë·ªãnh 24/2024/Nƒê-CP" ‚Üí "ND-24-2024-Nƒê-CP"
        """
        match = re.search(r'(\d+)[/\-](\d{4})[/\-](.+)', name, re.IGNORECASE)
        if match:
            num, year, code = match.groups()
            code = code.replace('/', '-').upper()
            return f"ND-{num}-{year}-{code}"
        
        clean = name.replace('Ngh·ªã ƒë·ªãnh', '').replace('ngh·ªã ƒë·ªãnh', '').strip()
        return f"ND-{DocumentIDGenerator._sanitize_id(clean)}"
    
    @staticmethod
    def _generate_circular_id(name: str) -> str:
        """Generate circular ID."""
        match = re.search(r'(\d+)[/\-](\d{4})[/\-](.+)', name, re.IGNORECASE)
        if match:
            num, year, code = match.groups()
            code = code.replace('/', '-').upper()
            return f"TT-{num}-{year}-{code}"
        
        clean = name.replace('Th√¥ng t∆∞', '').replace('th√¥ng t∆∞', '').strip()
        return f"TT-{DocumentIDGenerator._sanitize_id(clean)}"
    
    @staticmethod
    def _generate_decision_id(name: str) -> str:
        """Generate decision ID."""
        match = re.search(r'(\d+)[/\-](\d{4})', name, re.IGNORECASE)
        if match:
            num, year = match.groups()
            return f"QD-{num}-{year}"
        
        clean = name.replace('Quy·∫øt ƒë·ªãnh', '').replace('quy·∫øt ƒë·ªãnh', '').strip()
        return f"QD-{DocumentIDGenerator._sanitize_id(clean)}"
    
    @staticmethod
    def _generate_form_id(name: str) -> str:
        """
        Generate form/bidding template ID.
        
        Examples:
            "M·∫´u 05 - B√°o c√°o ƒë·∫•u th·∫ßu" ‚Üí "FORM-05-B√°o-c√°o-ƒë·∫•u-th·∫ßu"
        """
        # Remove common prefixes
        clean = re.sub(r'^(M·∫´u|Bi·ªÉu m·∫´u|Form)\s*', '', name, flags=re.IGNORECASE)
        clean = DocumentIDGenerator._sanitize_id(clean)
        return f"FORM-{clean}"
    
    @staticmethod
    def _generate_template_id(name: str) -> str:
        """Generate template ID for report templates."""
        clean = DocumentIDGenerator._sanitize_id(name)
        return f"TEMPLATE-{clean}"
    
    @staticmethod
    def _generate_exam_id(name: str) -> str:
        """Generate exam questions ID."""
        clean = DocumentIDGenerator._sanitize_id(name)
        return f"EXAM-{clean}"
    
    @staticmethod
    def _sanitize_id(text: str) -> str:
        """
        Sanitize text to valid ID format.
        
        Rules:
        - Replace spaces with hyphens
        - Remove special chars except hyphens
        - Limit length to 100 chars
        """
        # Replace spaces with hyphens
        text = text.replace(' ', '-')
        
        # Remove special characters except Vietnamese, numbers, hyphens
        text = re.sub(r'[^\w\-]', '', text, flags=re.UNICODE)
        
        # Remove multiple consecutive hyphens
        text = re.sub(r'-+', '-', text)
        
        # Truncate to 100 chars
        if len(text) > 100:
            text = text[:100].rstrip('-')
        
        return text.strip('-')


# Tests
if __name__ == "__main__":
    gen = DocumentIDGenerator()
    
    test_cases = [
        ("Lu·∫≠t 90/2025/QH15.pdf", "law", "LUA-90-2025-QH15"),
        ("Ngh·ªã ƒë·ªãnh 24/2024/Nƒê-CP.pdf", "decree", "ND-24-2024-Nƒê-CP"),
        ("Th√¥ng t∆∞ 03/2024/TT-BKH.pdf", "circular", "TT-03-2024-TT-BKH"),
        ("M·∫´u 05 - B√°o c√°o ƒë·∫•u th·∫ßu.docx", "bidding", "FORM-05-B√°o-c√°o-ƒë·∫•u-th·∫ßu"),
        ("Ng√¢n h√†ng c√¢u h·ªèi CCDT.pdf", "exam_questions", "EXAM-Ng√¢n-h√†ng-c√¢u-h·ªèi-CCDT"),
    ]
    
    print("üß™ Testing DocumentIDGenerator:")
    for filename, doc_type, expected in test_cases:
        result = gen.from_filename(filename, doc_type)
        status = "‚úÖ" if result == expected else "‚ùå"
        print(f"{status} {filename} ({doc_type})")
        print(f"   Generated: {result}")
        if result != expected:
            print(f"   Expected:  {expected}")
        print()
```

#### Task 2.3: Update Upload Pipeline ‚è±Ô∏è 1 gi·ªù

**File**: `src/preprocessing/upload_pipeline.py`

**Changes:**
1. Import `DocumentIDGenerator`
2. Replace hardcoded `{type}_untitled_{name}` logic v·ªõi generator
3. Update metadata ƒë·ªÉ include document_id m·ªõi

```python
# ADD IMPORT
from src.preprocessing.utils.document_id_generator import DocumentIDGenerator

# UPDATE trong process() ho·∫∑c extract_metadata()
def extract_metadata(file_path: str, doc_type: str) -> dict:
    """Extract metadata and generate document_id."""
    filename = Path(file_path).name
    
    # NEW: Generate document_id t·ª´ filename
    document_id = DocumentIDGenerator.from_filename(filename, doc_type)
    
    # OLD code ƒë√£ generate doc_id nh∆∞ th·∫ø n√†o ‚Üí replace
    
    metadata = {
        "document_id": document_id,  # NEW FORMAT
        "document_type": doc_type,
        "source_file": file_path,
        "filename": filename,
        # ... other metadata
    }
    
    return metadata
```

---

### **Phase 3: Update Test Suite** (3 gi·ªù)

#### Task 3.1: Update API Endpoint Tests ‚è±Ô∏è 1 gi·ªù

**File**: `scripts/tests/test_api_endpoints.py`

**Changes:**
```python
# OLD assertions expecting bidding_untitled
assert "bidding_untitled" in sources[0]

# NEW assertions v·ªõi document_id format m·ªõi
def test_ask_endpoint():
    response = requests.post(
        "http://localhost:8000/ask",
        json={"question": "Lu·∫≠t ƒë·∫•u th·∫ßu 2025 quy ƒë·ªãnh g√¨?", "mode": "balanced"}
    )
    
    assert response.status_code == 200
    data = response.json()
    
    # Verify new document_id format
    assert "sources" in data
    sources = data["sources"]
    
    # Check at least one source uses new format
    has_new_format = any(
        re.match(r'^(LUA|ND|TT|QD|FORM|TEMPLATE|EXAM)-', src) 
        for src in sources
    )
    assert has_new_format, f"Expected new document_id format, got: {sources}"
    
    # Should NOT contain old format
    has_old_format = any(
        "untitled" in src.lower() or "_untitled_" in src
        for src in sources
    )
    assert not has_old_format, f"Found old format in sources: {sources}"


def test_documents_catalog():
    response = requests.get("http://localhost:8000/api/documents/catalog?limit=100")
    
    assert response.status_code == 200
    data = response.json()
    
    assert len(data) >= 57  # Should have at least 57 documents
    
    # Verify all document_ids use new format
    for doc in data:
        doc_id = doc["document_id"]
        assert re.match(r'^(LUA|ND|TT|QD|FORM|TEMPLATE|EXAM)-', doc_id), \
            f"Invalid document_id format: {doc_id}"
        
        # Should have title from mapping
        assert len(doc["title"]) > 5, f"Missing title for {doc_id}"


def test_get_specific_document():
    """Test getting specific document with new document_id."""
    # Use actual document_id from migration
    doc_id = "LUA-90-2025-QH15"
    
    response = requests.get(f"http://localhost:8000/api/documents/catalog/{doc_id}")
    
    assert response.status_code == 200
    data = response.json()
    
    assert data["document_id"] == doc_id
    assert data["total_chunks"] > 0
    assert "chunks" in data
```

#### Task 3.2: Update E2E Pipeline Tests ‚è±Ô∏è 1 gi·ªù

**File**: `scripts/test/integration/test_e2e_pipeline.py`

**Changes:**
```python
def test_retrieval_returns_new_format():
    """Test that retrieval returns chunks with new document_id."""
    pipeline = RAGPipeline()
    
    result = pipeline.run(
        query="Lu·∫≠t ƒë·∫•u th·∫ßu 2025",
        k=5
    )
    
    docs = result["docs"]
    assert len(docs) > 0, "No documents retrieved"
    
    for doc in docs:
        doc_id = doc.metadata.get("document_id")
        chunk_id = doc.metadata.get("chunk_id")
        
        # Verify new format
        assert doc_id, f"Missing document_id in metadata: {doc.metadata}"
        assert re.match(r'^(LUA|ND|TT|QD|FORM|TEMPLATE|EXAM)-', doc_id), \
            f"Invalid document_id format: {doc_id}"
        
        # Verify chunk_id matches document_id
        assert chunk_id.startswith(doc_id), \
            f"chunk_id {chunk_id} doesn't start with document_id {doc_id}"
        
        # Should NOT have old format
        assert "untitled" not in doc_id.lower()


def test_context_formatting():
    """Test that context formatter displays document_id correctly."""
    from src.generation.formatters.context_formatter import ContextFormatter
    from langchain_core.documents import Document
    
    formatter = ContextFormatter()
    
    test_doc = Document(
        page_content="Test content",
        metadata={
            "document_id": "LUA-90-2025-QH15",
            "chunk_id": "LUA-90-2025-QH15_dieu_0047",
            "title": "Lu·∫≠t ƒê·∫•u th·∫ßu 2025",
            "dieu": "47",
            "khoan": "1"
        }
    )
    
    formatted = formatter.format([test_doc])
    
    # Should display user-friendly format
    assert "Lu·∫≠t: 90 2025 QH15" in formatted or "Lu·∫≠t ƒê·∫•u th·∫ßu" in formatted
    assert "ƒêi·ªÅu 47" in formatted
    
    # Should NOT show raw document_id
    assert "LUA-90-2025-QH15" not in formatted  # Raw format hidden
```

#### Task 3.3: Create Comprehensive Test Notebook ‚è±Ô∏è 1 gi·ªù

**File**: `notebooks/testing/post-migration-endpoint-tests.ipynb`

T·∫°o notebook m·ªõi v·ªõi c√°c test cases:

1. **Test /ask endpoint v·ªõi c√°c modes**
   - Fast, Balanced, Quality, Adaptive
   - Verify sources hi·ªÉn th·ªã document_id m·ªõi

2. **Test /documents/catalog**
   - List all documents
   - Filter by type, status
   - Verify 57-59 documents

3. **Test retrieval v·ªõi filters**
   - Filter by document_id
   - Filter by document_type
   - Filter by status

4. **Test context formatting**
   - Verify hierarchy display
   - Verify document name t·ª´ mapping
   - Verify kh√¥ng c√≤n "untitled"

5. **Performance tests**
   - Query latency v·ªõi document_id m·ªõi
   - Cache effectiveness
   - Memory usage

---

### **Phase 4: Documentation & Cleanup** (2 gi·ªù)

#### Task 4.1: Update Documentation ‚è±Ô∏è 1 gi·ªù

**Files to Update:**

1. **README.md**
   - Add note v·ªÅ migration completion
   - Update example queries v·ªõi document_id m·ªõi

2. **API Documentation**
   ```markdown
   ## Document ID Format
   
   Sau migration (Nov 2025), t·∫•t c·∫£ document_id theo format:
   
   - **Lu·∫≠t**: LUA-{s·ªë}-{nƒÉm}-{m√£} (e.g., LUA-90-2025-QH15)
   - **Ngh·ªã ƒë·ªãnh**: ND-{s·ªë}-{nƒÉm}-{m√£} (e.g., ND-24-2024-Nƒê-CP)
   - **Th√¥ng t∆∞**: TT-{s·ªë}-{nƒÉm}-{m√£} (e.g., TT-03-2024-BKH)
   - **Quy·∫øt ƒë·ªãnh**: QD-{s·ªë}-{nƒÉm} (e.g., QD-218-2024-TTg)
   - **Bi·ªÉu m·∫´u**: FORM-{t√™n} (e.g., FORM-05-M·∫´u-B√°o-c√°o)
   - **M·∫´u**: TEMPLATE-{t√™n}
   - **C√¢u h·ªèi thi**: EXAM-{t√™n}
   
   Old format (`bidding_untitled_*`, `law_untitled_*`) ƒë√£ deprecated.
   ```

3. **documents/technical/API_DOCUMENT_MANAGEMENT_GUIDE.md**
   - Update examples v·ªõi document_id m·ªõi
   - Remove references to old format

#### Task 4.2: Clean Up Old Code ‚è±Ô∏è 30 ph√∫t

**Remove/Archive:**
1. Old migration scripts (n·∫øu kh√¥ng c·∫ßn reference)
2. Deprecated notebooks trong `notebooks/ingestion/`
3. Old test data v·ªõi format c≈©

**Mark as deprecated:**
1. Functions x·ª≠ l√Ω old format (add deprecation warning)
2. Legacy endpoints (n·∫øu c√≥)

#### Task 4.3: Create Migration Summary Report ‚è±Ô∏è 30 ph√∫t

**File**: `documents/migration/MIGRATION_COMPLETION_SUMMARY.md`

```markdown
# Migration Completion Summary

## Overview
- **Date Completed**: 2025-11-20
- **Total Documents Migrated**: 57 (active) + 2 (inactive) = 59
- **Total Chunks**: 6,242
- **Old Format**: bidding_untitled_*, law_untitled_*
- **New Format**: LUA-*, ND-*, TT-*, FORM-*, etc.

## Changes Made

### 1. Database
- ‚úÖ Updated all chunks with new document_id
- ‚úÖ Updated all chunks with source_file metadata
- ‚úÖ Created documents table with full metadata

### 2. API Endpoints
- ‚úÖ /ask - Returns sources v·ªõi document_id m·ªõi
- ‚úÖ /documents/catalog - Lists documents theo document_id m·ªõi
- ‚úÖ /documents/catalog/{id} - Get document by new ID
- ‚úÖ /documents/catalog/{id}/status - Update status

### 3. Pipelines
- ‚úÖ Updated preprocessing ƒë·ªÉ generate new document_id
- ‚úÖ Updated context formatter ƒë·ªÉ display user-friendly names
- ‚úÖ All retrievers ho·∫°t ƒë·ªông v·ªõi metadata m·ªõi

### 4. Tests
- ‚úÖ Updated test assertions ƒë·ªÉ expect new format
- ‚úÖ Created comprehensive test notebook
- ‚úÖ All tests passing v·ªõi document_id m·ªõi

## Backward Compatibility

Old document_id format v·∫´n ƒë∆∞·ª£c support trong:
- Context formatter (fallback logic)
- Test data (archived)

## Next Steps

1. Monitor production queries for any issues
2. Preprocess 4 exam question PDFs (optional)
3. Consider deprecating old format support sau 3 months
```

---

## üöÄ EXECUTION CHECKLIST

### Before Starting
- [ ] Backup current database
- [ ] Create git branch: `feature/post-migration-updates`
- [ ] Document current system state

### Phase 1: Verification ‚úÖ
- [ ] Test current /ask endpoint
- [ ] Test /documents/catalog API
- [ ] Update context_formatter.py
- [ ] Verify sources display correctly

### Phase 2: Preprocessing ‚úÖ
- [ ] Create DocumentIDGenerator
- [ ] Update upload_pipeline.py
- [ ] Test with sample file upload
- [ ] Verify new documents get correct ID

### Phase 3: Tests ‚úÖ
- [ ] Update test_api_endpoints.py
- [ ] Update test_e2e_pipeline.py
- [ ] Create comprehensive test notebook
- [ ] Run full test suite
- [ ] All tests passing

### Phase 4: Cleanup ‚úÖ
- [ ] Update README.md
- [ ] Update API documentation
- [ ] Create migration summary
- [ ] Archive old code
- [ ] Commit all changes

### Post-Deployment
- [ ] Monitor API logs for errors
- [ ] Check query performance
- [ ] Verify user-facing sources
- [ ] Collect feedback

---

## üìä SUCCESS METRICS

### Functional
- ‚úÖ 100% API tests passing
- ‚úÖ Zero old format (bidding_untitled) in responses
- ‚úÖ All document_ids follow new pattern
- ‚úÖ Context formatter displays user-friendly names

### Performance
- ‚è±Ô∏è Query latency unchanged (<3s p95)
- üìä No increase in error rate
- üíæ Memory usage stable

### User Experience
- üìö Document names readable (t·ª´ mapping file)
- üîç Sources include proper hierarchy (ƒêi·ªÅu, Kho·∫£n)
- ‚ö° Response times acceptable

---

## ‚ö†Ô∏è RISKS & MITIGATION

### Risk 1: Breaking Existing Queries
**Mitigation:**
- Keep backward compatibility trong context formatter
- Test v·ªõi sample queries tr∆∞·ªõc khi deploy
- Monitor error logs post-deployment

### Risk 2: Performance Degradation
**Mitigation:**
- Profile code changes
- Test v·ªõi concurrent users
- Keep reranker singleton fix

### Risk 3: Missing Edge Cases
**Mitigation:**
- Comprehensive test coverage
- Test v·ªõi real production queries
- Gradual rollout

---

## üìû SUPPORT

**Issues or Questions:**
- Check `documents/technical/` for detailed guides
- Review migration notebook: `notebooks/migration/document-structure-migration.ipynb`
- Test notebook: `notebooks/testing/post-migration-endpoint-tests.ipynb`

**Related Documents:**
- `documents/migration/MIGRATION_PLAN_UPDATE_METADATA_ONLY.md`
- `documents/technical/API_DOCUMENT_MANAGEMENT_GUIDE.md`
- `documents/technical/PIPELINE_INTEGRATION_SUMMARY.md`


# ğŸ” CACHE & HNSW - GIáº¢I THÃCH CHI TIáº¾T

## âœ… REDIS CACHE - ÄÃƒ TRIá»‚N KHAI

### Kiáº¿n trÃºc 3-layer caching:

```
Query â†’ L1 (Memory) â†’ L2 (Redis) â†’ L3 (PostgreSQL)
        â†“ 0.1ms      â†“ 1-5ms      â†“ 868ms
```

### ğŸ“ File implementation:
**`src/retrieval/cached_retrieval.py`** (369 dÃ²ng)

### ğŸ¯ CÃ¡ch hoáº¡t Ä‘á»™ng:

#### Layer 1 - Memory Cache (Fastest)
- **Storage**: Python dictionary trong RAM
- **Latency**: ~0.1ms
- **Size**: 100 queries (configurable)
- **Strategy**: LRU (Least Recently Used)
- **Lifetime**: Process lifetime

```python
cached_store = CachedVectorStore(
    vector_store,
    enable_l1_cache=True,     # â† Memory cache
    l1_cache_size=100,        # â† Max 100 queries
)
```

#### Layer 2 - Redis Cache (Fast)
- **Storage**: Redis server (in-memory database)
- **Latency**: ~1-5ms
- **Size**: Unlimited (depends on RAM)
- **Strategy**: TTL-based expiration
- **Lifetime**: Persistent, shared across processes
- **TTL**: 300s (5 phÃºt) - configurable

```python
cached_store = CachedVectorStore(
    vector_store,
    redis_host="localhost",   # â† Redis server
    redis_port=6379,
    ttl=300,                  # â† 5 minutes expiration
)
```

#### Layer 3 - PostgreSQL (Authoritative)
- **Storage**: PostgreSQL + pgvector
- **Latency**: ~868ms (current)
- **Size**: Unlimited
- **Strategy**: Vector similarity search
- **Lifetime**: Permanent

### ğŸ”‘ Cache Key Generation:
```python
# Query: "Ä‘iá»u kiá»‡n tham gia Ä‘áº¥u tháº§u"
# K: 5
# Filter: {"document_type": "law"}

# Normalized key:
"q:Ä‘iá»u kiá»‡n tham gia Ä‘áº¥u tháº§u|k:5|f:document_type=law"
       â†“ MD5 hash
"rag:retrieval:a3f2c1d9e8b7..."
```

### ğŸ“Š Performance Impact:

| Cache Level | Latency | vs L3 | Speedup |
|-------------|---------|-------|---------|
| **L3 (PostgreSQL)** | 868ms | Baseline | 1x |
| **L2 (Redis)** | ~3ms | -865ms | **289x faster** âœ…âœ…âœ… |
| **L1 (Memory)** | ~0.1ms | -868ms | **8680x faster** âœ…âœ…âœ…âœ… |

### ğŸ¯ Expected Hit Rates (Production):
```
Total queries: 1000
â”œâ”€â”€ L1 hits: 50% â†’ 500 queries @ 0.1ms
â”œâ”€â”€ L2 hits: 45% â†’ 450 queries @ 3ms
â””â”€â”€ L3 hits: 5% â†’ 50 queries @ 868ms

Average latency:
= (500 Ã— 0.1ms) + (450 Ã— 3ms) + (50 Ã— 868ms) / 1000
= 50ms + 1350ms + 43400ms / 1000
= 44.8ms average âœ… (vs 868ms without cache)

Improvement: 19.4x faster!
```

### âœ… ÄÃ£ triá»ƒn khai cÃ¡c tÃ­nh nÄƒng:

1. **Multi-layer caching** âœ…
   - L1 (memory) + L2 (Redis) + L3 (PostgreSQL)

2. **LRU eviction** âœ…
   - Tá»± Ä‘á»™ng xÃ³a queries cÅ© nháº¥t khi L1 Ä‘áº§y

3. **Cache statistics** âœ…
   - Track hits/misses, hit rate
   
4. **Cache invalidation** âœ…
   - Clear all cache
   - Invalidate specific query

5. **Error handling** âœ…
   - Graceful degradation náº¿u Redis fail

### ğŸ§ª Test Cache (Ä‘Ã£ cÃ³):
```bash
# Cháº¡y test
python3 src/retrieval/cached_retrieval.py

# Káº¿t quáº£ expected:
# Round 1: All L3 hits (~868ms má»—i query)
# Round 2: All L1 hits (~0.1ms má»—i query) 
# Round 3: All L2 hits (~3ms má»—i query)
```

---

## ğŸš€ HNSW - HIERARCHICAL NAVIGABLE SMALL WORLD

### HNSW lÃ  gÃ¬?

**HNSW** = **H**ierarchical **N**avigable **S**mall **W**orld graph

Má»™t thuáº­t toÃ¡n **vector index** Ä‘á»ƒ tÃ¬m kiáº¿m nearest neighbors SIÃŠU NHANH!

### ğŸ¯ So sÃ¡nh vá»›i IVFFlat (hiá»‡n táº¡i):

| Feature | IVFFlat (Current) | HNSW (Recommended) |
|---------|-------------------|-------------------|
| **Build Time** | Fast (~10s) | Slower (~1-2 min) |
| **Search Speed** | Slow (868ms) | **Fast (100-200ms)** âœ… |
| **Accuracy** | Medium (85-95%) | **High (95-99%)** âœ… |
| **Memory** | Low | Medium |
| **Index Type** | Cluster-based | Graph-based |
| **Best For** | Small datasets | **Productionping 2>/dev/null || echo "Redis chÆ°a cháº¡y"* âœ… |

### ğŸ“ CÃ¡ch HNSW hoáº¡t Ä‘á»™ng:

#### 1. IVFFlat (Current method):
```
Táº¥t cáº£ 4,640 embeddings
    â†“ Cluster thÃ nh 100 lists (IVF)
    
List 1: [vec1, vec2, vec3, ...]  â† 46 vectors
List 2: [vec10, vec11, ...]      â† 46 vectors
List 3: [vec20, vec21, ...]      â† 46 vectors
...
List 100: [vec4600, ...]         â† 46 vectors

Search process:
1. Find closest list (fast)
2. Search ALL vectors in that list (slow!)
3. Return top-k

Problem: Pháº£i scan 46-92 vectors (náº¿u probes=1-2)
â†’ Slow: 868ms
```

#### 2. HNSW (Graph-based):
```
Layer 3 (top):    A -------- B
                  |          |
                  |          |
Layer 2:      A - C - D ---- B - E
              |   |   |      |   |
Layer 1:  A - C - D - F - G - B - E - H
          |||||||||||||||||||||||||||||
Layer 0:  [All 4,640 vectors connected]

Search process:
1. Start at top layer (long jumps)
2. Navigate to approximate area (fast!)
3. Drop to lower layer (shorter jumps)
4. Repeat until Layer 0
5. Refine locally
6. Return top-k

Benefit: Logarithmic search time O(log N)
â†’ Fast: 100-200ms âœ…
```

### ğŸ›ï¸ HNSW Parameters:

#### **m** (number of connections per node)
```
m = 4:   Fewer connections â†’ faster build, less accurate
m = 16:  Balanced â†’ RECOMMENDED âœ…
m = 32:  More connections â†’ slower build, more accurate
m = 64:  Maximum accuracy, highest memory
```

**Recommendation cho 4,640 embeddings**: `m = 16`

#### **ef_construction** (build quality)
```
ef_construction = 32:  Fast build, lower quality
ef_construction = 64:  Balanced â†’ RECOMMENDED âœ…
ef_construction = 128: Slow build, high quality
ef_construction = 200: Maximum quality
```

**Recommendation**: `ef_construction = 64`

#### **ef_search** (search quality at runtime)
```
ef_search = 10:  Fast, less accurate (85%)
ef_search = 40:  Balanced â†’ RECOMMENDED âœ… (95% accuracy)
ef_search = 100: Slow, very accurate (99%)
```

**Recommendation**: `ef_search = 40`

### ğŸ’¾ Memory Usage:

```
IVFFlat:
- Lists metadata: ~10 KB
- Overhead: ~20 MB
Total: ~20 MB

HNSW:
- Graph structure: ~50 MB
- Connections: m Ã— 4,640 Ã— 8 bytes
  = 16 Ã— 4,640 Ã— 8 = 595 KB
Total: ~51 MB

Impact: +31 MB (acceptable!)
```

### ğŸš€ Migration Commands:

#### Step 1: Check current index
```sql
-- Connect to database
psql postgresql://localhost:5432/rag_bidding_v2

-- List indexes
\d langchain_pg_embedding

-- Should see:
-- langchain_pg_embedding_embedding_idx (ivfflat)
```

#### Step 2: Drop IVFFlat index
```sql
DROP INDEX IF EXISTS langchain_pg_embedding_embedding_idx;
```

#### Step 3: Create HNSW index
```sql
CREATE INDEX langchain_pg_embedding_embedding_idx 
ON langchain_pg_embedding 
USING hnsw (embedding vector_cosine_ops)
WITH (
    m = 16,              -- 16 connections per node
    ef_construction = 64  -- Build quality
);

-- This takes ~1-2 minutes for 4,640 embeddings
```

#### Step 4: Set runtime parameters
```sql
-- In PostgreSQL config or session
SET hnsw.ef_search = 40;  -- Search quality (95% recall)
```

#### Step 5: Verify
```sql
-- Check index exists
SELECT indexname, indexdef 
FROM pg_indexes 
WHERE tablename = 'langchain_pg_embedding';

-- Should show HNSW index
```

### ğŸ“Š Expected Performance Improvement:

```
BEFORE (IVFFlat):
  Mean:     868ms
  P95:      1304ms
  P99:      1552ms
  Accuracy: ~92%

AFTER (HNSW):
  Mean:     150-200ms  â† 4.3-5.8x faster âœ…
  P95:      250-300ms  â† 4.3-5.2x faster âœ…
  P99:      350-400ms  â† 3.9-4.4x faster âœ…
  Accuracy: ~96%       â† Better! âœ…
```

### ğŸ¯ When to use HNSW vs IVFFlat?

#### Use **HNSW** when:
- âœ… Production deployment
- âœ… Need fast queries (<200ms)
- âœ… Need high accuracy (>95%)
- âœ… Dataset > 1,000 vectors
- âœ… Have enough memory

#### Use **IVFFlat** when:
- ğŸŸ¡ Development/testing only
- ğŸŸ¡ Fast rebuild needed
- ğŸŸ¡ Low memory constraints
- ğŸŸ¡ Dataset < 1,000 vectors

**Your case (4,640 embeddings)**: HNSW lÃ  lá»±a chá»n tá»‘t nháº¥t! âœ…

---

## ğŸ¯ COMBINED: Cache + HNSW

### Performance vá»›i cáº£ 2 optimizations:

```
Scenario 1: Cache MISS (cold query)
  Query â†’ L1 miss â†’ L2 miss â†’ L3 (HNSW)
  Latency: 150-200ms (vs 868ms before)
  Improvement: 4.3-5.8x faster âœ…

Scenario 2: Cache HIT (L2 Redis)
  Query â†’ L1 miss â†’ L2 HIT
  Latency: ~3ms
  Improvement: 289x faster âœ…âœ…

Scenario 3: Cache HIT (L1 Memory)
  Query â†’ L1 HIT
  Latency: ~0.1ms
  Improvement: 8680x faster âœ…âœ…âœ…

Production (95% cache hit rate):
  Average: ~44.8ms (vs 868ms)
  Improvement: 19.4x faster âœ…âœ…
```

### ğŸš€ Implementation Checklist:

#### âœ… Cache (Already Done!)
- [x] Redis running
- [x] CachedVectorStore implemented
- [x] Multi-layer (L1 + L2 + L3)
- [x] LRU eviction
- [x] Statistics tracking
- [ ] Integrate into production code

#### â³ HNSW (To Do)
- [ ] Drop IVFFlat index
- [ ] Create HNSW index (1-2 min)
- [ ] Set ef_search=40
- [ ] Re-benchmark
- [ ] Compare results

---

## ğŸ§ª NEXT STEPS: Test Both Optimizations

### Step 1: Test Cache (5 phÃºt)
```bash
# Run cache test
python3 src/retrieval/cached_retrieval.py

# Expected output:
# Round 1: 3 queries @ ~868ms each (L3)
# Round 2: 3 queries @ ~0.1ms each (L1)
# Round 3: 3 queries @ ~3ms each (L2)
# Hit rate: 66.7%
```

### Step 2: Migrate to HNSW (2 phÃºt)
```bash
# Connect to database
psql postgresql://localhost:5432/rag_bidding_v2

# Run migration SQL (see above)
# Wait 1-2 minutes for index build
```

### Step 3: Benchmark HNSW (3 phÃºt)
```bash
# Re-run benchmark
python3 scripts/benchmark_retrieval.py

# Expected improvement:
# Mean: 868ms â†’ 150-200ms âœ…
```

### Step 4: Test Cache + HNSW (5 phÃºt)
```bash
# Create combined test script
# Expected:
# Cold queries: ~150-200ms (HNSW)
# Warm queries: ~3ms (Redis) or ~0.1ms (Memory)
```

---

## ğŸ“Œ TÃ“M Táº®T

### Redis Cache:
- âœ… **ÄÃ£ triá»ƒn khai** tá»« hÃ´m qua
- âœ… 3-layer: Memory + Redis + PostgreSQL
- âœ… Expected: 19.4x faster (average)
- âš ï¸ ChÆ°a integrate vÃ o production code

### HNSW Index:
- âŒ **ChÆ°a migrate** (váº«n dÃ¹ng IVFFlat)
- ğŸ¯ Thuáº­t toÃ¡n graph-based search
- ğŸ¯ Expected: 4.3-5.8x faster than IVFFlat
- ğŸ¯ Build time: ~1-2 minutes
- ğŸ¯ Memory: +31 MB (acceptable)

### Combined (Cache + HNSW):
- ğŸš€ Cold queries: 150-200ms (HNSW)
- ğŸš€ Warm queries: 0.1-3ms (Cache)
- ğŸš€ Average: ~44.8ms (95% cache hit)
- ğŸš€ Total improvement: **19.4x faster!**

---

**Created**: 3/11/2025 08:30 AM  
**Status**: Cache ready, HNSW pending migration  
**Next**: Test cache, then migrate to HNSW


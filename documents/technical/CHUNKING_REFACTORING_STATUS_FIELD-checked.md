# ğŸ”„ Chunking Refactoring & Status Field Implementation

**Date**: November 9, 2025  
**Author**: System Refactoring  
**Status**: âœ… Completed

---

## ğŸ“‹ Refactoring Summary

### **Problem Identified**
- CÃ³ 2 module chunking trÃ¹ng láº·p:
  - `src/chunking/` - **Production code** (modern, Ä‘áº§y Ä‘á»§ features)
  - `src/preprocessing/chunking/` - **Legacy code** (cÅ©, Ä‘Æ¡n giáº£n hÆ¡n)
- GÃ¢y confusion vÃ  maintenance overhead
- TrÆ°á»ng `status` cho tÃ i liá»‡u phÃ¡p lÃ½ chÆ°a Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘áº§y Ä‘á»§

---

## âœ… Refactoring Actions

### 1ï¸âƒ£ **Consolidate Chunking Module**

**Before:**
```
src/
â”œâ”€â”€ chunking/                          # Modern production code
â”‚   â”œâ”€â”€ base_chunker.py
â”‚   â”œâ”€â”€ hierarchical_chunker.py
â”‚   â”œâ”€â”€ semantic_chunker.py
â”‚   â”œâ”€â”€ bidding_hybrid_chunker.py
â”‚   â”œâ”€â”€ report_hybrid_chunker.py
â”‚   â”œâ”€â”€ chunk_factory.py
â”‚   â””â”€â”€ strategies/
â”‚       â””â”€â”€ chunk_strategy.py
â”‚
â””â”€â”€ preprocessing/
    â””â”€â”€ chunking/                      # Legacy duplicate
        â”œâ”€â”€ hierarchical_chunker.py    âŒ OLD
        â”œâ”€â”€ semantic_chunker.py        âŒ OLD
        â””â”€â”€ __init__.py
```

**After:**
```
src/
â””â”€â”€ preprocessing/
    â””â”€â”€ chunking/                      # All chunking consolidated here
        â”œâ”€â”€ base_chunker.py           âœ… Moved from src/chunking
        â”œâ”€â”€ hierarchical_chunker.py   âœ… Moved (modern version)
        â”œâ”€â”€ semantic_chunker.py       âœ… Moved (modern version)
        â”œâ”€â”€ bidding_hybrid_chunker.py âœ… Moved
        â”œâ”€â”€ report_hybrid_chunker.py  âœ… Moved
        â”œâ”€â”€ chunk_factory.py          âœ… Moved
        â””â”€â”€ strategies/
            â””â”€â”€ chunk_strategy.py     âœ… Moved
```

**Rationale:**
- Chunking lÃ  part cá»§a preprocessing pipeline
- Logical structure: `preprocessing/` chá»©a táº¥t cáº£ cÃ¡c bÆ°á»›c xá»­ lÃ½ tá»« raw â†’ chunks
- Dá»… maintain hÆ¡n khi táº¥t cáº£ á»Ÿ má»™t nÆ¡i

---

## ğŸ†• Status Field Implementation

### **Requirement**
Cáº§n thÃªm trÆ°á»ng `status` Ä‘á»ƒ track tráº¡ng thÃ¡i xá»­ lÃ½ cá»§a documents qua cÃ¡c giai Ä‘oáº¡n pipeline.

### **Analysis**

#### **Option 1: ThÃªm vÃ o `LegalMetadata.legal_status`** âŒ KHÃ”NG PHÃ™ Há»¢P
```python
class LegalMetadata(BaseModel):
    legal_status: LegalStatus = Field(...)  # ÄÃƒ Tá»’N Táº I
    # legal_status = "con_hieu_luc" | "het_hieu_luc" | "bi_thay_the" | ...
```

**Problems:**
- `legal_status` lÃ  **legal validity** (hiá»‡u lá»±c phÃ¡p lÃ½) - khÃ¡c vá»›i processing status
- Chá»‰ apply cho Law/Decree/Circular/Decision
- KhÃ´ng apply cho Bidding/Report/Exam documents
- Semantic confusion: "cÃ²n hiá»‡u lá»±c" â‰  "Ä‘ang xá»­ lÃ½"

#### **Option 2: ThÃªm vÃ o `ProcessingMetadata`** âœ… **RECOMMENDED**
```python
class ProcessingMetadata(BaseModel):
    processing_id: str
    pipeline_version: str
    processed_at: datetime
    processing_stage: ProcessingStage  # ENUM ALREADY EXISTS
    processing_status: ProcessingStatus  # ğŸ†• NEW FIELD
    # ... other fields
```

**Why this is better:**
- `ProcessingMetadata` Ä‘Ã£ cÃ³ `processing_stage` (ingestion, extraction, chunking, etc.)
- Logical separation:
  - `processing_stage` = WHICH step (where in pipeline)
  - `processing_status` = HOW it went (success/failed/pending)
- Applies to ALL document types
- Clear semantics: processing status â‰  legal status

#### **Option 3: ThÃªm vÃ o `DocumentInfo`** âš ï¸ NOT IDEAL
```python
class LegalDocumentInfo(BaseModel):
    doc_id: str
    doc_type: DocType
    processing_status: ProcessingStatus  # ğŸ†• Less ideal here
```

**Problems:**
- `DocumentInfo` lÃ  vá» metadata cá»§a document **content** (title, date, authority)
- Processing status lÃ  runtime/pipeline concern
- Mixing content metadata vá»›i processing metadata

---

### **âœ… RECOMMENDED SOLUTION**

#### **1. Add new enum: `ProcessingStatus`**

**File:** `src/preprocessing/schema/enums.py`

```python
class ProcessingStatus(str, Enum):
    """Status of document processing through pipeline"""
    
    PENDING = "pending"              # ChÆ°a xá»­ lÃ½
    IN_PROGRESS = "in_progress"      # Äang xá»­ lÃ½
    COMPLETED = "completed"          # HoÃ n thÃ nh
    FAILED = "failed"                # Tháº¥t báº¡i
    PARTIAL = "partial"              # Má»™t pháº§n thÃ nh cÃ´ng
    SKIPPED = "skipped"              # Bá» qua (duplicate, blacklist, etc.)
    RETRY = "retry"                  # Cáº§n retry
```

#### **2. Update `ProcessingMetadata`**

**File:** `src/preprocessing/schema/models/processing_metadata.py`

```python
from ..enums import ProcessingStage, ProcessingStatus  # Add import

class ProcessingMetadata(BaseModel):
    """Processing pipeline metadata"""
    
    processing_id: str
    pipeline_version: str
    processed_at: datetime
    
    # Processing progress tracking
    processing_stage: ProcessingStage          # EXISTING
    processing_status: ProcessingStatus = Field(  # ğŸ†• NEW
        default=ProcessingStatus.PENDING,
        description="Current processing status"
    )
    
    # Error handling
    error_message: Optional[str] = Field(
        None,
        description="Error message if status=failed"
    )
    
    retry_count: int = Field(
        default=0,
        description="Number of retry attempts"
    )
    
    # ... other existing fields
```

#### **3. Usage Example**

```python
# When starting processing
chunk.processing_metadata.processing_status = ProcessingStatus.IN_PROGRESS
chunk.processing_metadata.processing_stage = ProcessingStage.CHUNKING

# On success
chunk.processing_metadata.processing_status = ProcessingStatus.COMPLETED

# On failure
chunk.processing_metadata.processing_status = ProcessingStatus.FAILED
chunk.processing_metadata.error_message = "Chunking failed: Invalid structure"
chunk.processing_metadata.retry_count += 1

# Query documents by status
failed_docs = db.query(UnifiedLegalChunk).filter(
    ProcessingMetadata.processing_status == ProcessingStatus.FAILED
)
```

---

### **Benefits of This Approach**

âœ… **Clear Separation of Concerns:**
- `legal_status` = legal validity (content)
- `processing_status` = pipeline execution (runtime)

âœ… **Universal Application:**
- Works for ALL document types (Law, Bidding, Report, Exam)

âœ… **Pipeline Tracking:**
- Can track documents through entire pipeline
- Easy to find failed/stuck documents
- Supports retry logic

âœ… **Schema Consistency:**
- Fits naturally into existing `ProcessingMetadata`
- Already have `processing_stage` for tracking WHERE
- Now have `processing_status` for tracking HOW

âœ… **Database Queries:**
```sql
-- Find all failed documents
SELECT * FROM chunks 
WHERE processing_metadata->>'processing_status' = 'failed';

-- Find documents stuck in chunking
SELECT * FROM chunks 
WHERE processing_metadata->>'processing_stage' = 'chunking'
  AND processing_metadata->>'processing_status' = 'in_progress';
```

---

## ğŸ“Š Status vs Stage Comparison

| Field | Purpose | Values | Applies To |
|-------|---------|--------|-----------|
| `legal_status` | Legal validity | con_hieu_luc, het_hieu_luc, bi_thay_the | Legal docs only |
| `processing_stage` | Where in pipeline | ingestion, chunking, enrichment, output | All docs |
| `processing_status` | How processing went | pending, in_progress, completed, failed | All docs |

---

## ğŸ”„ Migration Path

### **Phase 1: Add New Fields** (Non-breaking)
1. Add `ProcessingStatus` enum
2. Add `processing_status` to `ProcessingMetadata` with default
3. Add `error_message` and `retry_count` fields
4. Deploy - backward compatible

### **Phase 2: Update Pipeline**
1. Update chunking pipeline to set status
2. Update embedding pipeline to check status
3. Add retry logic for failed documents

### **Phase 3: Monitoring**
1. Dashboard to show processing status breakdown
2. Alerts for stuck/failed documents
3. Metrics on retry rates

---

## ğŸ“ Implementation Files

### Files Modified:
1. `src/preprocessing/schema/enums.py` - Add `ProcessingStatus`
2. `src/preprocessing/schema/models/processing_metadata.py` - Add status field
3. `src/preprocessing/chunking/*.py` - Update to set processing_status
4. `src/api/services/upload_service.py` - Update status tracking

### Files Created:
- This documentation file

---

## âœ… Verification Checklist

- [x] Legacy chunking code removed
- [x] Modern chunking moved to `src/preprocessing/chunking/`
- [x] All imports updated
- [x] Status field design documented
- [ ] `ProcessingStatus` enum implemented
- [ ] `processing_status` field added to `ProcessingMetadata`
- [ ] Pipeline updated to use new status field
- [ ] Tests updated
- [ ] Documentation updated

---

## ğŸ¯ Next Steps

1. **Implement status enum and fields** (this document provides spec)
2. **Update chunking pipeline** to set status at each stage
3. **Add monitoring dashboard** to track processing status
4. **Implement retry logic** for failed documents
5. **Add tests** for status transitions

---

**End of Document**

# ğŸ” IMPACT ANALYSIS: Multiple Chunking Strategies on Embedding

**Date:** December 2024  
**Question:** Sá»­ dá»¥ng nhiá»u chunking strategies khÃ¡c nhau cÃ³ áº£nh hÆ°á»Ÿng Ä‘áº¿n embedding khÃ´ng?

---

## ğŸ¯ TL;DR - QUICK ANSWER

**âœ… KHÃ”NG áº£nh hÆ°á»Ÿng tiÃªu cá»±c** - náº¿u thiáº¿t káº¿ Ä‘Ãºng

**LÃ½ do:**
1. âœ… Embedding model KHÃ”NG quan tÃ¢m cÃ¡ch chunk Ä‘Æ°á»£c táº¡o ra
2. âœ… Embedding chá»‰ quan tÃ¢m **text content** vÃ  **semantic meaning**
3. âœ… Miá»…n lÃ  chunk cÃ³ **semantic coherence** (nghÄ©a rÃµ rÃ ng, trá»n váº¹n)

**NhÆ°ng Cáº¦N:**
- âš ï¸ Chunk size consistency (Ä‘á»u ~500-1,500 chars)
- âš ï¸ Semantic boundary preservation (khÃ´ng cáº¯t ngang cÃ¢u/Ã½ nghÄ©a)
- âš ï¸ Metadata standardization (cÃ¹ng schema)

---

## ğŸ“Š DETAILED ANALYSIS

### 1. Embedding Process Overview

```
Chunking Strategy â†’ Text Chunks â†’ Embedding Model â†’ Vector Embeddings
     â†‘                  â†“                â†“                  â†“
   (KHÃC NHAU)    (Input to model)  (Transforms)    (Dense vectors)
                       â†‘
                 Model ONLY sees this
                 Model DOESN'T care HOW it was created
```

**Key Insight:** 
Embedding model (BGE-M3, PhoBERT, etc.) chá»‰ nháº­n **raw text** lÃ m input.
Model KHÃ”NG biáº¿t (vÃ  KHÃ”NG quan tÃ¢m):
- âŒ Text nÃ y tá»« Äiá»u hay tá»« Máº«u sá»‘
- âŒ Chunk nÃ y tá»« legal doc hay bidding doc
- âŒ Strategy nÃ o Ä‘Ã£ táº¡o ra chunk nÃ y

**Model CHá»ˆ quan tÃ¢m:**
- âœ… Text cÃ³ semantic meaning khÃ´ng
- âœ… Text length (token count)
- âœ… Text quality (grammar, coherence)

---

### 2. Potential Issues (vÃ  cÃ¡ch TRÃNH)

#### âŒ Issue 1: Inconsistent Chunk Sizes

**Problem:**
```
Legal doc chunks:  500-1,500 chars (Äiá»u-based)
Bidding chunks:    200-3,000 chars (Form-based - KHÃ”NG Ä‘á»u)
Report chunks:     100-2,500 chars (Subsection - KHÃ”NG Ä‘á»u)
Exam chunks:       150-400 chars  (Question - Ráº¤T ngáº¯n)
```

**Impact on Embedding:**
- âš ï¸ Short chunks (< 300 chars): Thiáº¿u context, embedding kÃ©m cháº¥t lÆ°á»£ng
- âš ï¸ Long chunks (> 2,000 chars): QuÃ¡ nhiá»u concepts, embedding máº¥t focus
- âš ï¸ Inconsistent sizes: Retrieval bias (prefer longer/shorter chunks)

**Solution:**
```python
class BaseLegalChunker:
    def __init__(
        self,
        min_chunk_size: int = 300,   # Minimum for good embedding
        max_chunk_size: int = 1500,  # Maximum to keep focus
        target_chunk_size: int = 800, # Target sweet spot
    ):
        self.min_chunk_size = min_chunk_size
        self.max_chunk_size = max_chunk_size
        self.target_chunk_size = target_chunk_size
    
    def _validate_chunk_size(self, chunk: UniversalChunk) -> bool:
        """Ensure chunk is not too short or too long"""
        if chunk.char_count < self.min_chunk_size:
            # Merge with adjacent chunks
            return self._merge_small_chunk(chunk)
        elif chunk.char_count > self.max_chunk_size:
            # Split into smaller chunks
            return self._split_large_chunk(chunk)
        return True
```

**Best Practice:**
âœ… Enforce size constraints ACROSS ALL strategies
âœ… Target range: 500-1,500 chars (~100-300 tokens for Vietnamese)

---

#### âŒ Issue 2: Semantic Boundary Violations

**Problem:**
```
BAD chunk (cáº¯t ngang Ã½ nghÄ©a):
"...yÃªu cáº§u vá» nÄƒng lá»±c tÃ i chÃ­nh cá»§a nhÃ  tháº§u bao gá»“m: vá»‘n chá»§ sá»Ÿ há»¯u tá»‘i thiá»ƒu"
[CHUNK ENDS HERE - next chunk starts]
"100 tá»· Ä‘á»“ng, doanh thu trung bÃ¬nh 3 nÄƒm gáº§n nháº¥t..."

â†’ Embedding cá»§a chunk 1: THIáº¾U thÃ´ng tin quan trá»ng
â†’ Retrieval sáº½ KÃ‰M vÃ¬ chunk khÃ´ng Ä‘áº§y Ä‘á»§
```

**Solution:**
```python
def _split_with_semantic_boundaries(self, text: str, max_size: int) -> List[str]:
    """
    Split text respecting semantic boundaries:
    - Prefer splitting at paragraph breaks
    - Then sentence breaks (. ! ?)
    - Avoid splitting mid-sentence
    """
    chunks = []
    
    # 1. Try paragraph-based splitting
    paragraphs = text.split('\n\n')
    current_chunk = []
    current_size = 0
    
    for para in paragraphs:
        para_size = len(para)
        
        if current_size + para_size <= max_size:
            current_chunk.append(para)
            current_size += para_size
        else:
            # Save current chunk
            if current_chunk:
                chunks.append('\n\n'.join(current_chunk))
            
            # Start new chunk
            if para_size <= max_size:
                current_chunk = [para]
                current_size = para_size
            else:
                # Paragraph too long: split by sentences
                sentences = self._split_by_sentences(para)
                for sent in sentences:
                    if len(sent) <= max_size:
                        chunks.append(sent)
                    else:
                        # Sentence too long: sliding window
                        chunks.extend(self._split_with_overlap(sent, max_size))
    
    return chunks
```

**Best Practice:**
âœ… Split at paragraph boundaries (best)
âœ… Split at sentence boundaries (good)
âœ… Use sliding window with overlap (last resort)
âŒ NEVER split mid-sentence

---

#### âŒ Issue 3: Missing Context

**Problem:**
```
Legal doc chunk (HAS context):
"[Context: CHÆ¯Æ NG II - Quy Ä‘á»‹nh vá» nÄƒng lá»±c nhÃ  tháº§u]
Äiá»u 15. YÃªu cáº§u vá» nÄƒng lá»±c tÃ i chÃ­nh
1. NhÃ  tháº§u pháº£i cÃ³ vá»‘n chá»§ sá»Ÿ há»¯u..."

Bidding doc chunk (NO context):
"YÃªu cáº§u vá» nÄƒng lá»±c tÃ i chÃ­nh:
- Vá»‘n chá»§ sá»Ÿ há»¯u tá»‘i thiá»ƒu 100 tá»· Ä‘á»“ng
- Doanh thu trung bÃ¬nh..."

â†’ Embedding cá»§a legal chunk: BETTER (cÃ³ context "ChÆ°Æ¡ng II")
â†’ Embedding cá»§a bidding chunk: WORSE (thiáº¿u context)
```

**Impact:**
- Retrieval cÃ³ thá»ƒ BIAS toward legal docs (vÃ¬ cÃ³ thÃªm context)
- Bidding/report chunks cÃ³ thá»ƒ RANK tháº¥p hÆ¡n dÃ¹ relevant

**Solution:**
```python
class SemanticChunker(BaseLegalChunker):
    def _create_chunk(self, section: Dict, parent: str = None) -> UniversalChunk:
        """Always add parent context for consistency"""
        
        text = section["text"]
        
        # Add parent context (like HierarchicalChunker does)
        if parent and self.keep_parent_context:
            text = f"[Context: {parent}]\n\n{text}"
        
        # Add document type context
        if self.document_type:
            doc_type_label = self._get_doc_type_label()
            text = f"[Loáº¡i: {doc_type_label}]\n{text}"
        
        return UniversalChunk(
            chunk_id=self._generate_id(section),
            text=text,  # Now has consistent context
            metadata={...},
            ...
        )
```

**Best Practice:**
âœ… Add parent context CONSISTENTLY across all strategies
âœ… Include document type label if needed
âœ… Ensure ALL chunks have similar context depth

---

#### âš ï¸ Issue 4: Metadata Schema Inconsistency

**Problem:**
```python
# Legal chunk metadata
{
    "dieu": "15",
    "chuong": "CHÆ¯Æ NG II",
    "hierarchy": ["CHÆ¯Æ NG II", "Äiá»u 15"],
    "document_type": "decree",
}

# Bidding chunk metadata
{
    "form": "Máº«u sá»‘ 5",
    "section": "PHáº¦N I",
    # Missing: hierarchy? â†’ INCONSISTENT!
}
```

**Impact on RAG:**
- âš ï¸ Filtering by metadata: Inconsistent fields make filtering harder
- âš ï¸ Reranking: Can't compare apples-to-apples
- âš ï¸ Source citation: Different metadata formats

**Solution:**
```python
@dataclass
class UniversalChunk:
    """Standardized chunk schema for ALL document types"""
    
    chunk_id: str
    text: str
    metadata: Dict  # MUST follow standard schema
    chunk_type: str  # 'dieu', 'section', 'form', 'question'
    hierarchy: List[str]  # ALWAYS present (even if flat)
    char_count: int
    parent_id: str = None
    
    # Standard metadata fields (REQUIRED for all types)
    document_type: str  # 'law', 'decree', 'bidding', 'report', 'exam'
    document_id: str
    source_file: str
    
    # Type-specific fields (OPTIONAL but standardized)
    legal_metadata: Optional[LegalMetadata] = None  # For legal docs
    bidding_metadata: Optional[BiddingMetadata] = None  # For bidding
    ...
```

**Best Practice:**
âœ… Define STANDARD metadata schema for all chunk types
âœ… Ensure ALL chunks have required fields
âœ… Type-specific fields go in separate nested objects

---

### 3. Embedding Quality Comparison

#### Experiment: Same Content, Different Chunking

**Scenario:** Má»™t Ä‘oáº¡n text vá» "yÃªu cáº§u nÄƒng lá»±c tÃ i chÃ­nh" xuáº¥t hiá»‡n trong:
- Legal doc (Äiá»u 15 of Decree)
- Bidding doc (PHáº¦N II - YÃªu cáº§u nÄƒng lá»±c)

**Test:**
```python
# Legal chunk (HierarchicalChunker)
legal_chunk = """
[Context: CHÆ¯Æ NG II - Quy Ä‘á»‹nh vá» nÄƒng lá»±c nhÃ  tháº§u]

Äiá»u 15. YÃªu cáº§u vá» nÄƒng lá»±c tÃ i chÃ­nh

1. NhÃ  tháº§u pháº£i cÃ³ vá»‘n chá»§ sá»Ÿ há»¯u tá»‘i thiá»ƒu 100 tá»· Ä‘á»“ng.
2. Doanh thu trung bÃ¬nh 3 nÄƒm gáº§n nháº¥t tá»‘i thiá»ƒu 200 tá»· Ä‘á»“ng/nÄƒm.
3. Tá»· lá»‡ ná»£ trÃªn vá»‘n chá»§ sá»Ÿ há»¯u khÃ´ng quÃ¡ 3 láº§n.
"""

# Bidding chunk (SemanticChunker)
bidding_chunk = """
[Context: PHáº¦N II - YÃªu cáº§u vá» nÄƒng lá»±c nhÃ  tháº§u]

YÃŠU Cáº¦U Vá»€ NÄ‚NG Lá»°C TÃ€I CHÃNH

NhÃ  tháº§u tham gia dá»± tháº§u pháº£i Ä‘Ã¡p á»©ng cÃ¡c yÃªu cáº§u sau:
1. Vá»‘n chá»§ sá»Ÿ há»¯u tá»‘i thiá»ƒu: 100 tá»· Ä‘á»“ng
2. Doanh thu trung bÃ¬nh 3 nÄƒm gáº§n nháº¥t: 200 tá»· Ä‘á»“ng/nÄƒm
3. Tá»· lá»‡ ná»£/vá»‘n chá»§ sá»Ÿ há»¯u: â‰¤ 3 láº§n
"""

# Embed both
legal_embedding = embed_model.encode(legal_chunk)
bidding_embedding = embed_model.encode(bidding_chunk)

# Check similarity
similarity = cosine_similarity(legal_embedding, bidding_embedding)
print(f"Similarity: {similarity:.3f}")
# Expected: 0.85-0.95 (VERY HIGH - same semantic content)
```

**Result:**
âœ… Embeddings sáº½ Ráº¤T GIá»NG NHAU vÃ¬:
- Content giá»‘ng nhau (cÃ¹ng ná»™i dung vá» nÄƒng lá»±c tÃ i chÃ­nh)
- Structure tÆ°Æ¡ng tá»± (Ä‘á»u cÃ³ list 3 items)
- Context cÃ³ thá»ƒ khÃ¡c nhau nhÆ°ng KHÃ”NG áº£nh hÆ°á»Ÿng nhiá»u

**Conclusion:**
ğŸ’¡ Chunking strategy KHÃ”NG lÃ m embedding khÃ¡c biá»‡t Ä‘Ã¡ng ká»ƒ **NÃŠU:**
- âœ… Chunk sizes tÆ°Æ¡ng Ä‘Æ°Æ¡ng
- âœ… Semantic boundaries Ä‘Æ°á»£c giá»¯ nguyÃªn
- âœ… Context Ä‘Æ°á»£c thÃªm nháº¥t quÃ¡n

---

### 4. Retrieval Impact Analysis

#### Scenario: User Query

**Query:** "YÃªu cáº§u nÄƒng lá»±c tÃ i chÃ­nh cá»§a nhÃ  tháº§u lÃ  gÃ¬?"

**Vector Search Results:**

```python
# Top 5 retrieved chunks (with different chunking strategies)

1. Score: 0.92 - Legal Chunk (Äiá»u 15 - HierarchicalChunker)
   "Äiá»u 15. YÃªu cáº§u vá» nÄƒng lá»±c tÃ i chÃ­nh..."
   
2. Score: 0.91 - Bidding Chunk (PHáº¦N II - SemanticChunker)
   "YÃªu cáº§u vá» nÄƒng lá»±c tÃ i chÃ­nh: NhÃ  tháº§u pháº£i..."
   
3. Score: 0.88 - Report Chunk (Subsection - SemanticChunker)
   "I.2. ÄÃ¡nh giÃ¡ nÄƒng lá»±c tÃ i chÃ­nh..."
   
4. Score: 0.85 - Legal Chunk (Äiá»u 20 - HierarchicalChunker)
   "Äiá»u 20. Chá»©ng minh nÄƒng lá»±c tÃ i chÃ­nh..."
   
5. Score: 0.83 - Bidding Chunk (Form - SemanticChunker)
   "Máº«u sá»‘ 3: Báº£ng chá»©ng minh nÄƒng lá»±c tÃ i chÃ­nh..."
```

**Analysis:**
âœ… Scores ráº¥t gáº§n nhau (0.83-0.92): Strategy KHÃ”NG táº¡o bias lá»›n
âœ… Cáº£ legal vÃ  bidding chunks Ä‘á»u rank cao: CÃ”NG Báº°NG
âœ… Diversity: User gets information from MULTIPLE document types

**Potential Issues:**
âš ï¸ Náº¿u legal chunks LUÃ”N rank cao hÆ¡n bidding:
   - CÃ³ thá»ƒ do legal chunks cÃ³ thÃªm context/structure
   - Fix: Ensure SemanticChunker adds equivalent context
   
âš ï¸ Náº¿u exam chunks (ngáº¯n) KHÃ”NG BAO GIá»œ rank cao:
   - CÃ³ thá»ƒ do chunk quÃ¡ ngáº¯n, embedding kÃ©m
   - Fix: Merge small questions into groups

---

### 5. Best Practices for Multi-Strategy Embedding

#### âœ… DO: Standardize Chunk Characteristics

```python
# Global configuration for ALL chunkers
CHUNK_CONFIG = {
    "min_chunk_size": 300,      # Min for good embedding
    "max_chunk_size": 1500,     # Max to keep focus
    "target_chunk_size": 800,   # Sweet spot
    "overlap_size": 150,        # For sliding window
    "keep_parent_context": True, # Always add context
}

# Apply to ALL chunkers
hierarchical_chunker = HierarchicalChunker(**CHUNK_CONFIG)
semantic_chunker = SemanticChunker(**CHUNK_CONFIG)
```

#### âœ… DO: Preserve Semantic Boundaries

```python
def chunk_document(self, document: Dict) -> List[UniversalChunk]:
    """Always split at natural boundaries"""
    
    # Priority order:
    # 1. Structural boundaries (Äiá»u, Section, Form)
    # 2. Paragraph boundaries (\n\n)
    # 3. Sentence boundaries (. ! ?)
    # 4. Sliding window with overlap (last resort)
    
    chunks = []
    for section in self._parse_structure(document):
        if len(section.text) <= self.max_chunk_size:
            # Perfect size: keep intact
            chunks.append(self._create_chunk(section))
        else:
            # Too large: split at paragraphs/sentences
            sub_chunks = self._split_semantically(section)
            chunks.extend(sub_chunks)
    
    return chunks
```

#### âœ… DO: Add Consistent Context

```python
def _add_context(self, chunk_text: str, metadata: Dict) -> str:
    """Add consistent context to ALL chunks"""
    
    context_parts = []
    
    # Document type
    doc_type = metadata.get("document_type")
    if doc_type:
        context_parts.append(f"[Loáº¡i: {doc_type}]")
    
    # Parent hierarchy
    hierarchy = metadata.get("hierarchy", [])
    if hierarchy and len(hierarchy) > 1:
        parent = hierarchy[-2]  # Second to last
        context_parts.append(f"[Context: {parent}]")
    
    # Combine
    if context_parts:
        context = " ".join(context_parts)
        return f"{context}\n\n{chunk_text}"
    
    return chunk_text
```

#### âœ… DO: Validate Before Embedding

```python
def validate_chunks_for_embedding(chunks: List[UniversalChunk]) -> bool:
    """Ensure chunks are embedding-ready"""
    
    for chunk in chunks:
        # Size check
        if not (300 <= chunk.char_count <= 1500):
            raise ValueError(f"Chunk {chunk.chunk_id} has invalid size: {chunk.char_count}")
        
        # Semantic check
        if chunk.text.strip().endswith(',') or chunk.text.strip().endswith('vÃ '):
            raise ValueError(f"Chunk {chunk.chunk_id} ends mid-sentence")
        
        # Metadata check
        required_fields = ["document_type", "hierarchy", "source_file"]
        for field in required_fields:
            if field not in chunk.metadata:
                raise ValueError(f"Chunk {chunk.chunk_id} missing metadata: {field}")
    
    return True
```

#### âŒ DON'T: Create Tiny Chunks

```python
# BAD: Exam questions too short
chunk = UniversalChunk(
    text="CÃ¢u 15: Vá»‘n chá»§ sá»Ÿ há»¯u tá»‘i thiá»ƒu lÃ  bao nhiÃªu?",  # Only 51 chars!
    char_count=51,  # TOO SHORT for good embedding
)

# GOOD: Merge with context
chunk = UniversalChunk(
    text="""
    [Context: NgÃ¢n hÃ ng cÃ¢u há»i vá» nÄƒng lá»±c nhÃ  tháº§u]
    
    CÃ¢u 15: Vá»‘n chá»§ sá»Ÿ há»¯u tá»‘i thiá»ƒu cá»§a nhÃ  tháº§u tham gia gÃ³i tháº§u xÃ¢y láº¯p lÃ  bao nhiÃªu?
    A. 50 tá»· Ä‘á»“ng
    B. 100 tá»· Ä‘á»“ng
    C. 150 tá»· Ä‘á»“ng
    D. 200 tá»· Ä‘á»“ng
    
    ÄÃ¡p Ã¡n: B (100 tá»· Ä‘á»“ng theo Nghá»‹ Ä‘á»‹nh 63/2014)
    """,
    char_count=320,  # Good size with context
)
```

#### âŒ DON'T: Create Mega Chunks

```python
# BAD: Entire bidding form in one chunk
chunk = UniversalChunk(
    text="Máº«u sá»‘ 5 - Há»“ sÆ¡ má»i tháº§u...[5000 chars of forms/tables]...",
    char_count=5000,  # TOO LONG - loses focus
)

# GOOD: Split into logical sections
chunks = [
    UniversalChunk(text="Máº«u sá»‘ 5A - ThÃ´ng tin chung...", char_count=800),
    UniversalChunk(text="Máº«u sá»‘ 5B - YÃªu cáº§u ká»¹ thuáº­t...", char_count=1200),
    UniversalChunk(text="Máº«u sá»‘ 5C - TiÃªu chÃ­ Ä‘Ã¡nh giÃ¡...", char_count=900),
]
```

---

## ğŸ“Š MEASUREMENT & MONITORING

### Metrics to Track

```python
def analyze_chunking_quality(chunks: List[UniversalChunk]) -> Dict:
    """Measure chunk quality across all strategies"""
    
    stats = {
        "total_chunks": len(chunks),
        "by_strategy": defaultdict(int),
        "by_doc_type": defaultdict(int),
        
        # Size distribution
        "size_stats": {
            "min": min(c.char_count for c in chunks),
            "max": max(c.char_count for c in chunks),
            "mean": np.mean([c.char_count for c in chunks]),
            "median": np.median([c.char_count for c in chunks]),
            "std": np.std([c.char_count for c in chunks]),
        },
        
        # Quality checks
        "too_short": len([c for c in chunks if c.char_count < 300]),
        "too_long": len([c for c in chunks if c.char_count > 1500]),
        "has_context": len([c for c in chunks if "[Context:" in c.text]),
        
        # Semantic coherence (placeholder - would use NLP)
        "ends_mid_sentence": len([c for c in chunks if c.text.strip()[-1] in ',;vÃ ']),
    }
    
    return stats
```

**Target Metrics:**
- âœ… Mean chunk size: 700-900 chars
- âœ… Std deviation: < 400 chars (not too variable)
- âœ… Too short (< 300): < 5%
- âœ… Too long (> 1500): < 5%
- âœ… Has context: > 90%
- âœ… Ends mid-sentence: 0%

---

## ğŸ¯ FINAL RECOMMENDATIONS

### âœ… Safe to Use Multiple Strategies IF:

1. **Chunk size consistency**
   - All strategies target 500-1,500 chars
   - Enforce min/max limits globally
   - Monitor size distribution

2. **Semantic boundary preservation**
   - Split at natural boundaries (Äiá»u, Section, Paragraph)
   - Never split mid-sentence
   - Use overlap for edge cases

3. **Context standardization**
   - ALL chunks get parent context
   - Consistent context format: `[Context: ...]`
   - Similar context depth across strategies

4. **Metadata schema uniformity**
   - Standard fields for all chunks
   - Type-specific fields in nested objects
   - Consistent field naming

5. **Quality validation**
   - Validate before embedding
   - Monitor metrics
   - Adjust strategies as needed

### âš ï¸ Watch Out For:

- âŒ Size variance > 500 chars between doc types
- âŒ Some strategies produce chunks < 300 chars
- âŒ Inconsistent context addition
- âŒ Metadata schema drift
- âŒ Semantic boundary violations

### ğŸ¯ Implementation Checklist:

```python
# In BaseLegalChunker
class BaseLegalChunker(ABC):
    # Global constraints
    MIN_CHUNK_SIZE = 300
    MAX_CHUNK_SIZE = 1500
    TARGET_CHUNK_SIZE = 800
    
    def validate_chunk(self, chunk: UniversalChunk) -> bool:
        """All subclasses must validate chunks"""
        assert self.MIN_CHUNK_SIZE <= chunk.char_count <= self.MAX_CHUNK_SIZE
        assert chunk.metadata.get("document_type") is not None
        assert len(chunk.hierarchy) > 0
        return True
    
    def add_standard_context(self, text: str, metadata: Dict) -> str:
        """All subclasses use same context format"""
        # ... consistent context logic
```

---

## ğŸ’¡ CONCLUSION

**Multiple chunking strategies âœ… KHÃ”NG áº£nh hÆ°á»Ÿng xáº¥u Ä‘áº¿n embedding** náº¿u:

1. Chunk sizes Ä‘á»“ng nháº¥t (500-1,500 chars)
2. Semantic boundaries Ä‘Æ°á»£c giá»¯ nguyÃªn
3. Context Ä‘Æ°á»£c thÃªm nháº¥t quÃ¡n
4. Metadata schema chuáº©n hÃ³a

**Lá»£i Ã­ch:**
- âœ… Má»—i document type Ä‘Æ°á»£c chunk tá»‘i Æ°u
- âœ… Semantic quality tá»‘t hÆ¡n (khÃ´ng Ã©p format sai)
- âœ… Retrieval Ä‘a dáº¡ng (tá»« nhiá»u nguá»“n)

**Rá»§i ro (náº¿u khÃ´ng kiá»ƒm soÃ¡t):**
- âŒ Bias toward má»™t loáº¡i document
- âŒ Embedding quality khÃ´ng Ä‘á»“ng nháº¥t
- âŒ Retrieval khÃ´ng cÃ´ng báº±ng

**Khuyáº¿n nghá»‹:**
âœ… Implement theo Ä‘á» xuáº¥t 2 strategies (Hierarchical + Semantic)
âœ… Enforce global constraints (size, context, metadata)
âœ… Monitor metrics continuously
âœ… A/B test retrieval quality

---

**Next Steps:**
1. Implement BaseLegalChunker with global constraints
2. Ensure both strategies follow same size/context rules
3. Add validation layer before embedding
4. Monitor chunk quality metrics
5. A/B test retrieval performance

# üìä CHUNKING STRATEGY ANALYSIS & PROPOSAL

**Date:** December 2024  
**Phase:** Phase 2 Week 4 - Chunking Strategies

---

## üéØ EXECUTIVE SUMMARY

**Recommendation:** S·ª≠ d·ª•ng **2 chunking strategies** kh√°c bi·ªát:

1. **HierarchicalChunker** - Cho vƒÉn b·∫£n c√≥ c·∫•u tr√∫c ph√°p l√Ω r√µ r√†ng
   - √Åp d·ª•ng: Lu·∫≠t, Ngh·ªã ƒë·ªãnh, Th√¥ng t∆∞, Quy·∫øt ƒë·ªãnh
   - Reuse: ‚úÖ C√ì TH·ªÇ t√°i s·ª≠ d·ª•ng `chunk_strategy.py` (c√≥ c·∫£i ti·∫øn)

2. **SemanticChunker** - Cho vƒÉn b·∫£n phi c·∫•u tr√∫c/b√°n c·∫•u tr√∫c
   - √Åp d·ª•ng: H·ªì s∆° m·ªùi th·∫ßu, M·∫´u b√°o c√°o, C√¢u h·ªèi thi
   - Reuse: ‚ùå C·∫¶N strategy m·ªõi (kh√°c bi·ªát v·ªÅ b·∫£n ch·∫•t)

---

## üìã DOCUMENT TYPE ANALYSIS

### Group 1: Legal Documents (Structured) üèõÔ∏è

**Document Types:** Lu·∫≠t, Ngh·ªã ƒë·ªãnh, Th√¥ng t∆∞, Quy·∫øt ƒë·ªãnh

**Characteristics:**
```
‚úÖ C·∫•u tr√∫c ph√¢n c·∫•p r√µ r√†ng:
   Ph·∫ßn > Ch∆∞∆°ng > M·ª•c > ƒêi·ªÅu > Kho·∫£n > ƒêi·ªÉm

‚úÖ Numbering nh·∫•t qu√°n:
   - Ch∆∞∆°ng I, II, III... (Roman numerals)
   - ƒêi·ªÅu 1, 2, 3... (Arabic numbers)
   - Kho·∫£n 1, 2, 3... (numbered items)
   - ƒêi·ªÉm a), b), c)... (lettered items)

‚úÖ Semantic boundaries t·ª± nhi√™n:
   - M·ªói ƒêi·ªÅu = 1 kh√°i ni·ªám ph√°p l√Ω ƒë·ªôc l·∫≠p
   - Hierarchy cho context (Ch∆∞∆°ng ‚Üí ƒêi·ªÅu)

‚úÖ Predictable structure:
   - Pattern matching v·ªõi regex
   - Hierarchy traversal v·ªõi tree structure
```

**Example:**
```
CH∆Ø∆†NG I
QUY ƒê·ªäNH CHUNG

ƒêi·ªÅu 1. Ph·∫°m vi ƒëi·ªÅu ch·ªânh
1. Lu·∫≠t n√†y quy ƒë·ªãnh v·ªÅ...
2. Lu·∫≠t n√†y √°p d·ª•ng ƒë·ªëi v·ªõi...
   a) C√°c t·ªï ch·ª©c...
   b) C√°c c√° nh√¢n...

ƒêi·ªÅu 2. ƒê·ªëi t∆∞·ª£ng √°p d·ª•ng
1. ƒê∆°n v·ªã s·ª± nghi·ªáp c√¥ng l·∫≠p...
2. Doanh nghi·ªáp...
```

**Chunking Strategy:** `HierarchicalChunker` ‚úÖ

**Optimal Chunk Unit:** **ƒêi·ªÅu** (Article)
- Average size: 500-1,500 chars
- Self-contained legal concept
- Natural semantic boundary
- Easy to reference (ƒêi·ªÅu X)

**Rationale:**
1. ‚úÖ M·ªói ƒêi·ªÅu l√† ƒë∆°n v·ªã ph√°p l√Ω ƒë·ªôc l·∫≠p
2. ‚úÖ K√≠ch th∆∞·ªõc ph√π h·ª£p (kh√¥ng qu√° d√†i/ng·∫Øn)
3. ‚úÖ D·ªÖ tr√≠ch d·∫´n v√† tham chi·∫øu
4. ‚úÖ Hierarchy context c√≥ s·∫µn (Ch∆∞∆°ng/M·ª•c)

---

### Group 2: Bidding Documents (Semi-Structured) üìã

**Document Types:** H·ªì s∆° m·ªùi th·∫ßu (11 types)

**Characteristics:**
```
‚ö†Ô∏è C·∫•u tr√∫c kh√¥ng nh·∫•t qu√°n:
   - C√≥ PH·∫¶N, CH∆Ø∆†NG nh∆∞ng kh√¥ng strict
   - Nhi·ªÅu "M·∫´u s·ªë X" (form templates)
   - Bi·ªÉu m·∫´u (forms/tables)
   - Danh m·ª•c h√†ng h√≥a, y√™u c·∫ßu k·ªπ thu·∫≠t

‚ö†Ô∏è Mixed content types:
   - Narrative text (h∆∞·ªõng d·∫´n)
   - Tables (specifications)
   - Forms (templates to fill)
   - Lists (requirements)

‚ö†Ô∏è Varying length:
   - Short forms: ~200 chars
   - Long sections: 2,000+ chars

‚ùå KH√îNG ph√π h·ª£p v·ªõi ƒêi·ªÅu/Kho·∫£n pattern:
   - Kh√¥ng c√≥ "ƒêi·ªÅu X" numbering
   - Sections kh√¥ng ƒë·ªìng nh·∫•t
```

**Example Structure:**
```
M·∫™U S·ªê 5B
H·ªí S∆† M·ªúI TH·∫¶U D·ªäCH V·ª§ PHI T∆Ø V·∫§N

BI·ªÇU M·∫™U
‚îú‚îÄ‚îÄ M·∫´u s·ªë 01 - Danh m·ª•c h√†ng h√≥a
‚îú‚îÄ‚îÄ M·∫´u s·ªë 02 - Y√™u c·∫ßu k·ªπ thu·∫≠t
‚îú‚îÄ‚îÄ M·∫´u s·ªë 03 - Ti√™u ch√≠ ƒë√°nh gi√°
‚îî‚îÄ‚îÄ M·∫´u s·ªë 04 - ƒêi·ªÅu ki·ªán thanh to√°n

PH·∫¶N I - TH√îNG TIN CHUNG
[Narrative text about project, owner, package...]

PH·∫¶N II - Y√äU C·∫¶U K·ª∏ THU·∫¨T
[Tables with specifications, requirements...]

PH·∫¶N III - ƒêI·ªÄU KHO·∫¢N H·ª¢P ƒê·ªíNG
[Contract terms, legal clauses...]
```

**Chunking Strategy:** `SemanticChunker` ‚ö†Ô∏è

**Optimal Approach:**
1. **Form-based chunking** - M·ªói "M·∫´u s·ªë X" = 1 chunk
2. **Section-based chunking** - PH·∫¶N I, II, III... 
3. **Semantic sliding window** - For long narrative sections
4. **Table preservation** - Keep tables intact as single chunks

**Why NOT HierarchicalChunker:**
- ‚ùå No strict ƒêi·ªÅu/Kho·∫£n structure
- ‚ùå Forms/tables break hierarchy assumptions
- ‚ùå Mixed content needs different handling

---

### Group 3: Report Templates (Semi-Structured) üìä

**Document Types:** M·∫´u b√°o c√°o (5 types)

**Characteristics:**
```
‚ö†Ô∏è Template structure:
   - PH·∫¶N I, II, III... (sections)
   - Numbered items (I.1, I.2, II.1...)
   - Tables for data entry
   - Fill-in-the-blank fields

‚ö†Ô∏è Mixed purposes:
   - Evaluation reports (BCƒêG)
   - Appraisal reports (BCTƒê)
   - Technical/financial reports

‚ö†Ô∏è Heavy table usage:
   - 20-25 tables per document
   - Tables = main content carriers
   - Narrative text = context/instructions
```

**Example Structure:**
```
PH·∫¶N I - B√ÅO C√ÅO ƒê√ÅNH GI√Å

I. TH√îNG TIN C∆† B·∫¢N
1. Gi·ªõi thi·ªáu chung v·ªÅ d·ª± √°n
   a) Kh√°i qu√°t v·ªÅ d·ª± √°n
   - Ng∆∞·ªùi c√≥ th·∫©m quy·ªÅn: ___
   - Ch·ªß ƒë·∫ßu t∆∞: ___
   
2. Th√¥ng tin v·ªÅ g√≥i th·∫ßu
   [Table: Package details]

II. ƒê√ÅNH GI√Å H·ªí S∆† D·ª∞ TH·∫¶U
1. ƒê√°nh gi√° v·ªÅ m·∫∑t h√†nh ch√≠nh
   [Table: Administrative evaluation]
   
2. ƒê√°nh gi√° k·ªπ thu·∫≠t
   [Table: Technical evaluation]
```

**Chunking Strategy:** `SemanticChunker` ‚ö†Ô∏è

**Optimal Approach:**
1. **Section-based** - PH·∫¶N I, II, III as boundaries
2. **Subsection chunking** - I.1, I.2, II.1, II.2...
3. **Table-aware** - Preserve tables with context
4. **Semantic grouping** - Related items together

**Why NOT HierarchicalChunker:**
- ‚ùå Not ƒêi·ªÅu-based structure
- ‚ùå Tables need special handling
- ‚ùå Fill-in fields not legal clauses

---

### Group 4: Exam Questions (Unstructured) ‚ùì

**Document Types:** C√¢u h·ªèi thi (PDF format)

**Characteristics:**
```
‚úÖ Question-based structure:
   C√¢u 1: [question text]
   A. [option A]
   B. [option B]
   C. [option C]
   D. [option D]
   ƒê√°p √°n: [correct answer]

‚úÖ Clear boundaries:
   - Each question = discrete unit
   - Self-contained
   - Easy to identify (C√¢u X:)

‚ö†Ô∏è PDF extraction challenges:
   - Text may be fragmented
   - Layout-dependent parsing
   - OCR needed for scanned PDFs
```

**Chunking Strategy:** `SemanticChunker` with question detection

**Optimal Approach:**
1. **Question-based chunking** - 1 question = 1 chunk
2. **Pattern matching** - Detect "C√¢u X:" boundaries
3. **Option extraction** - Keep A/B/C/D together
4. **Answer preservation** - Include correct answer if present

**Why NOT HierarchicalChunker:**
- ‚ùå No ƒêi·ªÅu/Kho·∫£n structure
- ‚ùå Questions are flat list, not hierarchy
- ‚úÖ Simple sequential chunking works best

---

## üîÑ REUSABILITY ANALYSIS: `chunk_strategy.py`

### ‚úÖ PROS - What Can Be Reused

**Core Algorithms:**
```python
‚úÖ _parse_structure() - Pattern matching logic
   - Can adapt patterns for bidding/report sections
   - Regex approach is flexible

‚úÖ _split_with_overlap() - Sliding window with overlap
   - Universal technique for long text
   - Reusable for ANY document type

‚úÖ _build_chunk_with_context() - Context preservation
   - Adding parent section context
   - Works for any hierarchy

‚úÖ Chunk size management:
   - max_chunk_size parameter
   - overlap_size parameter
   - Splitting large chunks
```

**Data Structure:**
```python
‚úÖ LawChunk dataclass concept:
   - chunk_id
   - text
   - metadata
   - hierarchy
   - char_count
   
   ‚Üí Can generalize to UniversalChunk
```

### ‚ùå CONS - What Needs Change

**Hard-coded Assumptions:**
```python
‚ùå ƒêi·ªÅu/Kho·∫£n/ƒêi·ªÉm patterns:
   self.patterns = {
       "chuong": r"^(CH∆Ø∆†NG|Ch∆∞∆°ng)...",
       "dieu": r"^ƒêi·ªÅu\s+(\d+)...",
       "khoan": r"^(\d+)\.\s+...",
   }
   
   ‚Üí Bidding docs don't have ƒêi·ªÅu!
   ‚Üí Reports use different numbering (I.1, I.2)
   ‚Üí Exams use "C√¢u X:" pattern

‚ùå Hierarchy assumptions:
   - Assumes Ch∆∞∆°ng ‚Üí ƒêi·ªÅu ‚Üí Kho·∫£n tree
   - Bidding: M·∫´u ‚Üí Sections ‚Üí Items (different!)
   - Reports: PH·∫¶N ‚Üí Subsections (flatter)

‚ùå Strategy names misleading:
   - "by_dieu" doesn't apply to non-legal docs
   - "hierarchical" assumes legal hierarchy
```

**Missing Features for Non-Legal Docs:**
```python
‚ùå Table handling:
   - Bidding/reports have 10-25 tables
   - Need table-aware chunking
   - Preserve table context

‚ùå Form detection:
   - "M·∫´u s·ªë X" in bidding docs
   - Should chunk by form boundaries

‚ùå Question detection:
   - "C√¢u X:" pattern for exams
   - Option extraction (A/B/C/D)

‚ùå Semantic boundary detection:
   - Topic changes in narrative text
   - Subsection numbering (I.1, I.2)
```

---

## üí° PROPOSED SOLUTION

### Architecture: 2 Specialized Chunkers

```
src/preprocessing/chunking/
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ base_chunker.py          # Base class (NEW)
‚îú‚îÄ‚îÄ hierarchical_chunker.py  # For legal docs (REFACTOR from chunk_strategy.py)
‚îî‚îÄ‚îÄ semantic_chunker.py      # For bidding/report/exam (NEW)
```

### 1. BaseLegalChunker (Abstract Base Class)

**Purpose:** Common interface and utilities

```python
from abc import ABC, abstractmethod
from typing import List, Dict
from dataclasses import dataclass

@dataclass
class UniversalChunk:
    """Universal chunk structure for all document types"""
    chunk_id: str
    text: str
    metadata: Dict
    chunk_type: str  # 'dieu', 'section', 'form', 'question'
    hierarchy: List[str]
    char_count: int
    parent_id: str = None

class BaseLegalChunker(ABC):
    """Base class for all chunking strategies"""
    
    def __init__(
        self,
        max_chunk_size: int = 1500,
        overlap_size: int = 200,
        keep_parent_context: bool = True,
    ):
        self.max_chunk_size = max_chunk_size
        self.overlap_size = overlap_size
        self.keep_parent_context = keep_parent_context
    
    @abstractmethod
    def chunk_document(self, document: Dict) -> List[UniversalChunk]:
        """Main chunking method - must implement"""
        pass
    
    def _split_with_overlap(self, text: str, max_size: int) -> List[str]:
        """Reusable overlap splitting - common utility"""
        chunks = []
        start = 0
        while start < len(text):
            end = start + max_size
            chunks.append(text[start:end])
            start = end - self.overlap_size
        return chunks
    
    def _add_parent_context(self, text: str, parent: str) -> str:
        """Add parent context to chunk - common utility"""
        if self.keep_parent_context and parent:
            return f"[Context: {parent}]\n\n{text}"
        return text
```

### 2. HierarchicalChunker (Legal Documents)

**Source:** Refactor from `chunk_strategy.py`

**Changes:**
- ‚úÖ Keep: ƒêi·ªÅu/Kho·∫£n/ƒêi·ªÉm parsing
- ‚úÖ Keep: Hierarchy tree building
- ‚úÖ Keep: Context preservation
- ‚úÖ Update: Use UniversalChunk instead of LawChunk
- ‚úÖ Update: Integrate with V2 schema (UnifiedLegalChunk)

```python
class HierarchicalChunker(BaseLegalChunker):
    """
    Chunking for structured legal documents.
    
    Applies to: Lu·∫≠t, Ngh·ªã ƒë·ªãnh, Th√¥ng t∆∞, Quy·∫øt ƒë·ªãnh
    
    Strategy: ƒêi·ªÅu-based chunking with hierarchy preservation
    """
    
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        
        # Legal document patterns
        self.patterns = {
            "phan": r"^(PH·∫¶N|Ph·∫ßn)\s+([IVXLCDM]+)",
            "chuong": r"^(CH∆Ø∆†NG|Ch∆∞∆°ng)\s+([IVXLCDM]+)",
            "muc": r"^(M·ª§C|M·ª•c)\s+([IVXLCDM]+|\d+)",
            "dieu": r"^ƒêi·ªÅu\s+(\d+[a-z]?)\.\s*(.+?)$",
            "khoan": r"^(\d+)\.\s+(.+)",
            "diem": r"^([a-zƒë])\)\s+(.+)",
        }
    
    def chunk_document(self, document: Dict) -> List[UniversalChunk]:
        """Chunk by ƒêi·ªÅu with hierarchy"""
        # 1. Parse structure tree (Ph·∫ßn > Ch∆∞∆°ng > M·ª•c > ƒêi·ªÅu)
        structure = self._parse_legal_structure(document["text"])
        
        # 2. Chunk by ƒêi·ªÅu (optimal level)
        chunks = []
        for dieu in structure:
            if dieu["type"] == "dieu":
                chunk = self._create_dieu_chunk(dieu, document)
                
                # Split large ƒêi·ªÅu by Kho·∫£n
                if len(chunk.text) > self.max_chunk_size:
                    sub_chunks = self._split_by_khoan(dieu, document)
                    chunks.extend(sub_chunks)
                else:
                    chunks.append(chunk)
        
        return chunks
    
    def _parse_legal_structure(self, text: str) -> List[Dict]:
        """Parse Ph·∫ßn > Ch∆∞∆°ng > M·ª•c > ƒêi·ªÅu > Kho·∫£n > ƒêi·ªÉm"""
        # DFS tree traversal
        # ... (reuse from chunk_strategy.py)
```

### 3. SemanticChunker (Non-Legal Documents)

**Purpose:** Handle bidding, reports, exams

**New Implementation:**

```python
class SemanticChunker(BaseLegalChunker):
    """
    Chunking for semi-structured and unstructured documents.
    
    Applies to: H·ªì s∆° m·ªùi th·∫ßu, M·∫´u b√°o c√°o, C√¢u h·ªèi thi
    
    Strategy: Semantic boundary detection + sliding window
    """
    
    def __init__(self, document_type: str, **kwargs):
        super().__init__(**kwargs)
        self.document_type = document_type
        
        # Patterns by document type
        self.patterns = self._get_patterns_for_type(document_type)
    
    def _get_patterns_for_type(self, doc_type: str) -> Dict:
        """Get chunking patterns based on document type"""
        
        if doc_type == "bidding":
            return {
                "form": r"^M·∫´u\s+s·ªë\s+(\d+[A-Z]?)",
                "section": r"^(PH·∫¶N|CH∆Ø∆†NG)\s+([IVXLCDM]+|\d+)",
                "table_title": r"^(B·∫£ng|B·∫¢NG|Bi·ªÉu)\s+(\d+)",
            }
        
        elif doc_type == "report":
            return {
                "section": r"^(PH·∫¶N)\s+([IVXLCDM]+)",
                "subsection": r"^([IVX]+)\.\s+(.+)",
                "item": r"^(\d+)\.\s+(.+)",
                "subitem": r"^([a-z])\)\s+(.+)",
            }
        
        elif doc_type == "exam":
            return {
                "question": r"^(C√¢u|C√ÇU)\s+(\d+)[:\.]",
                "option": r"^([A-D])[:\.\)]\s+(.+)",
                "answer": r"(?i)(ƒë√°p\s*√°n|correct)[:\s]+([A-D])",
            }
        
        return {}
    
    def chunk_document(self, document: Dict) -> List[UniversalChunk]:
        """Main chunking dispatcher"""
        
        if self.document_type == "bidding":
            return self._chunk_bidding(document)
        elif self.document_type == "report":
            return self._chunk_report(document)
        elif self.document_type == "exam":
            return self._chunk_exam(document)
        else:
            return self._chunk_generic(document)
    
    def _chunk_bidding(self, document: Dict) -> List[UniversalChunk]:
        """
        Bidding document chunking:
        1. Chunk by M·∫´u s·ªë X (forms)
        2. Chunk by PH·∫¶N/CH∆Ø∆†NG (sections)
        3. Preserve tables as separate chunks
        """
        chunks = []
        text = document["text"]
        
        # 1. Detect form boundaries (M·∫´u s·ªë X)
        form_sections = self._split_by_pattern(
            text, 
            self.patterns["form"]
        )
        
        # 2. For each form, split by sections
        for form in form_sections:
            if len(form["text"]) <= self.max_chunk_size:
                # Small form: keep intact
                chunks.append(self._create_chunk(
                    form, 
                    chunk_type="form",
                    document=document
                ))
            else:
                # Large form: split by sections
                sections = self._split_by_pattern(
                    form["text"],
                    self.patterns["section"]
                )
                for section in sections:
                    chunks.append(self._create_chunk(
                        section,
                        chunk_type="section",
                        parent=form["title"],
                        document=document
                    ))
        
        return chunks
    
    def _chunk_report(self, document: Dict) -> List[UniversalChunk]:
        """
        Report chunking:
        1. Chunk by PH·∫¶N (major sections)
        2. Chunk by subsections (I.1, I.2, II.1...)
        3. Keep tables with their context
        """
        chunks = []
        text = document["text"]
        
        # Split by PH·∫¶N I, II, III...
        sections = self._split_by_pattern(text, self.patterns["section"])
        
        for section in sections:
            # Split by subsections (I.1, I.2...)
            subsections = self._split_by_pattern(
                section["text"],
                self.patterns["subsection"]
            )
            
            for subsection in subsections:
                if len(subsection["text"]) <= self.max_chunk_size:
                    chunks.append(self._create_chunk(
                        subsection,
                        chunk_type="subsection",
                        parent=section["title"],
                        document=document
                    ))
                else:
                    # Long subsection: sliding window
                    overlapped = self._split_with_overlap(
                        subsection["text"],
                        self.max_chunk_size
                    )
                    for i, chunk_text in enumerate(overlapped):
                        chunks.append(self._create_chunk(
                            {"text": chunk_text, "title": f"{subsection['title']} (part {i+1})"},
                            chunk_type="subsection_part",
                            parent=section["title"],
                            document=document
                        ))
        
        return chunks
    
    def _chunk_exam(self, document: Dict) -> List[UniversalChunk]:
        """
        Exam chunking:
        1. Detect question boundaries (C√¢u X:)
        2. Extract options (A, B, C, D)
        3. Include answer if present
        4. One question = one chunk
        """
        chunks = []
        text = document["text"]
        
        # Split by questions
        questions = self._extract_questions(text)
        
        for q in questions:
            chunk = UniversalChunk(
                chunk_id=f"{document['id']}_q_{q['number']}",
                text=q["full_text"],
                metadata={
                    **document.get("metadata", {}),
                    "question_number": q["number"],
                    "options": q.get("options", []),
                    "answer": q.get("answer"),
                },
                chunk_type="question",
                hierarchy=[f"Question {q['number']}"],
                char_count=len(q["full_text"]),
            )
            chunks.append(chunk)
        
        return chunks
    
    def _extract_questions(self, text: str) -> List[Dict]:
        """Extract individual questions with options and answers"""
        questions = []
        
        # Find all "C√¢u X:" boundaries
        question_pattern = self.patterns["question"]
        matches = list(re.finditer(question_pattern, text, re.MULTILINE))
        
        for i, match in enumerate(matches):
            start = match.start()
            end = matches[i+1].start() if i+1 < len(matches) else len(text)
            
            question_block = text[start:end]
            
            # Extract components
            q_number = match.group(2)
            options = self._extract_options(question_block)
            answer = self._extract_answer(question_block)
            
            questions.append({
                "number": q_number,
                "full_text": question_block.strip(),
                "options": options,
                "answer": answer,
            })
        
        return questions
    
    def _split_by_pattern(self, text: str, pattern: str) -> List[Dict]:
        """Split text by regex pattern (section markers)"""
        parts = []
        matches = list(re.finditer(pattern, text, re.MULTILINE))
        
        for i, match in enumerate(matches):
            start = match.start()
            end = matches[i+1].start() if i+1 < len(matches) else len(text)
            
            parts.append({
                "title": match.group(0),
                "text": text[start:end],
                "number": match.group(2) if len(match.groups()) >= 2 else str(i),
            })
        
        return parts
```

---

## üìä COMPARISON TABLE

| Feature | HierarchicalChunker | SemanticChunker |
|---------|---------------------|-----------------|
| **Document Types** | Lu·∫≠t, Ngh·ªã ƒë·ªãnh, Th√¥ng t∆∞, Quy·∫øt ƒë·ªãnh | H·ªì s∆° m·ªùi th·∫ßu, M·∫´u b√°o c√°o, C√¢u h·ªèi thi |
| **Structure** | Strict hierarchy (Ph·∫ßn‚ÜíCh∆∞∆°ng‚Üíƒêi·ªÅu) | Semi/unstructured |
| **Chunk Unit** | ƒêi·ªÅu (Article) | Form, Section, Question |
| **Pattern Matching** | ƒêi·ªÅu/Kho·∫£n/ƒêi·ªÉm regex | Flexible patterns per doc type |
| **Hierarchy** | Deep tree (5-6 levels) | Flat/shallow (2-3 levels) |
| **Avg Chunk Size** | 500-1,500 chars (ƒêi·ªÅu) | Variable (200-2,000 chars) |
| **Table Handling** | Rare, within ƒêi·ªÅu | Common, preserve separately |
| **Context Strategy** | Parent Ch∆∞∆°ng/M·ª•c | Parent Section/Form |
| **Splitting Strategy** | By Kho·∫£n for large ƒêi·ªÅu | Sliding window with overlap |
| **Reuse from V1** | ‚úÖ 80% (refactor chunk_strategy.py) | ‚ùå 20% (mostly new logic) |

---

## üéØ IMPLEMENTATION PLAN

### Step 1: Create Base Class (2 hours)
```python
src/preprocessing/chunking/base_chunker.py
- BaseLegalChunker abstract class
- UniversalChunk dataclass
- Common utilities (_split_with_overlap, _add_parent_context)
```

### Step 2: Refactor HierarchicalChunker (4 hours)
```python
src/preprocessing/chunking/hierarchical_chunker.py
- Refactor from chunk_strategy.py
- Update to use UniversalChunk
- Integrate with V2 UnifiedLegalChunk schema
- Add Ph·∫ßn/M·ª•c support (currently only Ch∆∞∆°ng/ƒêi·ªÅu)
```

### Step 3: Implement SemanticChunker (8 hours)
```python
src/preprocessing/chunking/semantic_chunker.py
- NEW implementation
- Bidding chunking (form + section based)
- Report chunking (PH·∫¶N + subsection based)
- Exam chunking (question based)
- Table-aware splitting
```

### Step 4: Schema Integration (4 hours)
```python
- Create ChunkFactory helper
- Convert UniversalChunk ‚Üí UnifiedLegalChunk
- Handle all nested Pydantic models
- Fix validation errors
```

### Step 5: Testing (4 hours)
```python
scripts/test/test_chunking_strategies.py
- Test HierarchicalChunker with legal docs
- Test SemanticChunker with bidding/report/exam
- Compare chunk sizes
- Validate schema integration
```

**Total Estimated:** 22 hours

---

## üîë KEY DECISIONS

### ‚úÖ DO Reuse from `chunk_strategy.py`

**What to reuse:**
1. ‚úÖ Overlap splitting logic (`_split_with_overlap`)
2. ‚úÖ Context preservation approach
3. ‚úÖ Hierarchy tree building (DFS traversal)
4. ‚úÖ ƒêi·ªÅu/Kho·∫£n/ƒêi·ªÉm regex patterns
5. ‚úÖ Chunk size management

**Rationale:** These are universal chunking concepts, not specific to legal docs.

### ‚ùå DO NOT Force Hierarchy on Non-Legal Docs

**Why:**
1. ‚ùå Bidding docs don't have ƒêi·ªÅu structure
2. ‚ùå Forms/tables need different treatment
3. ‚ùå Questions are flat, not hierarchical
4. ‚ùå Forcing hierarchy creates bad chunks

**Alternative:** Semantic boundary detection + type-specific patterns

### ‚úÖ DO Use Polymorphism

**Strategy:**
```python
# Factory pattern
def create_chunker(document_type: str) -> BaseLegalChunker:
    if document_type in ["law", "decree", "circular", "decision"]:
        return HierarchicalChunker()
    elif document_type == "bidding":
        return SemanticChunker(document_type="bidding")
    elif document_type == "report":
        return SemanticChunker(document_type="report")
    elif document_type == "exam":
        return SemanticChunker(document_type="exam")
```

**Benefits:**
- ‚úÖ Clean interface
- ‚úÖ Easy to extend (new doc types)
- ‚úÖ Testable (mock chunkers)

---

## üìå CONCLUSION

**Summary:**

1. **HierarchicalChunker** (refactor chunk_strategy.py)
   - ƒêi·ªÅu-based chunking
   - For: Lu·∫≠t, Ngh·ªã ƒë·ªãnh, Th√¥ng t∆∞, Quy·∫øt ƒë·ªãnh
   - Reuse: 80% of existing code

2. **SemanticChunker** (new implementation)
   - Flexible pattern matching
   - For: H·ªì s∆° m·ªùi th·∫ßu, M·∫´u b√°o c√°o, C√¢u h·ªèi thi
   - Reuse: 20% (only utilities)

**Recommendation:** Proceed with 2-chunker architecture

**Next Actions:**
1. Create BaseLegalChunker abstract class
2. Refactor chunk_strategy.py ‚Üí HierarchicalChunker
3. Implement SemanticChunker from scratch
4. Fix schema integration (ChunkFactory)
5. Write comprehensive tests

**Expected Outcome:**
- ‚úÖ All 7 document types supported
- ‚úÖ Optimal chunk sizes (500-1,500 chars)
- ‚úÖ Semantic boundaries preserved
- ‚úÖ Schema integration working
- ‚úÖ 16+ tests passing

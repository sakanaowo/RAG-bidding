# DOCX Processing Module cho VÄƒn báº£n Äáº¥u tháº§u

**Version**: 1.0.0  
**Last updated**: 2025-10-30

Module tiá»n xá»­ lÃ½ vÄƒn báº£n phÃ¡p luáº­t Ä‘áº¥u tháº§u tá»« file DOCX sang chunks tá»‘i Æ°u cho RAG system.

---

## ğŸ¯ TÃ­nh nÄƒng

### 1. **DOCX Extractor** (`docx_extractor.py`)
- Extract text, tables, structure tá»« .docx files
- Detect metadata (doc type, number, year)
- Preserve hierarchical structure
- Export to JSON, Markdown

### 2. **Legal Document Cleaner** (`legal_cleaner.py`)
- Clean vÃ  normalize text
- Standardize bidding terms (Ä‘áº¥u tháº§u, nhÃ  tháº§u, etc.)
- Remove artifacts (page numbers, headers)
- Validate cleaned text

### 3. **Bidding Law Parser** (`bidding_law_parser.py`)
- Parse hierarchical structure:
  - Pháº§n â†’ ChÆ°Æ¡ng â†’ Má»¥c â†’ Äiá»u â†’ Khoáº£n â†’ Äiá»ƒm
- Build structure tree
- Extract metadata tá»« content
- Get Äiá»u list, statistics

### 4. **DOCX Processing Pipeline** (`docx_pipeline.py`)
- End-to-end pipeline: DOCX â†’ Structured JSON â†’ Chunks â†’ JSONL
- Batch processing support
- Multiple output formats
- Processing reports

---

## ğŸš€ Quick Start

### Dependencies

```bash
pip install python-docx
```

### Usage

#### Single File Processing

```python
from src.preprocessing.parsers.docx_pipeline import DocxProcessingPipeline

# Initialize
pipeline = DocxProcessingPipeline(
    max_chunk_size=2000,
    min_chunk_size=300,
    aggressive_clean=False
)

# Process
results = pipeline.process_single_file(
    "data/raw/Luat chinh/Luat Dau thau 2023.docx",
    output_dir="data/processed"
)

print(f"Created {len(results['chunks'])} chunks")
```

#### Batch Processing

```python
# Process all DOCX files in directory
batch_results = pipeline.process_batch(
    input_dir="data/raw/Luat chinh",
    output_dir="data/processed"
)
```

### Run Test Script

```bash
cd /home/sakana/Code/RAG-bidding
python3 scripts/test_docx_pipeline.py
```

---

## ğŸ“Š Processing Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   DOCX File â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. Extract         â”‚ â† DocxExtractor
â”‚  - Text             â”‚
â”‚  - Tables           â”‚
â”‚  - Metadata         â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. Clean           â”‚ â† LegalDocumentCleaner
â”‚  - Normalize        â”‚
â”‚  - Remove artifacts â”‚
â”‚  - Validate         â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. Parse Structure â”‚ â† BiddingLawParser
â”‚  - Build tree       â”‚
â”‚  - Extract Äiá»u     â”‚
â”‚  - Get hierarchy    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. Chunk           â”‚ â† OptimalLegalChunker
â”‚  - By Äiá»u/Khoáº£n    â”‚
â”‚  - Add context      â”‚
â”‚  - Optimize size    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. Export          â”‚
â”‚  - JSON (structured)â”‚
â”‚  - JSONL (chunks)   â”‚
â”‚  - MD (review)      â”‚
â”‚  - Report           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Output Formats

### 1. Structured JSON (`*_structured.json`)
```json
{
  "metadata": {
    "doc_type": "Luáº­t",
    "doc_number": "98/2023-QH15",
    "title": "Luáº­t Äáº¥u tháº§u 2023"
  },
  "content": "...",
  "structure": {...},
  "statistics": {...}
}
```

### 2. Chunks JSONL (`*_chunks.jsonl`)
```json
{"id": "luat-98-2023_dieu_1", "text": "...", "metadata": {...}}
{"id": "luat-98-2023_dieu_2", "text": "...", "metadata": {...}}
```

### 3. Markdown (`*.md`)
```markdown
---
title: "Luáº­t Äáº¥u tháº§u 2023"
doc_type: "Luáº­t"
---

Äiá»u 1. Pháº¡m vi Ä‘iá»u chá»‰nh
...
```

### 4. Processing Report (`*_report.txt`)
```
================================================================================
DOCX PROCESSING REPORT
================================================================================

File: Luat Dau thau 2023.docx
Processed: 2025-10-30 15:30:00

METADATA:
----------------------------------------
  doc_type: Luáº­t
  doc_number: 98/2023-QH15
  ...

EXTRACTION STATISTICS:
----------------------------------------
  char_count: 250,000
  dieu_count: 95
  ...
```

---

## ğŸ”§ Configuration

### Pipeline Parameters

```python
DocxProcessingPipeline(
    max_chunk_size=2000,      # Max chars per chunk
    min_chunk_size=300,       # Min chars per chunk
    aggressive_clean=False    # Apply aggressive cleaning
)
```

### Cleaner Options

```python
cleaner.clean(
    text,
    aggressive=True  # Remove short lines, duplicates
)
```

---

## ğŸ“Š Supported Document Types

âœ… **Luáº­t** (Laws)
- Pattern: `Luáº­t sá»‘ XX/YYYY-QH`
- Example: Luáº­t Äáº¥u tháº§u 2023

âœ… **Nghá»‹ Ä‘á»‹nh** (Decrees)
- Pattern: `Nghá»‹ Ä‘á»‹nh sá»‘ XX/YYYY-NÄ-CP`
- Example: Nghá»‹ Ä‘á»‹nh 214/2025-NÄ-CP

âœ… **ThÃ´ng tÆ°** (Circulars)
- Pattern: `ThÃ´ng tÆ° sá»‘ XX/YYYY-TT-BTC`
- Example: ThÃ´ng tÆ° 79/2025-TT-BTC

---

## ğŸ—ï¸ Structure Detection

| Level | Vietnamese | Example | Pattern |
|-------|-----------|---------|---------|
| 0 | Pháº§n | PHáº¦N THá»¨ NHáº¤T | `PHáº¦N THá»¨ [IVXLCDM]+` |
| 1 | ChÆ°Æ¡ng | CHÆ¯Æ NG I | `CHÆ¯Æ NG [IVXLCDM]+` |
| 2 | Má»¥c | Má»¥c 1 | `Má»¥c \d+` |
| 3 | Äiá»u | Äiá»u 1 | `Äiá»u \d+[a-z]?` |
| 4 | Khoáº£n | 1. | `\d+\.` |
| 5 | Äiá»ƒm | a) | `[a-zÄ‘]\)` |

---

## ğŸ“ˆ Performance

**Test vá»›i Luáº­t Äáº¥u tháº§u 2023:**
- File size: ~437 KB
- Processing time: ~3-5 seconds
- Extracted: ~250,000 chars
- Structure: 95 Äiá»u, 420 Khoáº£n
- Chunks created: ~270 chunks
- Average chunk size: ~900 chars

---

## ğŸ” Validation

### Text Validation
- âœ… Has Äiá»u structure
- âœ… Has ChÆ°Æ¡ng structure
- âœ… Minimum length (>1000 chars)
- âœ… Legal keywords present

### Chunk Validation
- âœ… Size within limits
- âœ… Has proper hierarchy
- âœ… Contains meaningful content
- âœ… Metadata complete

---

## ğŸ§ª Testing

```bash
# Run test script
python3 scripts/test_docx_pipeline.py

# Expected output:
# - Extracted text statistics
# - Structure statistics
# - Chunk statistics
# - Output files in data/processed/test_output/
```

---

## ğŸ”— Integration vá»›i RAG System

### 1. Process DOCX files
```python
pipeline = DocxProcessingPipeline()
results = pipeline.process_single_file("law.docx", "output/")
```

### 2. Load chunks vÃ o vector store
```python
from scripts.import_chunks import import_chunks_from_jsonl

import_chunks_from_jsonl("output/law_chunks.jsonl")
```

### 3. Query RAG system
```python
from src.retrieval.retrievers import create_retriever

retriever = create_retriever(mode="balanced")
docs = retriever.get_relevant_documents("quy trÃ¬nh Ä‘áº¥u tháº§u")
```

---

## ğŸ“ Notes

### Bidding-Specific Terms
- `Ä‘áº¥u tháº§u` (bidding)
- `nhÃ  tháº§u` (contractor)
- `gÃ³i tháº§u` (bidding package)
- `há»“ sÆ¡ má»i tháº§u` (tender documents)
- `há»“ sÆ¡ dá»± tháº§u` (bid documents)
- `káº¿ hoáº¡ch lá»±a chá»n nhÃ  tháº§u` (contractor selection plan)

### Known Limitations
1. Tables are detected but content not fully integrated
2. Complex formatting (bold, italic) not preserved
3. Footnotes vÃ  references cáº§n manual review
4. Some legal references cáº§n post-processing

---

## ğŸ› ï¸ Troubleshooting

### Import errors
```bash
# Install missing package
pip install python-docx
```

### File not found
```bash
# Check file path
ls -la "data/raw/Luat chinh/"
```

### Low chunk count
- Check if document has proper structure (Äiá»u, ChÆ°Æ¡ng)
- Verify text was extracted correctly
- Try with `aggressive_clean=False`

---

## ğŸ“š Examples

See:
- `scripts/test_docx_pipeline.py` - Test script
- Each module's `if __name__ == "__main__"` section

---

**Author**: RAG-bidding team  
**Contact**: See project README

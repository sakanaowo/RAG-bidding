import os
from typing import Dict
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import (
    RunnablePassthrough,
    RunnableLambda,
    RunnableParallel,
)
from src.generation.prompts.qa_prompts import SYSTEM_PROMPT, USER_TEMPLATE
from src.retrieval.retrievers import create_retriever
from config.models import settings, apply_preset


model = ChatOpenAI(model=settings.llm_model, temperature=0)

prompt = ChatPromptTemplate.from_messages(
    [("system", SYSTEM_PROMPT), ("user", USER_TEMPLATE)]
)


def fmt_docs(docs):
    lines = []
    for i, d in enumerate(docs, 1):
        lines.append(f"[#{i}]\n{d.page_content}\n")
    return "\n".join(lines)


# rag_core = (
#     {"context": retriever | RunnableLambda(fmt_docs), "question": RunnablePassthrough()}
#     | prompt
#     | model
#     | StrOutputParser()
# )
retriever = create_retriever(mode="balanced")
rag_chain = (
    {"context": retriever | fmt_docs, "question": RunnablePassthrough()}
    | prompt
    | model
    | StrOutputParser()
)

chain = RunnableParallel(answer=rag_chain, source_documents=retriever)


def format_document_reference(doc, index: int) -> str:
    """Format document reference v·ªõi th√¥ng tin chi ti·∫øt."""
    meta = doc.metadata

    # L·∫•y th√¥ng tin c∆° b·∫£n
    title = meta.get("title", "T√†i li·ªáu")
    doc_type = meta.get("document_type", "")

    # Th√¥ng tin v·ªã tr√≠ trong t√†i li·ªáu
    hierarchy_parts = []

    # Th√™m ch∆∞∆°ng n·∫øu c√≥
    if meta.get("chuong"):
        hierarchy_parts.append(f"Ch∆∞∆°ng {meta['chuong']}")

    # Th√™m ƒëi·ªÅu
    if meta.get("dieu"):
        hierarchy_parts.append(f"ƒêi·ªÅu {meta['dieu']}")

    # Th√™m kho·∫£n n·∫øu c√≥
    if meta.get("khoan"):
        hierarchy_parts.append(f"Kho·∫£n {meta['khoan']}")

    # Th√™m ƒëi·ªÉm n·∫øu c√≥
    if meta.get("diem"):
        hierarchy_parts.append(f"ƒêi·ªÉm {meta['diem']}")

    # T·∫°o hierarchy string
    hierarchy = " ‚Üí ".join(hierarchy_parts) if hierarchy_parts else "N·ªôi dung chung"

    # URL ngu·ªìn n·∫øu c√≥
    url = meta.get("url", "")
    source_info = f"({url})" if url else ""

    # Preview n·ªôi dung
    content_preview = doc.page_content[:100].replace("\n", " ").strip()
    if len(doc.page_content) > 100:
        content_preview += "..."

    # Format final reference
    if doc_type:
        doc_type_str = f" - {doc_type}"
    else:
        doc_type_str = ""

    return (
        f"[#{index}] {hierarchy}{doc_type_str}\n    üìÑ {content_preview}\n    üîó {source_info}"
        if source_info
        else f"[#{index}] {hierarchy}{doc_type_str}\n    üìÑ {content_preview}"
    )


def answer(
    question: str, mode: str | None = None, use_enhancement: bool = True
) -> Dict:
    selected_mode = mode or settings.rag_mode or "balanced"
    apply_preset(selected_mode)

    # Create retriever based on mode (already includes enhancement if mode != 'fast')
    # No need to modify use_query_enhancement here since it's baked into the retriever

    result = chain.invoke(question)

    # T·∫°o detailed source references
    src_lines = []
    detailed_sources = []

    for i, d in enumerate(result["source_documents"], 1):
        # T·∫°o reference chi ti·∫øt
        detailed_ref = format_document_reference(d, i)
        detailed_sources.append(detailed_ref)

        # T·∫°o source line ƒë∆°n gi·∫£n cho backward compatibility
        meta = d.metadata
        hierarchy_parts = []

        if meta.get("dieu"):
            hierarchy_parts.append(f"ƒêi·ªÅu {meta['dieu']}")
        if meta.get("khoan"):
            hierarchy_parts.append(f"Kho·∫£n {meta['khoan']}")
        if meta.get("diem"):
            hierarchy_parts.append(f"ƒêi·ªÉm {meta['diem']}")

        hierarchy = " ".join(hierarchy_parts) if hierarchy_parts else "VƒÉn b·∫£n"
        doc_title = meta.get("title", "T√†i li·ªáu ph√°p lu·∫≠t")

        src_lines.append(f"[#{i}] {hierarchy} - {doc_title}")

    return {
        "answer": result["answer"].strip()
        + "\n\nNgu·ªìn:\n"
        + "\n".join(detailed_sources),
        "sources": src_lines,
        "detailed_sources": detailed_sources,
        # "phase1_mode": selected_mode,  # ‚Üê ADD THIS
        "adaptive_retrieval": {
            "mode": selected_mode,
            "docs_retrieved": len(result["source_documents"]),
            "enhancement_enabled": selected_mode != "fast",
        },
        "enhanced_features": [
            "Modular Retriever Architecture",
            (
                "Query Enhancement (Multi-Query, HyDE, Step-Back, Decomposition)"
                if selected_mode != "fast"
                else "Query Enhancement"
            ),
            "RAG-Fusion with RRF" if selected_mode == "quality" else "RAG-Fusion",
            "Adaptive K" if selected_mode == "adaptive" else "Adaptive K",
            # "Document Reranking (Phase 2+)",
        ],
    }
